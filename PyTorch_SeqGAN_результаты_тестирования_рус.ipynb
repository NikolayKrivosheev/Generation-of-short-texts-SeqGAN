{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "PyTorch SeqGAN для статьи.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kSAtCAGcQgJP"
      },
      "source": [
        "**Предисловие:**\n",
        "\n",
        "**Реализация основана на работе:** ...\n",
        "\n",
        "**Результаты данной работы представлены в статье (при использовании просьба ссылаться на следующую работу):** ...\n",
        "\n",
        "**Выборки данных:**\n",
        ">*    Подписи к изображениям на английском языке из выборки COCO Image Captions\n",
        "*    Стихи на русском языке с сайта stihi.ru\n",
        "\n",
        "**Описание работы:**\n",
        "> В данной работе проведены реализация, обучение и тестирование нейронных сетей для генерации случайных коротких текстов. Используются такие нейронные сети как LSTM и SeqGAN. Проведена оценка качества генерации текста на основе метрики BLEU. Для обучения и тестирования используются следующие выборки данных:\n",
        "*   Подписи к изображениям на английском языке из выборки COCO Image Captions\n",
        "*   Стихи на русском языке с сайта stihi.ru\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dBqFdGkPPxCg"
      },
      "source": [
        "Список всех установленных библиотек и их версии"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CAl5Uo2vP12W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d8c06a8-9b32-4dd8-ddef-7317cad48051"
      },
      "source": [
        "!pip list"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Package                       Version        \n",
            "----------------------------- ---------------\n",
            "absl-py                       0.10.0         \n",
            "alabaster                     0.7.12         \n",
            "albumentations                0.1.12         \n",
            "altair                        4.1.0          \n",
            "argon2-cffi                   20.1.0         \n",
            "asgiref                       3.3.1          \n",
            "astor                         0.8.1          \n",
            "astropy                       4.1            \n",
            "astunparse                    1.6.3          \n",
            "async-generator               1.10           \n",
            "atari-py                      0.2.6          \n",
            "atomicwrites                  1.4.0          \n",
            "attrs                         20.3.0         \n",
            "audioread                     2.1.9          \n",
            "autograd                      1.3            \n",
            "Babel                         2.9.0          \n",
            "backcall                      0.2.0          \n",
            "beautifulsoup4                4.6.3          \n",
            "bleach                        3.2.1          \n",
            "blis                          0.4.1          \n",
            "bokeh                         2.1.1          \n",
            "Bottleneck                    1.3.2          \n",
            "branca                        0.4.1          \n",
            "bs4                           0.0.1          \n",
            "CacheControl                  0.12.6         \n",
            "cachetools                    4.1.1          \n",
            "catalogue                     1.0.0          \n",
            "certifi                       2020.11.8      \n",
            "cffi                          1.14.3         \n",
            "chainer                       7.4.0          \n",
            "chardet                       3.0.4          \n",
            "click                         7.1.2          \n",
            "cloudpickle                   1.3.0          \n",
            "cmake                         3.12.0         \n",
            "cmdstanpy                     0.9.5          \n",
            "colorlover                    0.3.0          \n",
            "community                     1.0.0b1        \n",
            "contextlib2                   0.5.5          \n",
            "convertdate                   2.3.0          \n",
            "coverage                      3.7.1          \n",
            "coveralls                     0.5            \n",
            "crcmod                        1.7            \n",
            "cufflinks                     0.17.3         \n",
            "cupy-cuda101                  7.4.0          \n",
            "cvxopt                        1.2.5          \n",
            "cvxpy                         1.0.31         \n",
            "cycler                        0.10.0         \n",
            "cymem                         2.0.4          \n",
            "Cython                        0.29.21        \n",
            "daft                          0.0.4          \n",
            "dask                          2.12.0         \n",
            "dataclasses                   0.8            \n",
            "datascience                   0.10.6         \n",
            "debugpy                       1.0.0          \n",
            "decorator                     4.4.2          \n",
            "defusedxml                    0.6.0          \n",
            "descartes                     1.1.0          \n",
            "dill                          0.3.3          \n",
            "distributed                   1.25.3         \n",
            "Django                        3.1.3          \n",
            "dlib                          19.18.0        \n",
            "dm-tree                       0.1.5          \n",
            "docopt                        0.6.2          \n",
            "docutils                      0.16           \n",
            "dopamine-rl                   1.0.5          \n",
            "earthengine-api               0.1.238        \n",
            "easydict                      1.9            \n",
            "ecos                          2.0.7.post1    \n",
            "editdistance                  0.5.3          \n",
            "en-core-web-sm                2.2.5          \n",
            "entrypoints                   0.3            \n",
            "ephem                         3.7.7.1        \n",
            "et-xmlfile                    1.0.1          \n",
            "fa2                           0.3.5          \n",
            "fancyimpute                   0.4.3          \n",
            "fastai                        1.0.61         \n",
            "fastdtw                       0.3.4          \n",
            "fastprogress                  1.0.0          \n",
            "fastrlock                     0.5            \n",
            "fbprophet                     0.7.1          \n",
            "feather-format                0.4.1          \n",
            "filelock                      3.0.12         \n",
            "firebase-admin                4.4.0          \n",
            "fix-yahoo-finance             0.0.22         \n",
            "Flask                         1.1.2          \n",
            "flatbuffers                   1.12           \n",
            "folium                        0.8.3          \n",
            "future                        0.16.0         \n",
            "gast                          0.3.3          \n",
            "GDAL                          2.2.2          \n",
            "gdown                         3.6.4          \n",
            "gensim                        3.6.0          \n",
            "geographiclib                 1.50           \n",
            "geopy                         1.17.0         \n",
            "gin-config                    0.3.0          \n",
            "glob2                         0.7            \n",
            "google                        2.0.3          \n",
            "google-api-core               1.16.0         \n",
            "google-api-python-client      1.7.12         \n",
            "google-auth                   1.17.2         \n",
            "google-auth-httplib2          0.0.4          \n",
            "google-auth-oauthlib          0.4.2          \n",
            "google-cloud-bigquery         1.21.0         \n",
            "google-cloud-bigquery-storage 1.1.0          \n",
            "google-cloud-core             1.0.3          \n",
            "google-cloud-datastore        1.8.0          \n",
            "google-cloud-firestore        1.7.0          \n",
            "google-cloud-language         1.2.0          \n",
            "google-cloud-storage          1.18.1         \n",
            "google-cloud-translate        1.5.0          \n",
            "google-colab                  1.0.0          \n",
            "google-pasta                  0.2.0          \n",
            "google-resumable-media        0.4.1          \n",
            "googleapis-common-protos      1.52.0         \n",
            "googledrivedownloader         0.4            \n",
            "graphviz                      0.10.1         \n",
            "grpcio                        1.33.2         \n",
            "gspread                       3.0.1          \n",
            "gspread-dataframe             3.0.8          \n",
            "gym                           0.17.3         \n",
            "h5py                          2.10.0         \n",
            "HeapDict                      1.0.1          \n",
            "holidays                      0.10.3         \n",
            "holoviews                     1.13.5         \n",
            "html5lib                      1.0.1          \n",
            "httpimport                    0.5.18         \n",
            "httplib2                      0.17.4         \n",
            "httplib2shim                  0.0.3          \n",
            "humanize                      0.5.1          \n",
            "hyperopt                      0.1.2          \n",
            "ideep4py                      2.0.0.post3    \n",
            "idna                          2.10           \n",
            "image                         1.5.33         \n",
            "imageio                       2.4.1          \n",
            "imagesize                     1.2.0          \n",
            "imbalanced-learn              0.4.3          \n",
            "imblearn                      0.0            \n",
            "imgaug                        0.2.9          \n",
            "importlib-metadata            2.0.0          \n",
            "importlib-resources           3.3.0          \n",
            "imutils                       0.5.3          \n",
            "inflect                       2.1.0          \n",
            "iniconfig                     1.1.1          \n",
            "intel-openmp                  2020.0.133     \n",
            "intervaltree                  2.1.0          \n",
            "ipykernel                     4.10.1         \n",
            "ipython                       5.5.0          \n",
            "ipython-genutils              0.2.0          \n",
            "ipython-sql                   0.3.9          \n",
            "ipywidgets                    7.5.1          \n",
            "itsdangerous                  1.1.0          \n",
            "jax                           0.2.6          \n",
            "jaxlib                        0.1.57+cuda101 \n",
            "jdcal                         1.4.1          \n",
            "jedi                          0.17.2         \n",
            "jieba                         0.42.1         \n",
            "Jinja2                        2.11.2         \n",
            "joblib                        0.17.0         \n",
            "jpeg4py                       0.1.4          \n",
            "jsonschema                    2.6.0          \n",
            "jupyter                       1.0.0          \n",
            "jupyter-client                5.3.5          \n",
            "jupyter-console               5.2.0          \n",
            "jupyter-core                  4.7.0          \n",
            "jupyterlab-pygments           0.1.2          \n",
            "kaggle                        1.5.9          \n",
            "kapre                         0.1.3.1        \n",
            "Keras                         2.4.3          \n",
            "Keras-Preprocessing           1.1.2          \n",
            "keras-vis                     0.4.1          \n",
            "kiwisolver                    1.3.1          \n",
            "knnimpute                     0.1.0          \n",
            "korean-lunar-calendar         0.2.1          \n",
            "librosa                       0.6.3          \n",
            "lightgbm                      2.2.3          \n",
            "llvmlite                      0.31.0         \n",
            "lmdb                          0.99           \n",
            "lucid                         0.3.8          \n",
            "LunarCalendar                 0.0.9          \n",
            "lxml                          4.2.6          \n",
            "Markdown                      3.3.3          \n",
            "MarkupSafe                    1.1.1          \n",
            "matplotlib                    3.2.2          \n",
            "matplotlib-venn               0.11.6         \n",
            "missingno                     0.4.2          \n",
            "mistune                       0.8.4          \n",
            "mizani                        0.6.0          \n",
            "mkl                           2019.0         \n",
            "mlxtend                       0.14.0         \n",
            "more-itertools                8.6.0          \n",
            "moviepy                       0.2.3.5        \n",
            "mpmath                        1.1.0          \n",
            "msgpack                       1.0.0          \n",
            "multiprocess                  0.70.11.1      \n",
            "multitasking                  0.0.9          \n",
            "murmurhash                    1.0.4          \n",
            "music21                       5.5.0          \n",
            "natsort                       5.5.0          \n",
            "nbclient                      0.5.1          \n",
            "nbconvert                     5.6.1          \n",
            "nbformat                      5.0.8          \n",
            "nest-asyncio                  1.4.3          \n",
            "networkx                      2.5            \n",
            "nibabel                       3.0.2          \n",
            "nltk                          3.2.5          \n",
            "notebook                      5.3.1          \n",
            "np-utils                      0.5.12.1       \n",
            "numba                         0.48.0         \n",
            "numexpr                       2.7.1          \n",
            "numpy                         1.18.5         \n",
            "nvidia-ml-py3                 7.352.0        \n",
            "oauth2client                  4.1.3          \n",
            "oauthlib                      3.1.0          \n",
            "okgrade                       0.4.3          \n",
            "opencv-contrib-python         4.1.2.30       \n",
            "opencv-python                 4.1.2.30       \n",
            "openpyxl                      2.5.9          \n",
            "opt-einsum                    3.3.0          \n",
            "osqp                          0.6.1          \n",
            "packaging                     20.4           \n",
            "palettable                    3.3.0          \n",
            "pandas                        1.1.4          \n",
            "pandas-datareader             0.9.0          \n",
            "pandas-gbq                    0.13.3         \n",
            "pandas-profiling              1.4.1          \n",
            "pandocfilters                 1.4.3          \n",
            "panel                         0.9.7          \n",
            "param                         1.10.0         \n",
            "parso                         0.7.1          \n",
            "pathlib                       1.0.1          \n",
            "patsy                         0.5.1          \n",
            "pexpect                       4.8.0          \n",
            "pickleshare                   0.7.5          \n",
            "Pillow                        7.0.0          \n",
            "pip                           19.3.1         \n",
            "pip-tools                     4.5.1          \n",
            "plac                          1.1.3          \n",
            "plotly                        4.4.1          \n",
            "plotnine                      0.6.0          \n",
            "pluggy                        0.7.1          \n",
            "portpicker                    1.3.1          \n",
            "prefetch-generator            1.0.1          \n",
            "preshed                       3.0.4          \n",
            "prettytable                   2.0.0          \n",
            "progressbar2                  3.38.0         \n",
            "prometheus-client             0.9.0          \n",
            "promise                       2.3            \n",
            "prompt-toolkit                1.0.18         \n",
            "protobuf                      3.12.4         \n",
            "psutil                        5.4.8          \n",
            "psycopg2                      2.7.6.1        \n",
            "ptyprocess                    0.6.0          \n",
            "py                            1.9.0          \n",
            "pyarrow                       0.14.1         \n",
            "pyasn1                        0.4.8          \n",
            "pyasn1-modules                0.2.8          \n",
            "pycocotools                   2.0.2          \n",
            "pycparser                     2.20           \n",
            "pyct                          0.4.8          \n",
            "pydata-google-auth            1.1.0          \n",
            "pydot                         1.3.0          \n",
            "pydot-ng                      2.0.0          \n",
            "pydotplus                     2.0.2          \n",
            "PyDrive                       1.3.1          \n",
            "pyemd                         0.5.1          \n",
            "pyglet                        1.5.0          \n",
            "Pygments                      2.6.1          \n",
            "pygobject                     3.26.1         \n",
            "pymc3                         3.7            \n",
            "PyMeeus                       0.3.7          \n",
            "pymongo                       3.11.1         \n",
            "pymystem3                     0.2.0          \n",
            "PyOpenGL                      3.1.5          \n",
            "pyparsing                     2.4.7          \n",
            "pyrsistent                    0.17.3         \n",
            "pysndfile                     1.3.8          \n",
            "PySocks                       1.7.1          \n",
            "pystan                        2.19.1.1       \n",
            "pytest                        3.6.4          \n",
            "python-apt                    1.6.5+ubuntu0.3\n",
            "python-chess                  0.23.11        \n",
            "python-dateutil               2.8.1          \n",
            "python-louvain                0.14           \n",
            "python-slugify                4.0.1          \n",
            "python-utils                  2.4.0          \n",
            "pytz                          2018.9         \n",
            "pyviz-comms                   0.7.6          \n",
            "PyWavelets                    1.1.1          \n",
            "PyYAML                        3.13           \n",
            "pyzmq                         20.0.0         \n",
            "qtconsole                     5.0.1          \n",
            "QtPy                          1.9.0          \n",
            "regex                         2019.12.20     \n",
            "requests                      2.23.0         \n",
            "requests-oauthlib             1.3.0          \n",
            "resampy                       0.2.2          \n",
            "retrying                      1.3.3          \n",
            "rpy2                          3.2.7          \n",
            "rsa                           4.6            \n",
            "scikit-image                  0.16.2         \n",
            "scikit-learn                  0.22.2.post1   \n",
            "scipy                         1.4.1          \n",
            "screen-resolution-extra       0.0.0          \n",
            "scs                           2.1.2          \n",
            "seaborn                       0.11.0         \n",
            "Send2Trash                    1.5.0          \n",
            "setuptools                    50.3.2         \n",
            "setuptools-git                1.2            \n",
            "Shapely                       1.7.1          \n",
            "simplegeneric                 0.8.1          \n",
            "six                           1.15.0         \n",
            "sklearn                       0.0            \n",
            "sklearn-pandas                1.8.0          \n",
            "slugify                       0.0.1          \n",
            "smart-open                    3.0.0          \n",
            "snowballstemmer               2.0.0          \n",
            "sortedcontainers              2.3.0          \n",
            "spacy                         2.2.4          \n",
            "Sphinx                        1.8.5          \n",
            "sphinxcontrib-serializinghtml 1.1.4          \n",
            "sphinxcontrib-websupport      1.2.4          \n",
            "SQLAlchemy                    1.3.20         \n",
            "sqlparse                      0.4.1          \n",
            "srsly                         1.0.4          \n",
            "statsmodels                   0.10.2         \n",
            "sympy                         1.1.1          \n",
            "tables                        3.4.4          \n",
            "tabulate                      0.8.7          \n",
            "tblib                         1.7.0          \n",
            "tensorboard                   2.3.0          \n",
            "tensorboard-plugin-wit        1.7.0          \n",
            "tensorboardcolab              0.0.22         \n",
            "tensorflow                    2.3.0          \n",
            "tensorflow-addons             0.8.3          \n",
            "tensorflow-datasets           4.0.1          \n",
            "tensorflow-estimator          2.3.0          \n",
            "tensorflow-gcs-config         2.3.0          \n",
            "tensorflow-hub                0.10.0         \n",
            "tensorflow-metadata           0.25.0         \n",
            "tensorflow-privacy            0.2.2          \n",
            "tensorflow-probability        0.11.0         \n",
            "termcolor                     1.1.0          \n",
            "terminado                     0.9.1          \n",
            "testpath                      0.4.4          \n",
            "text-unidecode                1.3            \n",
            "textblob                      0.15.3         \n",
            "textgenrnn                    1.4.1          \n",
            "Theano                        1.0.5          \n",
            "thinc                         7.4.0          \n",
            "tifffile                      2020.9.3       \n",
            "toml                          0.10.2         \n",
            "toolz                         0.11.1         \n",
            "torch                         1.7.0+cu101    \n",
            "torchsummary                  1.5.1          \n",
            "torchtext                     0.3.1          \n",
            "torchvision                   0.8.1+cu101    \n",
            "tornado                       5.1.1          \n",
            "tqdm                          4.41.1         \n",
            "traitlets                     4.3.3          \n",
            "tweepy                        3.6.0          \n",
            "typeguard                     2.7.1          \n",
            "typing-extensions             3.7.4.3        \n",
            "tzlocal                       1.5.1          \n",
            "umap-learn                    0.4.6          \n",
            "uritemplate                   3.0.1          \n",
            "urllib3                       1.24.3         \n",
            "vega-datasets                 0.8.0          \n",
            "wasabi                        0.8.0          \n",
            "wcwidth                       0.2.5          \n",
            "webencodings                  0.5.1          \n",
            "Werkzeug                      1.0.1          \n",
            "wheel                         0.35.1         \n",
            "widgetsnbextension            3.5.1          \n",
            "wordcloud                     1.5.0          \n",
            "wrapt                         1.12.1         \n",
            "xarray                        0.15.1         \n",
            "xgboost                       0.90           \n",
            "xkit                          0.0.0          \n",
            "xlrd                          1.1.0          \n",
            "xlwt                          1.3.0          \n",
            "yellowbrick                   0.9.1          \n",
            "zict                          2.0.0          \n",
            "zipp                          3.4.0          \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1mRG9mlM3z69"
      },
      "source": [
        "Подключение к Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kzB9Qsf7QeUk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9d7eb29-738d-4624-a575-572d428123ce"
      },
      "source": [
        "#подключение к гугл диску\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VqRu97X9S9A9"
      },
      "source": [
        "import os\n",
        "\n",
        "path = '/content/drive/My Drive/SeqGAN/'\n",
        "os.chdir(path)"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CInBwn4iUsK7"
      },
      "source": [
        "Объявление параметров по умолчанию"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QbtQOz8UUn0Q"
      },
      "source": [
        "from __future__ import print_function\n",
        "from math import ceil\n",
        "import numpy as np\n",
        "import sys\n",
        "\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "\n",
        "import torch.autograd as autograd\n",
        "import torch.nn.functional as F\n",
        "import torch.nn.init as init\n",
        "\n",
        "import helpers # перетащить функции в код\n",
        "\n",
        "DATASET = 'stihi_ru' # название выборки данных список выборок: ['stihi_ru', 'coco_image_captions']\n",
        "CUDA = True # использование cuda (gpu/tpu): True/False\n",
        "BATCH_SIZE = 1000 # количество примеров в партии/батче\n",
        "MLE_TRAIN_EPOCHS = 30 # количество эпох при обучении генератора на основе MLE\n",
        "DIS_TRAIN_ITERATIONS = 300 # количество итераций при обучении дискриминатора (итерации содержит несколько эпох, на каждой итерации данные для обучения обновляются)\n",
        "DIS_TRAIN_EPOCHS = 1 # количество эпох в одной итерации обучения дискриминатора\n",
        "ADV_TRAIN_EPOCHS = 25 # количество эпох при обучении генератора на основе соревновательного обучения / обучения с подкреплением\n",
        "POS_NEG_SAMPLES = 10000\n",
        "\n",
        "GEN_EMBEDDING_DIM = 150 # ширина слоя Embedding генератора\n",
        "GEN_HIDDEN_DIM = 150 # количество нейронов в слоях генератора\n",
        "DIS_EMBEDDING_DIM = 150 # ширина слоя Embedding дискриминатора\n",
        "DIS_HIDDEN_DIM = 150 # количество нейронов в слоях дискриминатора\n",
        "\n",
        "# параметры START_LETTER, VOCAB_SIZE, MAX_SEQ_LEN и FILE_PATHS задаются автоматически ниже\n",
        "START_LETTER = None #! стартовое слово (слово которое подается первым на нейронную сеть генератор)\n",
        "MAX_SEQ_LEN = None # длина генерируемого примера\n",
        "VOCAB_SIZE = None # количество слов в словаре\n",
        "FILE_PATHS = None # пути к файлам набора данных\n",
        "CLOSING_WORD = None # заключительное слово / слово заполнитель ставящееся в конце предложения\n",
        "\n",
        "# выбор набора данных и инициализация соответствующих глобальных параметров\n",
        "if DATASET == 'stihi_ru': # выборка с русскими стихами с сайта stihi_ru (длина примера 10 слов, размер словаря 5 000 слов)\n",
        "  START_LETTER = 0\n",
        "  MAX_SEQ_LEN = 10\n",
        "  VOCAB_SIZE = 5000\n",
        "  CLOSING_WORD = 4999#4997\n",
        "  FILE_PATHS = {'train': r'datasets/stihi_ru/stihi_ru_realtrain_cotra.txt', 'test': r'datasets/stihi_ru/stihi_ru_realtest_coco.txt',\n",
        "                'vocab': r'datasets/stihi_ru/stihi_ru_vocab_cotra.pkl', 'saved_models': r'saved_models/stihi_ru'}\n",
        "elif DATASET == 'coco_image_captions': # выборка COCO Image Captions (длина примера 20 слов, размер словаря 4980 слов)\n",
        "  START_LETTER = 0\n",
        "  MAX_SEQ_LEN = 20\n",
        "  VOCAB_SIZE = 4838\n",
        "  CLOSING_WORD = 1814\n",
        "  FILE_PATHS = {'train': r'datasets/coco_image_captions/coco_image_captions_train.txt', 'test': r'datasets/coco_image_captions/coco_image_captions_test.txt',\n",
        "                'vocab': r'datasets/coco_image_captions/coco_image_captions_vocab_cotra_test.pkl', 'saved_models': r'saved_models/coco_image_captions'}"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-nZvyD7AVMWl"
      },
      "source": [
        "Инициализация генераторов случайных чисел."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fXQAcf0yVL6Q"
      },
      "source": [
        "# инициализация генераторов случайных чисел.\n",
        "torch.random.manual_seed(50)\n",
        "np.random.seed(50)\n",
        "#системный рандом!!!"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D22oWzXQ3-A-"
      },
      "source": [
        "Объявление класса Генератора"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NWxd3fgqvLbz"
      },
      "source": [
        "class Generator(nn.Module):\n",
        "\n",
        "  def __init__(self, embedding_dim, hidden_dim, vocab_size, max_seq_len, gpu=False):\n",
        "    super(Generator, self).__init__()\n",
        "    self.hidden_dim = hidden_dim # количество элементов на скрытом слое\n",
        "    self.embedding_dim = embedding_dim # размер слоя embedding\n",
        "    self.max_seq_len = max_seq_len # длина генерируемых примеров\n",
        "    self.vocab_size = vocab_size # размер словаря использующегося при генерации\n",
        "    self.gpu = gpu # использование cuda (True/False)\n",
        "    self.lstm_num_layers = 1 # количество LSTM слоев\n",
        "\n",
        "    self.embeddings = nn.Embedding(vocab_size, embedding_dim) # объявление слоя embeddings\n",
        "    self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers=self.lstm_num_layers) # объявление LSTM слоев\n",
        "    self.lstm2out = nn.Linear(hidden_dim, vocab_size) # объявление выходного слоя\n",
        "\n",
        "  def init_hidden(self, batch_size=1):\n",
        "    # инициализация состояния LSTM слоев\n",
        "    h = autograd.Variable(torch.zeros(self.lstm_num_layers, batch_size, self.hidden_dim)) \n",
        "    c = autograd.Variable(torch.zeros(self.lstm_num_layers, batch_size, self.hidden_dim))\n",
        "\n",
        "    if self.gpu:\n",
        "        return h.cuda(), c.cuda()\n",
        "    else:\n",
        "        return h, c\n",
        "\n",
        "  def forward(self, inp, hidden, c):\n",
        "    \"\"\"\n",
        "    Embeds input and applies LSTM one token at a time (seq_len = 1)\n",
        "    \"\"\"\n",
        "    # input dim                                             # batch_size\n",
        "    emb = self.embeddings(inp)                              # batch_size x embedding_dim\n",
        "    emb = emb.view(1, -1, self.embedding_dim)               # 1 x batch_size x embedding_dim\n",
        "    out, (hidden, c) = self.lstm(emb, (hidden, c))                    # 1 x batch_size x hidden_dim (out)\n",
        "    out = self.lstm2out(out.view(-1, self.hidden_dim))       # batch_size x vocab_size\n",
        "    out = F.log_softmax(out, dim=1)\n",
        "    return out, hidden, c\n",
        "\n",
        "  def sample(self, num_samples, start_letter=0, degree=1):\n",
        "    \"\"\"\n",
        "    Samples the network and returns num_samples samples of length max_seq_len.\n",
        "\n",
        "    Outputs: samples, hidden\n",
        "        - samples: num_samples x max_seq_length (a sampled sequence in each row)\n",
        "    \"\"\"\n",
        "\n",
        "    samples = torch.zeros(num_samples, self.max_seq_len).type(torch.LongTensor)\n",
        "\n",
        "    h, c = self.init_hidden(num_samples)\n",
        "    inp = autograd.Variable(torch.LongTensor([start_letter]*num_samples))\n",
        "    if self.gpu:\n",
        "        samples = samples.cuda()\n",
        "        inp = inp.cuda()\n",
        "\n",
        "    for i in range(self.max_seq_len):\n",
        "        out, h, c = self.forward(inp, h, c)               # out: num_samples x vocab_size\n",
        "        out = torch.exp(out)**degree\n",
        "        out = torch.multinomial(out, 1)  # num_samples x 1 (sampling from each row)\n",
        "        samples[:, i] = out.view(-1).data\n",
        "\n",
        "        inp = out.view(-1)\n",
        "\n",
        "    return samples\n",
        "\n",
        "  def batchNLLLoss(self, inp, target):\n",
        "    \"\"\"\n",
        "    Returns the NLL Loss for predicting target sequence.\n",
        "\n",
        "    Inputs: inp, target\n",
        "        - inp: batch_size x seq_len\n",
        "        - target: batch_size x seq_len\n",
        "\n",
        "        inp should be target with <s> (start letter) prepended\n",
        "    \"\"\"\n",
        "\n",
        "    loss_fn = nn.NLLLoss()\n",
        "    batch_size, seq_len = inp.size()\n",
        "    inp = inp.permute(1, 0)           # seq_len x batch_size\n",
        "    target = target.permute(1, 0)     # seq_len x batch_size\n",
        "    h, c = self.init_hidden(batch_size)\n",
        "\n",
        "    loss = 0\n",
        "    for i in range(seq_len):\n",
        "        out, h, c = self.forward(inp[i], h, c)\n",
        "        loss += loss_fn(out, target[i])\n",
        "\n",
        "    return loss     # per batch\n",
        "\n",
        "  def batchPGLoss(self, inp, target, reward):\n",
        "    \"\"\"\n",
        "    Returns a pseudo-loss that gives corresponding policy gradients (on calling .backward()).\n",
        "    Inspired by the example in http://karpathy.github.io/2016/05/31/rl/\n",
        "\n",
        "    Inputs: inp, target\n",
        "        - inp: batch_size x seq_len\n",
        "        - target: batch_size x seq_len\n",
        "        - reward: batch_size (discriminator reward for each sentence, applied to each token of the corresponding\n",
        "                  sentence)\n",
        "\n",
        "        inp should be target with <s> (start letter) prepended\n",
        "    \"\"\"\n",
        "\n",
        "    batch_size, seq_len = inp.size()\n",
        "    inp = inp.permute(1, 0)          # seq_len x batch_size\n",
        "    target = target.permute(1, 0)    # seq_len x batch_size\n",
        "    h, c = self.init_hidden(batch_size)\n",
        "\n",
        "    loss = 0\n",
        "    for i in range(seq_len):\n",
        "        out, h, c = self.forward(inp[i], h, c)\n",
        "        # TODO: should h be detached from graph (.detach())?\n",
        "        for j in range(batch_size):\n",
        "            loss += -out[j][target.data[i][j]]*reward[j]#     # log(P(y_t|Y_1:Y_{t-1})) * Q\n",
        "\n",
        "    return loss/batch_size"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ut2px_RD4HIi"
      },
      "source": [
        "Объявяление класса Дискриминатора"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zUIXW8JMzAWk"
      },
      "source": [
        "class Discriminator(nn.Module):\n",
        "\n",
        "    def __init__(self, embedding_dim, hidden_dim, vocab_size, max_seq_len, gpu=False, dropout=0.2):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.hidden_dim = hidden_dim # размер скрытого слоя\n",
        "        self.embedding_dim = embedding_dim # ширина слоя embedding\n",
        "        self.max_seq_len = max_seq_len # длина входного примера\n",
        "        self.gpu = gpu # использование cuda (True/False)\n",
        "\n",
        "        self.embeddings = nn.Embedding(vocab_size, embedding_dim) # объявление слоя Embedding\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers=3, bidirectional=True, dropout=dropout) # объявление LSTM слоев\n",
        "\n",
        "        self.lstm2hidden = nn.Linear(2*3*hidden_dim, hidden_dim) # объявление скрытого слоя\n",
        "        # self.lstm2hidden = nn.Linear(max_seq_len*hidden_dim*2, hidden_dim) # объявление скрытого слоя\n",
        "\n",
        "        self.dropout_linear = nn.Dropout(p=dropout)\n",
        "        self.hidden2out = nn.Linear(hidden_dim, 1) # объявление выходного слоя\n",
        "\n",
        "    def init_hidden(self, batch_size):\n",
        "        # инициализация LSTM слоев\n",
        "        h = autograd.Variable(torch.zeros(2*3*1, batch_size, self.hidden_dim))\n",
        "        c = autograd.Variable(torch.zeros(2*3*1, batch_size, self.hidden_dim))\n",
        "\n",
        "        if self.gpu:\n",
        "            return h.cuda(), c.cuda()\n",
        "        else:\n",
        "            return h, c\n",
        "\n",
        "    def forward(self, input, hidden, c):\n",
        "        # input dim                                                # batch_size x seq_len\n",
        "        # print(input.shape)\n",
        "        emb = self.embeddings(input)                               # batch_size x seq_len x embedding_dim\n",
        "        # print(emb.shape)\n",
        "        emb = emb.permute(1, 0, 2)                                 # seq_len x batch_size x embedding_dim\n",
        "        # print(emb.shape)\n",
        "        out_lstm, (hidden, c) = self.lstm(emb, (hidden, c))                          # 4 x batch_size x hidden_dim\n",
        "\n",
        "        hidden = hidden.permute(1, 0, 2).contiguous()              # batch_size x 4 x hidden_dim\n",
        "        # hidden = out_lstm\n",
        "        # print(hidden.shape, hidden.view(-1, self.max_seq_len*self.hidden_dim).shape)\n",
        "        # print(hidden.permute(1, 0, 2).contiguous().shape, hidden.permute(1, 0, 2).contiguous().view(-1, self.max_seq_len*self.hidden_dim*2).shape)\n",
        "\n",
        "        out = self.lstm2hidden(hidden.view(-1, 6*self.hidden_dim))  # batch_size x 4*hidden_dim\n",
        "        # out = self.lstm2hidden(hidden.view(-1, self.max_seq_len*self.hidden_dim*2))  # batch_size x 4*hidden_dim\n",
        "        \n",
        "        out = torch.relu(out)\n",
        "        # out = out * torch.sigmoid(0.1 * out) # функция активации Swish: x * sigmoid(b*x)\n",
        "        out = self.dropout_linear(out)\n",
        "        out = self.hidden2out(out)                                 # batch_size x 1\n",
        "        out = torch.sigmoid(out)\n",
        "        return out\n",
        "\n",
        "    def batchClassify(self, inp):\n",
        "        \"\"\"\n",
        "        Classifies a batch of sequences.\n",
        "\n",
        "        Inputs: inp\n",
        "            - inp: batch_size x seq_len\n",
        "\n",
        "        Returns: out\n",
        "            - out: batch_size ([0,1] score)\n",
        "        \"\"\"\n",
        "\n",
        "        h, c = self.init_hidden(inp.size()[0])\n",
        "        out = self.forward(inp, h, c)\n",
        "        return out.view(-1)\n",
        "\n",
        "    def batchBCELoss(self, inp, target):\n",
        "        \"\"\"\n",
        "        Returns Binary Cross Entropy Loss for discriminator.\n",
        "\n",
        "         Inputs: inp, target\n",
        "            - inp: batch_size x seq_len\n",
        "            - target: batch_size (binary 1/0)\n",
        "        \"\"\"\n",
        "\n",
        "        loss_fn = nn.BCELoss()\n",
        "        h, c = self.init_hidden(inp.size()[0])\n",
        "        out = self.forward(inp, h, c)\n",
        "        return loss_fn(out, target)"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "czr-pzJe4KTW"
      },
      "source": [
        "Объявление функций возвращающих данные"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cKQ2qmEm3xZ9"
      },
      "source": [
        "# функция генерации реалиных данных\n",
        "def sampler_example(batch_size):\n",
        "  x = data_file_train[np.random.randint(0, len(data_file_train), batch_size)]\n",
        "  y = np.concatenate([x[:, 1:], np.zeros([batch_size, 1])+VOCAB_SIZE-2], axis=-1)\n",
        "  return x, y\n",
        "\n",
        "# функция генерации реалиных данных\n",
        "def sampler_example_test(batch_size):\n",
        "  x = data_file_test[np.random.randint(0, len(data_file_test), batch_size)]\n",
        "  y = np.concatenate([x[:, 1:], np.zeros([batch_size, 1])+VOCAB_SIZE-2], axis=-1)\n",
        "  return x, y"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-YpbTp_a5L1W"
      },
      "source": [
        "Функции обучения генератора"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jx23T6ef5MTA"
      },
      "source": [
        "# функция обучения генератора на основе MLE\n",
        "def train_generator_MLE(gen, gen_opt, real_samples_train, real_samples_test, epochs):\n",
        "    \"\"\"\n",
        "    Max Likelihood Pretraining for the generator\n",
        "    \"\"\"\n",
        "    for epoch in range(epochs):\n",
        "        print('epoch %d : ' % (epoch + 1), end='')\n",
        "        sys.stdout.flush()\n",
        "        total_loss = 0\n",
        "\n",
        "        # обучение\n",
        "        for i in range(0, len(real_samples_train), BATCH_SIZE):\n",
        "            inp_train, target_train = helpers.prepare_generator_batch(real_samples_train[i:i + BATCH_SIZE], start_letter=START_LETTER,\n",
        "                                                          gpu=CUDA)\n",
        "            gen_opt.zero_grad()\n",
        "            loss = gen.batchNLLLoss(inp_train, target_train)\n",
        "            loss.backward()\n",
        "            gen_opt.step()\n",
        "\n",
        "            total_loss += loss.data.item()\n",
        "\n",
        "            if (i / BATCH_SIZE) % ceil(\n",
        "                            ceil(len(real_samples_train) / float(BATCH_SIZE)) / 10.) == 0:  # roughly every 10% of an epoch\n",
        "                print('.', end='')\n",
        "                sys.stdout.flush()\n",
        "\n",
        "        # each loss in a batch is loss per sample\n",
        "        total_loss = total_loss / ceil(len(real_samples_train) / float(BATCH_SIZE)) / MAX_SEQ_LEN\n",
        "        print(' average_train_NLL = %.4f' % total_loss, end='')\n",
        "\n",
        "        # тестирование\n",
        "        test_loss = 0\n",
        "\n",
        "        for i in range(0, len(real_samples_test), BATCH_SIZE):\n",
        "            inp_test, target_test = helpers.prepare_generator_batch(real_samples_test[i:i + BATCH_SIZE], start_letter=START_LETTER,\n",
        "                                                              gpu=CUDA)\n",
        "            loss = gen.batchNLLLoss(inp_test, target_test)\n",
        "            test_loss += loss.data.item()\n",
        "        test_loss = test_loss / ceil(len(real_samples_test) / float(BATCH_SIZE)) / MAX_SEQ_LEN\n",
        "        print(' average_test_NLL = %.4f' % test_loss)\n",
        "\n",
        "def test_mle(gen, real_samples_train, real_samples_test):\n",
        "  '''\n",
        "  Тестирование генератора на обучающей и тестовой выборках.\n",
        "  '''\n",
        "  # тестирование на обучающей\n",
        "  test_loss = 0\n",
        "  for i in range(0, len(real_samples_train), BATCH_SIZE):\n",
        "      inp_test, target_test = helpers.prepare_generator_batch(real_samples_train[i:i + BATCH_SIZE], start_letter=START_LETTER,\n",
        "                                                        gpu=CUDA)\n",
        "      loss = gen.batchNLLLoss(inp_test, target_test)\n",
        "      test_loss += loss.data.item()\n",
        "  test_loss = test_loss / ceil(len(real_samples_train) / float(BATCH_SIZE)) / MAX_SEQ_LEN\n",
        "  print('average_train_NLL = %.4f' % test_loss, end='')\n",
        "\n",
        "  # тестирование на тестовой\n",
        "  test_loss = 0\n",
        "  for i in range(0, len(real_samples_test), BATCH_SIZE):\n",
        "      inp_test, target_test = helpers.prepare_generator_batch(real_samples_test[i:i + BATCH_SIZE], start_letter=START_LETTER,\n",
        "                                                        gpu=CUDA)\n",
        "      loss = gen.batchNLLLoss(inp_test, target_test)\n",
        "      test_loss += loss.data.item()\n",
        "  test_loss = test_loss / ceil(len(real_samples_test) / float(BATCH_SIZE)) / MAX_SEQ_LEN\n",
        "  print(' average_test_NLL = %.4f' % test_loss)\n",
        "\n",
        "# функция обучения генератора на основе обучения с подкреплением RL\n",
        "def train_generator_PG(gen, gen_opt, dis, num_batches): # !переименовать!\n",
        "    \"\"\"\n",
        "    The generator is trained using policy gradients, using the reward from the discriminator.\n",
        "    Training is done for num_batches batches.\n",
        "    \"\"\"\n",
        "\n",
        "    for batch in range(num_batches):\n",
        "        s = gen.sample(BATCH_SIZE*4)        # 64 works best\n",
        "        inp, target = helpers.prepare_generator_batch(s, start_letter=START_LETTER, gpu=CUDA)\n",
        "        rewards = dis.batchClassify(target)\n",
        "\n",
        "        gen_opt.zero_grad()\n",
        "        pg_loss = gen.batchPGLoss(inp, target, rewards)\n",
        "        pg_loss.backward()\n",
        "        gen_opt.step()\n",
        "    print()"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bx5xFCA35pKw"
      },
      "source": [
        "Функция обучения дискриминатора"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bSi-RHh45pk3"
      },
      "source": [
        "# функция обучения дискриминатора\n",
        "def train_discriminator(discriminator, dis_opt, real_data_samples, generator, d_steps, epochs):\n",
        "    \"\"\"\n",
        "    Training the discriminator on real_data_samples (positive) and generated samples from generator (negative).\n",
        "    Samples are drawn d_steps times, and the discriminator is trained for epochs epochs.\n",
        "    \"\"\"\n",
        "\n",
        "    # generating a small validation set before training\n",
        "    pos_val = real_data_samples[np.random.randint(0, len(real_data_samples), 500)] #sampler_example(250)\n",
        "    neg_val = generator.sample(500)\n",
        "    val_inp, val_target = helpers.prepare_discriminator_data(pos_val, neg_val, gpu=CUDA)\n",
        "\n",
        "    for d_step in range(d_steps):\n",
        "        s = helpers.batchwise_sample(generator, POS_NEG_SAMPLES, BATCH_SIZE)\n",
        "        dis_inp, dis_target = helpers.prepare_discriminator_data(real_data_samples, s, gpu=CUDA)\n",
        "        val_pred = discriminator.batchClassify(val_inp)\n",
        "        print('ДО ОБУЧЕНИЯ: val_acc = %.4f' % (\n",
        "            torch.sum((val_pred>0.5)==(val_target>0.5)).data.item()/1000.))\n",
        "        for epoch in range(epochs):\n",
        "            print('d-step %d epoch %d : ' % (d_step + 1, epoch + 1), end='')\n",
        "            sys.stdout.flush()\n",
        "            total_loss = 0\n",
        "            total_acc = 0\n",
        "\n",
        "            for i in range(0, 2 * POS_NEG_SAMPLES, BATCH_SIZE):\n",
        "                inp, target = dis_inp[i:i + BATCH_SIZE], dis_target[i:i + BATCH_SIZE]\n",
        "                dis_opt.zero_grad()\n",
        "                out = discriminator.batchClassify(inp)\n",
        "                loss_fn = nn.BCELoss()\n",
        "                loss = loss_fn(out, target)\n",
        "                loss.backward()\n",
        "                dis_opt.step()\n",
        "\n",
        "                total_loss += loss.data.item()\n",
        "                total_acc += torch.sum((out>0.5)==(target>0.5)).data.item()\n",
        "\n",
        "                if (i / BATCH_SIZE) % ceil(ceil(2 * POS_NEG_SAMPLES / float(\n",
        "                        BATCH_SIZE)) / 10.) == 0:  # roughly every 10% of an epoch\n",
        "                    print('.', end='')\n",
        "                    sys.stdout.flush()\n",
        "\n",
        "            total_loss /= ceil(2 * POS_NEG_SAMPLES / float(BATCH_SIZE))\n",
        "            total_acc /= float(2 * POS_NEG_SAMPLES)\n",
        "\n",
        "            val_pred = discriminator.batchClassify(val_inp)\n",
        "            print(' average_loss = %.4f, train_acc = %.4f, val_acc = %.4f' % (\n",
        "                total_loss, total_acc, torch.sum((val_pred>0.5)==(val_target>0.5)).data.item()/1000.))"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OBuFdlsb55XU"
      },
      "source": [
        "Функция оценки качества генерации текста"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P_D3lTI654PU"
      },
      "source": [
        "# оценка качества по BLEU метрике\n",
        "from nltk.translate.bleu_score import SmoothingFunction\n",
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "from datetime import datetime\n",
        "import nltk\n",
        "import random\n",
        "from scipy import stats\n",
        "\n",
        "# функция оценки качества генерации текста по метрике BLEU\n",
        "def BLEU(reference_sample, test_sample, print_iteration=100, flag_print=True):\n",
        "  if flag_print:\n",
        "    print(\"--- --- ---\\nStart BLEU\")\n",
        "  pad = CLOSING_WORD\n",
        "  #################################################\n",
        "  reference = []\n",
        "  for line in reference_sample:\n",
        "    candidate = []\n",
        "    for i in line:\n",
        "      if i == pad:\n",
        "        break\n",
        "      candidate.append(i)\n",
        "\n",
        "    reference.append(candidate)\n",
        "  #################################################\n",
        "  hypothesis_list_leakgan = []\n",
        "  for line in test_sample:\n",
        "    while line[-1] == str(pad):\n",
        "      line.remove(str(pad))\n",
        "    hypothesis_list_leakgan.append(line)\n",
        "  #################################################\n",
        "  random.shuffle(hypothesis_list_leakgan)\n",
        "  #################################################\n",
        "\n",
        "  smoothing_function = SmoothingFunction().method1\n",
        "\n",
        "  mass_bleu = []\n",
        "  for ngram in range(2,6):\n",
        "      weight = tuple((1. / ngram for _ in range(ngram)))\n",
        "      bleu_leakgan = []\n",
        "      bleu_supervise = []\n",
        "      bleu_base2 = []\n",
        "      num = 0\n",
        "      for h in hypothesis_list_leakgan:\n",
        "          BLEUscore = nltk.translate.bleu_score.sentence_bleu(reference, h, weight, smoothing_function = smoothing_function)\n",
        "          num += 1\n",
        "          bleu_leakgan.append(BLEUscore)\n",
        "\n",
        "          if num%print_iteration == 0 and flag_print:\n",
        "            print(ngram, num, sum(bleu_leakgan)/len(bleu_leakgan))\n",
        "          \n",
        "      mass_bleu.append(1.0 * sum(bleu_leakgan) / len(bleu_leakgan))\n",
        "      if flag_print:\n",
        "        print('--- --- ---')\n",
        "        print(len(weight), '-gram BLEU score : ', 1.0 * sum(bleu_leakgan) / len(bleu_leakgan), \"\\n\")\n",
        "  return mass_bleu"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XlNNlpWxIEM0"
      },
      "source": [
        "Функция сохранения моделей"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "idULo4Q_IC6z"
      },
      "source": [
        "# функция сохранения моделей (сериализация: моделей генератора и дискриминатора, параметров по умолчанию, обучающих данных)\n",
        "def save_models(data_file_tensor_train, gen, dis, gen_optimizer, dis_optimizer, name):\n",
        "  state = {\n",
        "      'default_parameters': {'VOCAB_SIZE': VOCAB_SIZE, 'MAX_SEQ_LEN': MAX_SEQ_LEN, 'GEN_EMBEDDING_DIM': GEN_EMBEDDING_DIM,\n",
        "                             'GEN_HIDDEN_DIM': GEN_HIDDEN_DIM, 'DIS_EMBEDDING_DIM': DIS_EMBEDDING_DIM, 'DIS_HIDDEN_DIM': DIS_HIDDEN_DIM},\n",
        "      'data_file_tensor_train': data_file_tensor_train,\n",
        "      'gen_state_dict': gen.state_dict(),\n",
        "      'dis_state_dict': dis.state_dict(),\n",
        "      'gen_optimizer': gen_optimizer.state_dict(),\n",
        "      'dis_optimizer': dis_optimizer.state_dict(),\n",
        "  }\n",
        "  torch.save(state, name)"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bg9nWuCKHgZQ"
      },
      "source": [
        "Функция загрузки моделей"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iAlKsfNiHUnZ"
      },
      "source": [
        "# функция загрузки моделей (десериализация: моделей генератора и дискриминатора, параметров по умолчанию, обучающих данных)\n",
        "def load_models(name):\n",
        "  if CUDA:\n",
        "    device = torch.device('cuda')\n",
        "  else:\n",
        "    device = torch.device('cpu')\n",
        "\n",
        "  print('state')\n",
        "  state = torch.load(name, map_location=device)\n",
        "\n",
        "  print('default_parameters')\n",
        "  VOCAB_SIZE = state['default_parameters']['VOCAB_SIZE']\n",
        "  MAX_SEQ_LEN = state['default_parameters']['MAX_SEQ_LEN']\n",
        "  GEN_EMBEDDING_DIM = state['default_parameters']['GEN_EMBEDDING_DIM']\n",
        "  GEN_HIDDEN_DIM = state['default_parameters']['GEN_HIDDEN_DIM']\n",
        "  DIS_EMBEDDING_DIM = state['default_parameters']['DIS_EMBEDDING_DIM']\n",
        "  DIS_HIDDEN_DIM = state['default_parameters']['DIS_HIDDEN_DIM']\n",
        "\n",
        "  print('data_file_tensor_train')\n",
        "  data_file_tensor_train = torch.tensor(state['data_file_tensor_train'])\n",
        "\n",
        "  print('Generator')\n",
        "  gen = Generator(GEN_EMBEDDING_DIM, GEN_HIDDEN_DIM, VOCAB_SIZE, MAX_SEQ_LEN, gpu=CUDA)\n",
        "  gen.load_state_dict(state['gen_state_dict'])\n",
        "  gen_optimizer = optim.Adam(gen.parameters(), lr=0.001)\n",
        "  gen_optimizer.load_state_dict(state['gen_optimizer'])\n",
        "\n",
        "  print('Discriminator')\n",
        "  dis = Discriminator(DIS_EMBEDDING_DIM, DIS_HIDDEN_DIM, VOCAB_SIZE, MAX_SEQ_LEN, gpu=CUDA)\n",
        "  dis.load_state_dict(state['dis_state_dict'])\n",
        "  dis_optimizer = optim.Adagrad(dis.parameters())\n",
        "  dis_optimizer.load_state_dict(state['dis_optimizer'])\n",
        "\n",
        "  print('CUDA')\n",
        "  if CUDA:\n",
        "    data_file_tensor_train = data_file_tensor_train.cuda()\n",
        "    gen = gen.cuda()\n",
        "    dis = dis.cuda()\n",
        "  \n",
        "  return [data_file_tensor_train, gen, dis, gen_optimizer, dis_optimizer,\n",
        "          VOCAB_SIZE, MAX_SEQ_LEN, GEN_EMBEDDING_DIM, GEN_HIDDEN_DIM, DIS_EMBEDDING_DIM, DIS_HIDDEN_DIM]"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vorPpC0M65Lv"
      },
      "source": [
        "Загрузка набора данных"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vB8boRQzJ_sb"
      },
      "source": [
        "# загрузка словаря\n",
        "import pickle\n",
        "\n",
        "vocab_file = FILE_PATHS['vocab']\n",
        "word, vocab = pickle.load(open(vocab_file, 'rb'))"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4MmMIx2VQmal",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2fd53209-ae4f-449c-ca8f-c5083844ce46"
      },
      "source": [
        "# загрузка обучающей выборки\n",
        "f = open(FILE_PATHS['train'], 'r')\n",
        "data_file_train = []\n",
        "for line in f:\n",
        "  line = line.replace('\\n', '')\n",
        "  line = line.split()\n",
        "  for i in range(len(line)):\n",
        "    line[i] = int(line[i])\n",
        "  data_file_train.append(line)\n",
        "data_file_train = np.array(data_file_train)[:, :MAX_SEQ_LEN]\n",
        "print(\"Примеров в обучающей выборке: \", len(data_file_train))"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Примеров в обучающей выборке:  70000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QHY_LhDP_o9n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "175c5f9c-b82d-45a7-d45a-93b7f95cf264"
      },
      "source": [
        "# загрузка тестовой выборки\n",
        "f = open(FILE_PATHS['test'], 'r')\n",
        "data_file_test = []\n",
        "for line in f:\n",
        "  line = line.replace('\\n', '')\n",
        "  line = line.split()\n",
        "  for i in range(len(line)):\n",
        "    line[i] = int(line[i])\n",
        "  data_file_test.append(line)\n",
        "data_file_test = np.array(data_file_test)[:, :MAX_SEQ_LEN]\n",
        "print(\"Примеров в тестовой выборке: \", len(data_file_test))"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Примеров в тестовой выборке:  5000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zc9jtz0qaQHO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c01454bf-4577-4c49-9ee7-c1e178f7ebc9"
      },
      "source": [
        "# примеры из обучающей выборки\n",
        "print(\"Примеры из обучающей выборки\")\n",
        "samples = sampler_example(50)[0]\n",
        "output_function = []\n",
        "for samp in samples:\n",
        "  line = [word[x] for x in samp]\n",
        "  line = ' '.join(line)\n",
        "  output_function.append(line)\n",
        "\n",
        "for i, output in enumerate(output_function):\n",
        "  print(\"#\", i, \"\\tПример: \", output)    "
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Примеры из обучающей выборки\n",
            "# 0 \tПример:  будь спокоен за счастье за нежность нашу и тепло \n",
            "# 1 \tПример:  но просить же я могу и желать такого  \n",
            "# 2 \tПример:  ее тебе не удержать и не о чем говорить \n",
            "# 3 \tПример:  ты что то говоришь а мне тепло тепло  \n",
            "# 4 \tПример:  настоящее добро в одном лишь боге больше его нет нигде\n",
            "# 5 \tПример:  я здесь ты там но это не беда  \n",
            "# 6 \tПример:  здесь однажды был я знал что снова буду  \n",
            "# 7 \tПример:  но не все в этой жизни так просто  \n",
            "# 8 \tПример:  а любви всё ж на всех не хватает  \n",
            "# 9 \tПример:  густой исчезла лишь только шелест слышен был вдали  \n",
            "# 10 \tПример:  но с надеждой к богу все к нему в пути\n",
            "# 11 \tПример:  если не буду знать я где ты я знаю ты\n",
            "# 12 \tПример:  но в чем оно счастье и где оно лето \n",
            "# 13 \tПример:  я б остался в том сне навсегда навсегда  \n",
            "# 14 \tПример:  но что то есть что знаем только мы и звезды\n",
            "# 15 \tПример:  а проснусь почему то я опять не с тобой \n",
            "# 16 \tПример:  дни летят за днями и за годом год  \n",
            "# 17 \tПример:  я пью её а ведь ещё бы жил  \n",
            "# 18 \tПример:  я думала что все нормально что мы вместе  \n",
            "# 19 \tПример:  с тобою в чем то стали мы похожи  \n",
            "# 20 \tПример:  лишь только рядом ты б со мной была  \n",
            "# 21 \tПример:  так будь же счастлив в этот самый миг  \n",
            "# 22 \tПример:  думал я что преград не будет у нас  \n",
            "# 23 \tПример:  я бы слушал тебя и дарил за те песни цветы\n",
            "# 24 \tПример:  и делать вид счастливой а ночью плакать незаметно  \n",
            "# 25 \tПример:  и кто то для тебя лишь дверь души своей откроет\n",
            "# 26 \tПример:  вот уже год или два я все в том же\n",
            "# 27 \tПример:  не прощаю не бог но поверь отпускаю тебя  \n",
            "# 28 \tПример:  пройти немало здесь сумел но не жалею ни о чём\n",
            "# 29 \tПример:  и забыть что когда то тебя я любила  \n",
            "# 30 \tПример:  и ты тот парень ожидает что у дома  \n",
            "# 31 \tПример:  то с этим нужно как ни трудно жить  \n",
            "# 32 \tПример:  и в общем не важно там женщины дети  \n",
            "# 33 \tПример:  все дороги к тебе все дороги к тебе  \n",
            "# 34 \tПример:  я с тобою как сначала помню всё от первой встречи\n",
            "# 35 \tПример:  и будет новый мир и счастье у порога  \n",
            "# 36 \tПример:  я улыбаюсь и плачу смотрю на твое лицо  \n",
            "# 37 \tПример:  и если случается чудо он чувствует то же  \n",
            "# 38 \tПример:  и все же не понимаю не знаю что у тебя\n",
            "# 39 \tПример:  ведь что прошло то и станет нам мило  \n",
            "# 40 \tПример:  но придёт тот день и всё станет на свои места\n",
            "# 41 \tПример:  и жили мы без бед и без проблем  \n",
            "# 42 \tПример:  так играем в игру знаем или не знаем  \n",
            "# 43 \tПример:  что никогда не будет у нас любви до гроба \n",
            "# 44 \tПример:  и слов своих назад не сможешь ты забрать  \n",
            "# 45 \tПример:  и что чёрт возьми происходит в твоей голове  \n",
            "# 46 \tПример:  так нет и слова без любви к стране отцов \n",
            "# 47 \tПример:  твоё но мы мы бы не встретились случайно  \n",
            "# 48 \tПример:  и лишь от того как жизнь ты прожил  \n",
            "# 49 \tПример:  и всё из за тебя в которую поверил  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FtfMO3AXK-yk"
      },
      "source": [
        "Оценка качества примеров из обучающей выборки на основе BLEU  (для сравнения с генератором)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FNMHGxTTIQMZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "656b2727-140c-458c-bb43-f5d170880c9e"
      },
      "source": [
        "%%time\n",
        "# оценка качества на основе примеров из обучающей выборки (для сравнения с генератором)\n",
        "print(\"Оценка примеров из обучающей выборки на основе BLEU\")\n",
        "BLEU(data_file_test.tolist(), data_file_train[:500].tolist(), print_iteration=100)\n",
        "\n",
        "'''\n",
        "BLEU примеров из обучающей выборки\n",
        "--- --- ---\n",
        "Start BLEU\n",
        "2 100 0.5365504958995001\n",
        "2 200 0.5426700180034696\n",
        "2 300 0.5425210147596119\n",
        "2 400 0.5438925313146432\n",
        "2 500 0.5499117864293879\n",
        "--- --- ---\n",
        "2 -gram BLEU score :  0.5499117864293879\n",
        "3 100 0.4252853298296578\n",
        "3 200 0.4294441261529973\n",
        "3 300 0.42938411299670276\n",
        "3 400 0.432946142036555\n",
        "3 500 0.436991427933691\n",
        "--- --- ---\n",
        "3 -gram BLEU score :  0.436991427933691\n",
        "4 100 0.3118228221158724\n",
        "4 200 0.31347352868277367\n",
        "4 300 0.3133847969805193\n",
        "4 400 0.3148005592801212\n",
        "4 500 0.3173224414085976\n",
        "--- --- ---\n",
        "4 -gram BLEU score :  0.3173224414085976\n",
        "5 100 0.20748007111715946\n",
        "5 200 0.21057918753505803\n",
        "5 300 0.20884027925072032\n",
        "5 400 0.20986772415037908\n",
        "5 500 0.21083373415979106\n",
        "--- --- ---\n",
        "5 -gram BLEU score :  0.21083373415979106\n",
        "'''"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Оценка примеров из обучающей выборки на основе BLEU\n",
            "--- --- ---\n",
            "Start BLEU\n",
            "2 100 0.7557356298048126\n",
            "2 200 0.7431149192926594\n",
            "2 300 0.7406077524743515\n",
            "2 400 0.7376227044540618\n",
            "2 500 0.7379809479854459\n",
            "--- --- ---\n",
            "2 -gram BLEU score :  0.7379809479854459 \n",
            "\n",
            "3 100 0.44528086673712786\n",
            "3 200 0.4241709731237712\n",
            "3 300 0.4263801126725085\n",
            "3 400 0.4260298418663686\n",
            "3 500 0.4254384872936007\n",
            "--- --- ---\n",
            "3 -gram BLEU score :  0.4254384872936007 \n",
            "\n",
            "4 100 0.2437210033202152\n",
            "4 200 0.22273400244271355\n",
            "4 300 0.2249459514664226\n",
            "4 400 0.22592203062778282\n",
            "4 500 0.22426177276840145\n",
            "--- --- ---\n",
            "4 -gram BLEU score :  0.22426177276840145 \n",
            "\n",
            "5 100 0.14527711133766108\n",
            "5 200 0.13632915060821213\n",
            "5 300 0.1382702406801177\n",
            "5 400 0.13784283127701344\n",
            "5 500 0.13625371525855653\n",
            "--- --- ---\n",
            "5 -gram BLEU score :  0.13625371525855653 \n",
            "\n",
            "CPU times: user 5min 56s, sys: 115 ms, total: 5min 56s\n",
            "Wall time: 5min 56s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wQ2SVFc57G_h"
      },
      "source": [
        "Создание нейронных сетей генератора и дискриминатора"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LziOsVRduVtC"
      },
      "source": [
        "# объявление нейронных сетей генератора и дискриминатора, подготовка выборок данных для использования pytorch\n",
        "gen = Generator(GEN_EMBEDDING_DIM, GEN_HIDDEN_DIM, VOCAB_SIZE, MAX_SEQ_LEN, gpu=CUDA)\n",
        "dis = Discriminator(DIS_EMBEDDING_DIM, DIS_HIDDEN_DIM, VOCAB_SIZE, MAX_SEQ_LEN, gpu=CUDA)\n",
        "\n",
        "if CUDA:\n",
        "  gen = gen.cuda()\n",
        "  dis = dis.cuda()\n",
        "  data_file_tensor_train = torch.tensor(data_file_train).cuda()\n",
        "  data_file_tensor_test = torch.tensor(data_file_test).cuda()\n",
        "else:\n",
        "  data_file_tensor_train = torch.tensor(data_file_train)\n",
        "  data_file_tensor_test = torch.tensor(data_file_test)\n",
        "\n",
        "gen_optimizer = optim.Adam(gen.parameters(), lr=0.001) #, lr=0.001\n",
        "dis_optimizer = optim.Adagrad(dis.parameters())"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PjtGu-Dh7Xn0"
      },
      "source": [
        "Обучение генератора на основе MLE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2w7pqxEA3jhx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "afc94a97-1048-4b4a-d7dd-83a28a01aeac"
      },
      "source": [
        "%%time\n",
        "test_mle(gen, data_file_tensor_train, data_file_tensor_test)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "average_train_NLL = 8.5393 average_test_NLL = 8.5392\n",
            "CPU times: user 641 ms, sys: 199 ms, total: 840 ms\n",
            "Wall time: 840 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R_ZzVettuZHH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db7a8008-07c3-4ee3-b55b-b1fb1cb0ed85"
      },
      "source": [
        "%%time\n",
        "# обучение генератора на основе MLE / предобучение генератора\n",
        "print('Запуск обучения генератора на основе MLE...')\n",
        "gen_optimizer = optim.Adam(gen.parameters())#, lr=0.0002\n",
        "train_generator_MLE(gen, gen_optimizer, data_file_tensor_train, data_file_tensor_test, MLE_TRAIN_EPOCHS) # MLE_TRAIN_EPOCHS\n",
        "\n",
        "test_mle(gen, data_file_tensor_train, data_file_tensor_test)\n",
        "# сохранение результата обучения\n",
        "save_models(data_file_tensor_train, gen, dis, gen_optimizer, dis_optimizer,\n",
        "            FILE_PATHS['saved_models'] + r'/' + r'seqgan_mle.pytorch')\n",
        "# epoch 1 : .......... average_train_NLL = 1.8447 average_test_NLL = 1.9937"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Запуск обучения генератора на основе MLE...\n",
            "epoch 1 : .......... average_train_NLL = 6.3798 average_test_NLL = 5.5416\n",
            "epoch 2 : .......... average_train_NLL = 5.3908 average_test_NLL = 5.2943\n",
            "epoch 3 : .......... average_train_NLL = 5.1978 average_test_NLL = 5.1441\n",
            "epoch 4 : .......... average_train_NLL = 5.0625 average_test_NLL = 5.0328\n",
            "epoch 5 : .......... average_train_NLL = 4.9601 average_test_NLL = 4.9514\n",
            "epoch 6 : .......... average_train_NLL = 4.8811 average_test_NLL = 4.8908\n",
            "epoch 7 : .......... average_train_NLL = 4.8178 average_test_NLL = 4.8431\n",
            "epoch 8 : .......... average_train_NLL = 4.7642 average_test_NLL = 4.8038\n",
            "epoch 9 : .......... average_train_NLL = 4.7174 average_test_NLL = 4.7706\n",
            "epoch 10 : .......... average_train_NLL = 4.6757 average_test_NLL = 4.7418\n",
            "epoch 11 : .......... average_train_NLL = 4.6378 average_test_NLL = 4.7162\n",
            "epoch 12 : .......... average_train_NLL = 4.6029 average_test_NLL = 4.6933\n",
            "epoch 13 : .......... average_train_NLL = 4.5706 average_test_NLL = 4.6730\n",
            "epoch 14 : .......... average_train_NLL = 4.5410 average_test_NLL = 4.6539\n",
            "epoch 15 : .......... average_train_NLL = 4.5123 average_test_NLL = 4.6388\n",
            "epoch 16 : .......... average_train_NLL = 4.4849 average_test_NLL = 4.6230\n",
            "epoch 17 : .......... average_train_NLL = 4.4592 average_test_NLL = 4.6083\n",
            "epoch 18 : .......... average_train_NLL = 4.4351 average_test_NLL = 4.5966\n",
            "epoch 19 : .......... average_train_NLL = 4.4125 average_test_NLL = 4.5847\n",
            "epoch 20 : .......... average_train_NLL = 4.3890 average_test_NLL = 4.5738\n",
            "epoch 21 : .......... average_train_NLL = 4.3669 average_test_NLL = 4.5648\n",
            "epoch 22 : .......... average_train_NLL = 4.3459 average_test_NLL = 4.5565\n",
            "epoch 23 : .......... average_train_NLL = 4.3257 average_test_NLL = 4.5488\n",
            "epoch 24 : .......... average_train_NLL = 4.3065 average_test_NLL = 4.5412\n",
            "epoch 25 : .......... average_train_NLL = 4.2883 average_test_NLL = 4.5346\n",
            "epoch 26 : .......... average_train_NLL = 4.2705 average_test_NLL = 4.5329\n",
            "epoch 27 : .......... average_train_NLL = 4.2529 average_test_NLL = 4.5263\n",
            "epoch 28 : .......... average_train_NLL = 4.2338 average_test_NLL = 4.5201\n",
            "epoch 29 : .......... average_train_NLL = 4.2163 average_test_NLL = 4.5158\n",
            "epoch 30 : .......... average_train_NLL = 4.1994 average_test_NLL = 4.5120\n",
            "average_train_NLL = 4.1744 average_test_NLL = 4.5120\n",
            "CPU times: user 53.3 s, sys: 15.1 s, total: 1min 8s\n",
            "Wall time: 1min 11s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9vE1qrmlgJNa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e887ccc-3746-445e-ee2a-b26fdcfdca7c"
      },
      "source": [
        "%%time\n",
        "test_mle(gen, data_file_tensor_train, data_file_tensor_test)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "average_train_NLL = 4.1744 average_test_NLL = 4.5120\n",
            "CPU times: user 655 ms, sys: 188 ms, total: 844 ms\n",
            "Wall time: 845 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O2AFMeIuIg6R"
      },
      "source": [
        "Генерация примеров текстов на основе MLE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eGaETrFgIfzL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37bdf7a9-8b17-4db2-bdd2-6c83c18580aa"
      },
      "source": [
        "# примеры сгенерированных текстов\n",
        "print(\"Примеры генерируемых текстов на основе MLE\")\n",
        "degree = 1\n",
        "print(\"Degree:\", degree)\n",
        "samples = gen.sample(50, degree=degree).cpu().detach().numpy()\n",
        "\n",
        "output_function = []\n",
        "for i, samp in enumerate(samples):\n",
        "  line = [word[x] for x in samp]\n",
        "  line = ' '.join(line)\n",
        "  output_function.append(line)\n",
        "  bleu = BLEU(data_file_test.tolist(), [samp], flag_print=False)\n",
        "  print(\"#\", i, \"\\tПример: \", line, ' '*(100-len(line)), '\\tОценка: ', bleu)"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Примеры генерируемых текстов на основе MLE\n",
            "Degree: 1\n",
            "# 0 \tПример:  огня друг ответила за ним в кровать до сна                                                            \tОценка:  [0.6666666666666666, 0.381571414184444, 0.167844596251862, 0.10575371703212418]\n",
            "# 1 \tПример:  так даёт лучами друг для толпы и такого нет                                                           \tОценка:  [0.3162277660168379, 0.10772173450159421, 0.06500593260343694, 0.04951447111434312]\n",
            "# 2 \tПример:  а где то там ни минуты до края                                                                        \tОценка:  [0.9428090415820634, 0.7631428283688879, 0.5969491792019646, 0.2918230803979956]\n",
            "# 3 \tПример:  и пусть теперь без страха в часа с е больше                                                           \tОценка:  [0.5773502691896257, 0.34668063717531744, 0.15619699684601282, 0.09984076352304341]\n",
            "# 4 \tПример:  я в не в плену ты как это раньше сам                                                                  \tОценка:  [0.816496580927726, 0.20274006651911342, 0.10445522730720386, 0.07236255500755572]\n",
            "# 5 \tПример:  о том как раз я могла с тобой просыпаться с                                                           \tОценка:  [0.7453559924999299, 0.4110353457217451, 0.17747405280050269, 0.11058026936233441]\n",
            "# 6 \tПример:  я ненавижу всей быть и край                                                                           \tОценка:  [0.5962847939999439, 0.3542195230608704, 0.15873761852172436, 0.10113783164576018]\n",
            "# 7 \tПример:  вот вместе с нами хорошо и страх будут суть                                                           \tОценка:  [0.7453559924999299, 0.19078570709222206, 0.09980099403873667, 0.069771433108763]\n",
            "# 8 \tПример:  я буду выть как и с богом я тоже                                                                      \tОценка:  [0.7745966692414834, 0.42171633265087466, 0.18092176081223305, 0.11229551070568211]\n",
            "# 9 \tПример:  кому не важно зачем и за тебя нам                                                                     \tОценка:  [0.816496580927726, 0.43679023236814946, 0.18575057999133604, 0.11468692082056794]\n",
            "# 10 \tПример:  только вот так голос так чтоб я его найду                                                             \tОценка:  [0.816496580927726, 0.20274006651911342, 0.10445522730720386, 0.07236255500755572]\n",
            "# 11 \tПример:  мне одиноко и не жизнью давно убивать небо                                                            \tОценка:  [0.6666666666666666, 0.381571414184444, 0.167844596251862, 0.10575371703212418]\n",
            "# 12 \tПример:  и просто то цель от обид даже ее                                                                      \tОценка:  [0.5773502691896257, 0.16091489743427165, 0.08783602619713964, 0.0629952630233744]\n",
            "# 13 \tПример:  ведь для меня вместе я когда нибудь там                                                               \tОценка:  [0.8819171036881969, 0.5793377741477417, 0.22957488466614331, 0.13586551826765378]\n",
            "# 14 \tПример:  уже второй талант зная счастье часами приносит нам                                                    \tОценка:  [0.4714045207910317, 0.30285343213869, 0.1411399193078978, 0.09206395793297462]\n",
            "# 15 \tПример:  ну а сделать как и время боли в чужую в                                                               \tОценка:  [0.6324555320336759, 0.17099759466766976, 0.09193227152249189, 0.06533473633311172]\n",
            "# 16 \tПример:  и понятно я как воздух и тёплый лет                                                                   \tОценка:  [0.7453559924999299, 0.4110353457217451, 0.17747405280050269, 0.11058026936233441]\n",
            "# 17 \tПример:  не мог я знаю что с ними было давно а                                                                 \tОценка:  [0.8819171036881969, 0.5793377741477417, 0.22957488466614331, 0.13586551826765378]\n",
            "# 18 \tПример:  туда в дом моя тоска и моя придет                                                                     \tОценка:  [0.7453559924999299, 0.4110353457217451, 0.17747405280050269, 0.11058026936233441]\n",
            "# 19 \tПример:  а я бы заранее весь случайно и ласку                                                                  \tОценка:  [0.5477225575051661, 0.3347164750410848, 0.15213646010839674, 0.0977589201004575]\n",
            "# 20 \tПример:  я лечу не знаю ведь твой смех из сердца                                                               \tОценка:  [0.7453559924999299, 0.4110353457217451, 0.17747405280050269, 0.11058026936233441]\n",
            "# 21 \tПример:  легко смотреть за моря каждый раб но меня не забыл                                                    \tОценка:  [0.5773502691896257, 0.16091489743427165, 0.08783602619713964, 0.0629952630233744]\n",
            "# 22 \tПример:  к тебе я убит слишком писать ни капли глаза                                                           \tОценка:  [0.6666666666666666, 0.381571414184444, 0.167844596251862, 0.10575371703212418]\n",
            "# 23 \tПример:  к той доме и не стану когда не случится                                                               \tОценка:  [0.6666666666666666, 0.381571414184444, 0.167844596251862, 0.10575371703212418]\n",
            "# 24 \tПример:  ты самый враг в большие мира в этой уме мечтаю                                                        \tОценка:  [0.4216370213557839, 0.13049558803896216, 0.07506238537503397, 0.05555301564078447]\n",
            "# 25 \tПример:  пойми меня всю жизнь ты родные и не знаешь                                                            \tОценка:  [0.8819171036881969, 0.45982069606352016, 0.19304869754804488, 0.11827780346042588]\n",
            "# 26 \tПример:  ты будешь спал в а л а н д                                                                            \tОценка:  [0.816496580927726, 0.6299605249474366, 0.43472087194499137, 0.2264321778409878]\n",
            "# 27 \tПример:  но как дура я уже этой встречи дурак                                                                  \tОценка:  [0.6666666666666666, 0.381571414184444, 0.167844596251862, 0.10575371703212418]\n",
            "# 28 \tПример:  я могу уйду не могу мужчины пушкин с сердцем                                                          \tОценка:  [0.5773502691896257, 0.16091489743427165, 0.08783602619713964, 0.0629952630233744]\n",
            "# 29 \tПример:  я бы больше выбрать своей уж точно смог                                                               \tОценка:  [0.6666666666666666, 0.381571414184444, 0.167844596251862, 0.10575371703212418]\n",
            "# 30 \tПример:  он лучше на свете можно но давно то стал                                                              \tОценка:  [0.4714045207910317, 0.1405721108836249, 0.07936880926086218, 0.05808843041972589]\n",
            "# 31 \tПример:  мы верим в том что мир внутри чудес                                                                   \tОценка:  [0.816496580927726, 0.5503212081491045, 0.22089591134157885, 0.1317406772862616]\n",
            "# 32 \tПример:  и горечь в его всегда мы в мире похож                                                                 \tОценка:  [0.6666666666666666, 0.17710976153043526, 0.09438595268231116, 0.06672608446749886]\n",
            "# 33 \tПример:  как в этой любви мой милый грусти в океане                                                            \tОценка:  [0.7453559924999299, 0.19078570709222206, 0.09980099403873667, 0.069771433108763]\n",
            "# 34 \tПример:  но я я вам уже не могу тебя забыть                                                                    \tОценка:  [0.8819171036881969, 0.2134298608312491, 0.10855926040543844, 0.07462824878234049]\n",
            "# 35 \tПример:  пусть всё скучно и ждём с рожденья                                                                    \tОценка:  [0.7071067811865476, 0.39685026299204995, 0.17286039232097056, 0.10827448965556544]\n",
            "# 36 \tПример:  мне нужно твой взгляд обычно чистый день корабли родной                                               \tОценка:  [0.5477225575051661, 0.15536162529769298, 0.08555261858712451, 0.06168170862583606]\n",
            "# 37 \tПример:  мозг по правде строчки и телом за вами                                                                \tОценка:  [0.6324555320336759, 0.4641588833612779, 0.345720784641941, 0.18851683592050572]\n",
            "# 38 \tПример:  сколько хочется побыть а чёрт возьми для счастья                                                      \tОценка:  [0.6666666666666666, 0.381571414184444, 0.167844596251862, 0.10575371703212418]\n",
            "# 39 \tПример:  страна и детям твой дьявол вот так с самого собою                                                     \tОценка:  [0.6666666666666666, 0.17710976153043526, 0.09438595268231116, 0.06672608446749886]\n",
            "# 40 \tПример:  я хочу сказать но сейчас ты уже не познал                                                             \tОценка:  [0.8819171036881969, 0.5793377741477417, 0.22957488466614331, 0.13586551826765378]\n",
            "# 41 \tПример:  потому что есть у нас нельзя с тобой                                                                  \tОценка:  [0.8819171036881969, 0.7299198566479815, 0.4854917717073234, 0.24735189898367643]\n",
            "# 42 \tПример:  он был при чем ты суть в моей и сердца                                                                \tОценка:  [0.6666666666666666, 0.17710976153043526, 0.09438595268231116, 0.06672608446749886]\n",
            "# 43 \tПример:  да и от себя места в век мать                                                                         \tОценка:  [0.8819171036881969, 0.45982069606352016, 0.19304869754804488, 0.11827780346042588]\n",
            "# 44 \tПример:  страдать в краю если сердце без бед боле                                                              \tОценка:  [0.4714045207910317, 0.1405721108836249, 0.07936880926086218, 0.05808843041972589]\n",
            "# 45 \tПример:  пусть встану не в них те с луной                                                                      \tОценка:  [0.6324555320336759, 0.3684031498640387, 0.1634812655665549, 0.10354857884559052]\n",
            "# 46 \tПример:  и ночь то и вспомнить навсегда по совести                                                             \tОценка:  [0.7071067811865476, 0.18420157493201939, 0.09720654209069822, 0.06831658446802373]\n",
            "# 47 \tПример:  не с где милым на пути она смотрит                                                                    \tОценка:  [0.5477225575051661, 0.15536162529769298, 0.08555261858712451, 0.06168170862583606]\n",
            "# 48 \tПример:  кто то ждал но его ты место дверь                                                                     \tОценка:  [0.7453559924999299, 0.4110353457217451, 0.17747405280050269, 0.11058026936233441]\n",
            "# 49 \tПример:  ну я не могу думать ни чего ты                                                                        \tОценка:  [0.8819171036881969, 0.5793377741477417, 0.22957488466614331, 0.13586551826765378]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8lZnWDHB7xsN"
      },
      "source": [
        "Оценка качества генерации текста после обучения с помощью MLE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4R2_zZKV7yPv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6667bd7a-7c61-491a-9f4f-d5f9a045a15e"
      },
      "source": [
        "%%time\n",
        "print(\"Оценка качества генерации текста на основе BLEU, после обучения с помощью MLE\")\n",
        "# проверка качества обучения\n",
        "BLEU(data_file_test.tolist(), gen.sample(500, degree=degree).cpu().detach().numpy().tolist(), print_iteration=100)"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Оценка качества генерации текста на основе BLEU, после обучения с помощью MLE\n",
            "--- --- ---\n",
            "Start BLEU\n",
            "2 100 0.7207746163633939\n",
            "2 200 0.7102008706809321\n",
            "2 300 0.714883145523868\n",
            "2 400 0.7169106889930906\n",
            "2 500 0.7191104366142823\n",
            "--- --- ---\n",
            "2 -gram BLEU score :  0.7191104366142823 \n",
            "\n",
            "3 100 0.3778506843966224\n",
            "3 200 0.37401724302890577\n",
            "3 300 0.3747892007161154\n",
            "3 400 0.3725004302247718\n",
            "3 500 0.37587988607508577\n",
            "--- --- ---\n",
            "3 -gram BLEU score :  0.37587988607508577 \n",
            "\n",
            "4 100 0.18629428171386284\n",
            "4 200 0.18730292654987502\n",
            "4 300 0.18779596434235124\n",
            "4 400 0.1854892453738397\n",
            "4 500 0.1861466902118776\n",
            "--- --- ---\n",
            "4 -gram BLEU score :  0.1861466902118776 \n",
            "\n",
            "5 100 0.11410926993417572\n",
            "5 200 0.11586304074775632\n",
            "5 300 0.11600506518730475\n",
            "5 400 0.11449217860642476\n",
            "5 500 0.11463232316925863\n",
            "--- --- ---\n",
            "5 -gram BLEU score :  0.11463232316925863 \n",
            "\n",
            "CPU times: user 5min 57s, sys: 121 ms, total: 5min 57s\n",
            "Wall time: 5min 57s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ILoM7VA7nKpO"
      },
      "source": [
        "Оценка с возведением в степень"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ncMN88-nGy6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa48d654-a5c5-4725-ea51-dd0089a7a4c8"
      },
      "source": [
        "# примеры сгенерированных текстов\n",
        "print(\"Примеры генерируемых текстов на основе MLE\")\n",
        "degree = 1.5\n",
        "print(\"Degree:\", degree)\n",
        "samples = gen.sample(50, degree=degree).cpu().detach().numpy()\n",
        "\n",
        "output_function = []\n",
        "for i, samp in enumerate(samples):\n",
        "  line = [word[x] for x in samp]\n",
        "  line = ' '.join(line)\n",
        "  output_function.append(line)\n",
        "  bleu = BLEU(data_file_test.tolist(), [samp], flag_print=False)\n",
        "  print(\"#\", i, \"\\tПример: \", line, ' '*(100-len(line)), '\\tОценка: ', bleu)"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Примеры генерируемых текстов на основе MLE\n",
            "Degree: 1.5\n",
            "# 0 \tПример:  и я не знаю что я не могу                                                                             \tОценка:  [1.0, 1.0, 0.8091067115702212, 0.5898945623563899]\n",
            "# 1 \tПример:  ты мне и не то и не сможешь                                                                           \tОценка:  [0.9428090415820634, 0.7631428283688879, 0.5969491792019646, 0.2918230803979956]\n",
            "# 2 \tПример:  и в них нет там где нет боли                                                                          \tОценка:  [0.816496580927726, 0.43679023236814946, 0.18575057999133604, 0.11468692082056794]\n",
            "# 3 \tПример:  и мы все хотим с тобой по кругу                                                                       \tОценка:  [0.8819171036881969, 0.7299198566479815, 0.4854917717073234, 0.24735189898367643]\n",
            "# 4 \tПример:  я не знаю что в тебе я совсем придумал                                                                \tОценка:  [0.8819171036881969, 0.7299198566479815, 0.5773502691896257, 0.2841327194679419]\n",
            "# 5 \tПример:  так и я не знаю как быть с тобою                                                                      \tОценка:  [1.0, 0.9085602964160698, 0.8091067115702212, 0.3721983065876935]\n",
            "# 6 \tПример:  кто то сказал что им не важно же                                                                      \tОценка:  [0.8819171036881969, 0.45982069606352016, 0.19304869754804488, 0.11827780346042588]\n",
            "# 7 \tПример:  но не в силах я и вновь на миг                                                                        \tОценка:  [0.9428090415820634, 0.6933612743506347, 0.4671379777282001, 0.2398423611497788]\n",
            "# 8 \tПример:  а в стихах нет в этот раз                                                                             \tОценка:  [0.8366600265340756, 0.6402895824937471, 0.4400558683966967, 0.22865252596366317]\n",
            "# 9 \tПример:  но если ты в этом мире не кричи                                                                       \tОценка:  [1.0, 0.8549879733383485, 0.6500593260343691, 0.31241519207647167]\n",
            "# 10 \tПример:  я не знаю как обычно снова и не дают                                                                  \tОценка:  [0.8819171036881969, 0.5793377741477417, 0.408248290463863, 0.2153323349926055]\n",
            "# 11 \tПример:  коль не в том что не будешь мне                                                                       \tОценка:  [0.9428090415820634, 0.7631428283688879, 0.5019724248795793, 0.25404674702328517]\n",
            "# 12 \tПример:  я хочу чтоб в этом мире не было                                                                       \tОценка:  [0.9428090415820634, 0.6933612743506347, 0.4671379777282001, 0.2398423611497788]\n",
            "# 13 \tПример:  всё что будет просто в жизни не будет                                                                 \tОценка:  [0.9428090415820634, 0.7631428283688879, 0.5019724248795793, 0.25404674702328517]\n",
            "# 14 \tПример:  я тебя любил и не хочу я с тобой                                                                      \tОценка:  [0.9428090415820634, 0.7631428283688879, 0.5019724248795793, 0.25404674702328517]\n",
            "# 15 \tПример:  что то с тобой будет вечно и было                                                                     \tОценка:  [0.9428090415820634, 0.7631428283688879, 0.28227983861579553, 0.16029266087564348]\n",
            "# 16 \tПример:  жаль что я сам не мог быть с тобой                                                                    \tОценка:  [1.0, 0.7937005259840998, 0.5169731539571706, 0.26010227020433874]\n",
            "# 17 \tПример:  и в эти игры ни в ком же                                                                              \tОценка:  [0.7745966692414834, 0.42171633265087466, 0.18092176081223305, 0.11229551070568211]\n",
            "# 18 \tПример:  ты увидишь не в силах вы моя мы                                                                       \tОценка:  [0.7453559924999299, 0.5178720843256431, 0.21105340631872638, 0.12702337351164256]\n",
            "# 19 \tПример:  порой мне не сказала и как прежде мне                                                                 \tОценка:  [0.816496580927726, 0.5503212081491045, 0.22089591134157885, 0.1317406772862616]\n",
            "# 20 \tПример:  что будет так как и ночью и грусть                                                                    \tОценка:  [1.0, 0.9085602964160698, 0.5721248424548514, 0.28207356966104163]\n",
            "# 21 \tПример:  за всё что в этом мире нам не в силах                                                                 \tОценка:  [0.9428090415820634, 0.82207069144349, 0.5307712171072443, 0.2656413268946963]\n",
            "# 22 \tПример:  а может быть что было с нами будет                                                                    \tОценка:  [0.9428090415820634, 0.82207069144349, 0.5307712171072443, 0.2656413268946963]\n",
            "# 23 \tПример:  и если бы я не верю я в сердце                                                                        \tОценка:  [1.0, 0.9564655913861946, 0.5946035575013605, 0.290905379576344]\n",
            "# 24 \tПример:  вот и я что то любила на свете                                                                        \tОценка:  [0.8819171036881969, 0.6631762013160654, 0.4518010018049224, 0.23352183872556712]\n",
            "# 25 \tПример:  а с ним и на сердце не пойду                                                                          \tОценка:  [0.8819171036881969, 0.5793377741477417, 0.22957488466614331, 0.13586551826765378]\n",
            "# 26 \tПример:  что у каждого из нас в жизни                                                                          \tОценка:  [0.8944271909999159, 0.7368062997280773, 0.488923022434901, 0.24874945631098302]\n",
            "# 27 \tПример:  и вот оно же в них не боится                                                                          \tОценка:  [0.8819171036881969, 0.6631762013160654, 0.2540663740773074, 0.14734231924041577]\n",
            "# 28 \tПример:  я не знаю что у меня есть ты                                                                          \tОценка:  [1.0, 0.9564655913861946, 0.8891397050194614, 0.7924465962305567]\n",
            "# 29 \tПример:  и пусть никогда не станет ни в чем                                                                    \tОценка:  [0.8819171036881969, 0.5793377741477417, 0.22957488466614331, 0.13586551826765378]\n",
            "# 30 \tПример:  я так боюсь чтобы в жизни нашей все было                                                              \tОценка:  [0.816496580927726, 0.43679023236814946, 0.18575057999133604, 0.11468692082056794]\n",
            "# 31 \tПример:  пусть будет все с нами наяву и а может это                                                            \tОценка:  [0.7453559924999299, 0.5178720843256431, 0.21105340631872638, 0.12702337351164256]\n",
            "# 32 \tПример:  и как мне хотелось бы я не стану                                                                      \tОценка:  [1.0, 0.7211247851537042, 0.48109772909788073, 0.24555930495936829]\n",
            "# 33 \tПример:  и что ведь ты уже не понимаешь что ты меня                                                            \tОценка:  [0.8819171036881969, 0.6631762013160654, 0.4518010018049224, 0.23352183872556712]\n",
            "# 34 \tПример:  пусть есть у бога как у всех своя                                                                     \tОценка:  [0.7453559924999299, 0.4110353457217451, 0.17747405280050269, 0.11058026936233441]\n",
            "# 35 \tПример:  что есть то что у нас с тобой                                                                         \tОценка:  [1.0, 0.9085602964160698, 0.7529586373193689, 0.35138777297455254]\n",
            "# 36 \tПример:  я тебя не боюсь и не могу летать                                                                      \tОценка:  [0.9428090415820634, 0.6933612743506347, 0.2626909894424158, 0.15133029928492392]\n",
            "# 37 \tПример:  где ты и не можешь мне быть одному                                                                    \tОценка:  [0.8819171036881969, 0.5793377741477417, 0.22957488466614331, 0.13586551826765378]\n",
            "# 38 \tПример:  потому что я вижу в жизни всё как в чём                                                               \tОценка:  [1.0, 0.7937005259840998, 0.29071536848410967, 0.1641134377013993]\n",
            "# 39 \tПример:  в котором мы с тобой должны со мной                                                                   \tОценка:  [0.816496580927726, 0.6299605249474366, 0.43472087194499137, 0.2264321778409878]\n",
            "# 40 \tПример:  откуда теперь я в снах в лицо от них всегда                                                           \tОценка:  [0.6666666666666666, 0.17710976153043526, 0.09438595268231116, 0.06672608446749886]\n",
            "# 41 \tПример:  а если бы не так как не надо                                                                          \tОценка:  [1.0, 0.8549879733383485, 0.5466325569645467, 0.27197322144443925]\n",
            "# 42 \tПример:  я не могу быть с тобой не по пути                                                                     \tОценка:  [0.9428090415820634, 0.7631428283688879, 0.28227983861579553, 0.16029266087564348]\n",
            "# 43 \tПример:  а ты мне нужна и своё мой дом                                                                         \tОценка:  [0.816496580927726, 0.6299605249474366, 0.43472087194499137, 0.2264321778409878]\n",
            "# 44 \tПример:  и если кто то держал и краше меня                                                                     \tОценка:  [0.816496580927726, 0.5503212081491045, 0.22089591134157885, 0.1317406772862616]\n",
            "# 45 \tПример:  в те дни где в вечер он не был                                                                        \tОценка:  [0.816496580927726, 0.5503212081491045, 0.22089591134157885, 0.1317406772862616]\n",
            "# 46 \tПример:  и мы все же не понимаем мы в вине                                                                     \tОценка:  [0.9428090415820634, 0.6933612743506347, 0.2626909894424158, 0.15133029928492392]\n",
            "# 47 \tПример:  но я знаю что нет не так уж                                                                           \tОценка:  [1.0, 0.8549879733383485, 0.3073940764756322, 0.17160350157230692]\n",
            "# 48 \tПример:  и друзья все будут с тобой ради тебя                                                                  \tОценка:  [0.816496580927726, 0.43679023236814946, 0.18575057999133604, 0.11468692082056794]\n",
            "# 49 \tПример:  мне не надо ни к чему не смогу                                                                        \tОценка:  [0.8819171036881969, 0.7299198566479815, 0.4854917717073234, 0.24735189898367643]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XOr1E34CnJ_v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46c7e56a-6816-4467-e0ff-76ebf4b6cb12"
      },
      "source": [
        "%%time\n",
        "print(\"Оценка качества генерации текста на основе BLEU, после обучения с помощью MLE\")\n",
        "# проверка качества обучения\n",
        "BLEU(data_file_test.tolist(), gen.sample(500, degree=degree).cpu().detach().numpy().tolist(), print_iteration=100)"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Оценка качества генерации текста на основе BLEU, после обучения с помощью MLE\n",
            "--- --- ---\n",
            "Start BLEU\n",
            "2 100 0.9110841130803087\n",
            "2 200 0.9128592924385134\n",
            "2 300 0.9146554172705765\n",
            "2 400 0.9163526544163312\n",
            "2 500 0.9131904285074142\n",
            "--- --- ---\n",
            "2 -gram BLEU score :  0.9131904285074142 \n",
            "\n",
            "3 100 0.6632484121585793\n",
            "3 200 0.6720061886944637\n",
            "3 300 0.6777352343138564\n",
            "3 400 0.6803502290187979\n",
            "3 500 0.6792977554430498\n",
            "--- --- ---\n",
            "3 -gram BLEU score :  0.6792977554430498 \n",
            "\n",
            "4 100 0.3799941689996252\n",
            "4 200 0.3904176754214317\n",
            "4 300 0.39871029395880414\n",
            "4 400 0.4026617908579711\n",
            "4 500 0.4001824956390621\n",
            "--- --- ---\n",
            "4 -gram BLEU score :  0.4001824956390621 \n",
            "\n",
            "5 100 0.21590792026570313\n",
            "5 200 0.22347565990667476\n",
            "5 300 0.22796507131962357\n",
            "5 400 0.23232880727386018\n",
            "5 500 0.2305350903578656\n",
            "--- --- ---\n",
            "5 -gram BLEU score :  0.2305350903578656 \n",
            "\n",
            "CPU times: user 5min 52s, sys: 114 ms, total: 5min 53s\n",
            "Wall time: 5min 52s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vdrWQfpV7bie"
      },
      "source": [
        "Предварительное обучение дискриминатора"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FVypqCS4ucWp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a363c833-ec79-4b91-c407-f2b1b296213c"
      },
      "source": [
        "%%time\n",
        "# предобучение дискриминатора\n",
        "print('Запуск обучения дискриминатора...')\n",
        "# dis_optimizer = optim.Adagrad(dis.parameters()) # , lr=0.0001\n",
        "# dis_optimizer = optim.Adam(gen.parameters(), lr=0.001, weight_decay=1e-5)#0.001\n",
        "# dis_optimizer = optim.Adadelta(gen.parameters())\n",
        "# dis_optimizer = optim.Adagrad(dis.parameters())#, lr=0.0001)#, weight_decay=1e-5)\n",
        "#, weight_decay=1e-5) # регуляризация\n",
        "train_discriminator(dis, dis_optimizer, data_file_tensor_train, gen, DIS_TRAIN_ITERATIONS, DIS_TRAIN_EPOCHS)#25, 1 | (15, 3), (25, 1)\n",
        "\n",
        "# сохранение результата обучения\n",
        "save_models(data_file_tensor_train, gen, dis, gen_optimizer, dis_optimizer,\n",
        "            FILE_PATHS['saved_models'] + r'/' + r'seqgan_pretraining_dis.pytorch')\n",
        "\n",
        "# ДО ОБУЧЕНИЯ: val_acc = 0.5230\n",
        "# d-step 50 epoch 1 : .......... average_loss = 0.2859, train_acc = 0.9136, val_acc = 0.5240"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Запуск обучения дискриминатора...\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5040\n",
            "d-step 1 epoch 1 : .......... average_loss = 0.4592, train_acc = 0.8385, val_acc = 0.5000\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5000\n",
            "d-step 2 epoch 1 : .......... average_loss = 0.3759, train_acc = 0.8758, val_acc = 0.5000\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5000\n",
            "d-step 3 epoch 1 : .......... average_loss = 0.3779, train_acc = 0.8747, val_acc = 0.5000\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5000\n",
            "d-step 4 epoch 1 : .......... average_loss = 0.3778, train_acc = 0.8742, val_acc = 0.5000\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5000\n",
            "d-step 5 epoch 1 : .......... average_loss = 0.3681, train_acc = 0.8791, val_acc = 0.5000\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5000\n",
            "d-step 6 epoch 1 : .......... average_loss = 0.3765, train_acc = 0.8741, val_acc = 0.5000\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5000\n",
            "d-step 7 epoch 1 : .......... average_loss = 0.3772, train_acc = 0.8744, val_acc = 0.5000\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5000\n",
            "d-step 8 epoch 1 : .......... average_loss = 0.3745, train_acc = 0.8753, val_acc = 0.5000\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5000\n",
            "d-step 9 epoch 1 : .......... average_loss = 0.3720, train_acc = 0.8766, val_acc = 0.5000\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5000\n",
            "d-step 10 epoch 1 : .......... average_loss = 0.3700, train_acc = 0.8770, val_acc = 0.5000\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5000\n",
            "d-step 11 epoch 1 : .......... average_loss = 0.3750, train_acc = 0.8746, val_acc = 0.5000\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5000\n",
            "d-step 12 epoch 1 : .......... average_loss = 0.3830, train_acc = 0.8697, val_acc = 0.5000\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5000\n",
            "d-step 13 epoch 1 : .......... average_loss = 0.3740, train_acc = 0.8751, val_acc = 0.5000\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5000\n",
            "d-step 14 epoch 1 : .......... average_loss = 0.3713, train_acc = 0.8755, val_acc = 0.5000\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5000\n",
            "d-step 15 epoch 1 : .......... average_loss = 0.3774, train_acc = 0.8732, val_acc = 0.5000\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5000\n",
            "d-step 16 epoch 1 : .......... average_loss = 0.3700, train_acc = 0.8767, val_acc = 0.5000\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5000\n",
            "d-step 17 epoch 1 : .......... average_loss = 0.3737, train_acc = 0.8745, val_acc = 0.5000\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5000\n",
            "d-step 18 epoch 1 : .......... average_loss = 0.3739, train_acc = 0.8741, val_acc = 0.5000\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5000\n",
            "d-step 19 epoch 1 : .......... average_loss = 0.3731, train_acc = 0.8730, val_acc = 0.5000\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5000\n",
            "d-step 20 epoch 1 : .......... average_loss = 0.3583, train_acc = 0.8804, val_acc = 0.5000\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5000\n",
            "d-step 21 epoch 1 : .......... average_loss = 0.3709, train_acc = 0.8737, val_acc = 0.5000\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5000\n",
            "d-step 22 epoch 1 : .......... average_loss = 0.3706, train_acc = 0.8733, val_acc = 0.5000\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5000\n",
            "d-step 23 epoch 1 : .......... average_loss = 0.3688, train_acc = 0.8743, val_acc = 0.5000\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5000\n",
            "d-step 24 epoch 1 : .......... average_loss = 0.3702, train_acc = 0.8733, val_acc = 0.5000\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5000\n",
            "d-step 25 epoch 1 : .......... average_loss = 0.3686, train_acc = 0.8750, val_acc = 0.5000\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5000\n",
            "d-step 26 epoch 1 : .......... average_loss = 0.3691, train_acc = 0.8742, val_acc = 0.5000\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5000\n",
            "d-step 27 epoch 1 : .......... average_loss = 0.3679, train_acc = 0.8747, val_acc = 0.5000\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5000\n",
            "d-step 28 epoch 1 : .......... average_loss = 0.3697, train_acc = 0.8733, val_acc = 0.5000\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5000\n",
            "d-step 29 epoch 1 : .......... average_loss = 0.3612, train_acc = 0.8773, val_acc = 0.5000\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5000\n",
            "d-step 30 epoch 1 : .......... average_loss = 0.3697, train_acc = 0.8743, val_acc = 0.5120\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5110\n",
            "d-step 31 epoch 1 : .......... average_loss = 0.3666, train_acc = 0.8754, val_acc = 0.5110\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5120\n",
            "d-step 32 epoch 1 : .......... average_loss = 0.3649, train_acc = 0.8783, val_acc = 0.5110\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5120\n",
            "d-step 33 epoch 1 : .......... average_loss = 0.3642, train_acc = 0.8787, val_acc = 0.5080\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5120\n",
            "d-step 34 epoch 1 : .......... average_loss = 0.3636, train_acc = 0.8789, val_acc = 0.5100\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5120\n",
            "d-step 35 epoch 1 : .......... average_loss = 0.3620, train_acc = 0.8794, val_acc = 0.5120\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5080\n",
            "d-step 36 epoch 1 : .......... average_loss = 0.3626, train_acc = 0.8792, val_acc = 0.5130\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5110\n",
            "d-step 37 epoch 1 : .......... average_loss = 0.3609, train_acc = 0.8807, val_acc = 0.5130\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5130\n",
            "d-step 38 epoch 1 : .......... average_loss = 0.3613, train_acc = 0.8802, val_acc = 0.5130\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5120\n",
            "d-step 39 epoch 1 : .......... average_loss = 0.3673, train_acc = 0.8777, val_acc = 0.5120\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5130\n",
            "d-step 40 epoch 1 : .......... average_loss = 0.3608, train_acc = 0.8798, val_acc = 0.5120\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5130\n",
            "d-step 41 epoch 1 : .......... average_loss = 0.3680, train_acc = 0.8770, val_acc = 0.5130\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5120\n",
            "d-step 42 epoch 1 : .......... average_loss = 0.3612, train_acc = 0.8796, val_acc = 0.5120\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5130\n",
            "d-step 43 epoch 1 : .......... average_loss = 0.3631, train_acc = 0.8787, val_acc = 0.5130\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5130\n",
            "d-step 44 epoch 1 : .......... average_loss = 0.3570, train_acc = 0.8813, val_acc = 0.5130\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5130\n",
            "d-step 45 epoch 1 : .......... average_loss = 0.3647, train_acc = 0.8777, val_acc = 0.5130\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5130\n",
            "d-step 46 epoch 1 : .......... average_loss = 0.3657, train_acc = 0.8781, val_acc = 0.5130\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5130\n",
            "d-step 47 epoch 1 : .......... average_loss = 0.3699, train_acc = 0.8747, val_acc = 0.5140\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5130\n",
            "d-step 48 epoch 1 : .......... average_loss = 0.3605, train_acc = 0.8791, val_acc = 0.5130\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5130\n",
            "d-step 49 epoch 1 : .......... average_loss = 0.3574, train_acc = 0.8810, val_acc = 0.5130\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5130\n",
            "d-step 50 epoch 1 : .......... average_loss = 0.3599, train_acc = 0.8792, val_acc = 0.5130\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5130\n",
            "d-step 51 epoch 1 : .......... average_loss = 0.3594, train_acc = 0.8800, val_acc = 0.5140\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5130\n",
            "d-step 52 epoch 1 : .......... average_loss = 0.3656, train_acc = 0.8763, val_acc = 0.5140\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5140\n",
            "d-step 53 epoch 1 : .......... average_loss = 0.3692, train_acc = 0.8741, val_acc = 0.5140\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5130\n",
            "d-step 54 epoch 1 : .......... average_loss = 0.3612, train_acc = 0.8781, val_acc = 0.5140\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5140\n",
            "d-step 55 epoch 1 : .......... average_loss = 0.3553, train_acc = 0.8819, val_acc = 0.5130\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5130\n",
            "d-step 56 epoch 1 : .......... average_loss = 0.3633, train_acc = 0.8770, val_acc = 0.5140\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5130\n",
            "d-step 57 epoch 1 : .......... average_loss = 0.3687, train_acc = 0.8743, val_acc = 0.5140\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5130\n",
            "d-step 58 epoch 1 : .......... average_loss = 0.3632, train_acc = 0.8769, val_acc = 0.5140\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5140\n",
            "d-step 59 epoch 1 : .......... average_loss = 0.3557, train_acc = 0.8801, val_acc = 0.5130\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5140\n",
            "d-step 60 epoch 1 : .......... average_loss = 0.3551, train_acc = 0.8803, val_acc = 0.5140\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5140\n",
            "d-step 61 epoch 1 : .......... average_loss = 0.3627, train_acc = 0.8761, val_acc = 0.5150\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5140\n",
            "d-step 62 epoch 1 : .......... average_loss = 0.3676, train_acc = 0.8754, val_acc = 0.5140\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5140\n",
            "d-step 63 epoch 1 : .......... average_loss = 0.3569, train_acc = 0.8793, val_acc = 0.5140\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5140\n",
            "d-step 64 epoch 1 : .......... average_loss = 0.3571, train_acc = 0.8793, val_acc = 0.5140\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5140\n",
            "d-step 65 epoch 1 : .......... average_loss = 0.3593, train_acc = 0.8788, val_acc = 0.5140\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5140\n",
            "d-step 66 epoch 1 : .......... average_loss = 0.3592, train_acc = 0.8782, val_acc = 0.5140\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5140\n",
            "d-step 67 epoch 1 : .......... average_loss = 0.3556, train_acc = 0.8798, val_acc = 0.5150\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5150\n",
            "d-step 68 epoch 1 : .......... average_loss = 0.3526, train_acc = 0.8806, val_acc = 0.5150\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5140\n",
            "d-step 69 epoch 1 : .......... average_loss = 0.3524, train_acc = 0.8807, val_acc = 0.5160\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5140\n",
            "d-step 70 epoch 1 : .......... average_loss = 0.3625, train_acc = 0.8762, val_acc = 0.5150\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5180\n",
            "d-step 71 epoch 1 : .......... average_loss = 0.3593, train_acc = 0.8765, val_acc = 0.5150\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5140\n",
            "d-step 72 epoch 1 : .......... average_loss = 0.3560, train_acc = 0.8767, val_acc = 0.5140\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5160\n",
            "d-step 73 epoch 1 : .......... average_loss = 0.3571, train_acc = 0.8788, val_acc = 0.5170\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5160\n",
            "d-step 74 epoch 1 : .......... average_loss = 0.3590, train_acc = 0.8764, val_acc = 0.5200\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5200\n",
            "d-step 75 epoch 1 : .......... average_loss = 0.3571, train_acc = 0.8780, val_acc = 0.5170\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5180\n",
            "d-step 76 epoch 1 : .......... average_loss = 0.3485, train_acc = 0.8827, val_acc = 0.5180\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5180\n",
            "d-step 77 epoch 1 : .......... average_loss = 0.3562, train_acc = 0.8779, val_acc = 0.5140\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5170\n",
            "d-step 78 epoch 1 : .......... average_loss = 0.3510, train_acc = 0.8799, val_acc = 0.5150\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5170\n",
            "d-step 79 epoch 1 : .......... average_loss = 0.3593, train_acc = 0.8766, val_acc = 0.5200\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5190\n",
            "d-step 80 epoch 1 : .......... average_loss = 0.3529, train_acc = 0.8790, val_acc = 0.5160\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5180\n",
            "d-step 81 epoch 1 : .......... average_loss = 0.3531, train_acc = 0.8791, val_acc = 0.5170\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5180\n",
            "d-step 82 epoch 1 : .......... average_loss = 0.3540, train_acc = 0.8789, val_acc = 0.5200\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5180\n",
            "d-step 83 epoch 1 : .......... average_loss = 0.3396, train_acc = 0.8851, val_acc = 0.5250\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5260\n",
            "d-step 84 epoch 1 : .......... average_loss = 0.3462, train_acc = 0.8804, val_acc = 0.5220\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5210\n",
            "d-step 85 epoch 1 : .......... average_loss = 0.3504, train_acc = 0.8799, val_acc = 0.5180\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5200\n",
            "d-step 86 epoch 1 : .......... average_loss = 0.3539, train_acc = 0.8781, val_acc = 0.5260\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5260\n",
            "d-step 87 epoch 1 : .......... average_loss = 0.3516, train_acc = 0.8796, val_acc = 0.5230\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5190\n",
            "d-step 88 epoch 1 : .......... average_loss = 0.3446, train_acc = 0.8820, val_acc = 0.5250\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5250\n",
            "d-step 89 epoch 1 : .......... average_loss = 0.3514, train_acc = 0.8790, val_acc = 0.5260\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5240\n",
            "d-step 90 epoch 1 : .......... average_loss = 0.3498, train_acc = 0.8793, val_acc = 0.5290\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5290\n",
            "d-step 91 epoch 1 : .......... average_loss = 0.3546, train_acc = 0.8773, val_acc = 0.5240\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5240\n",
            "d-step 92 epoch 1 : .......... average_loss = 0.3470, train_acc = 0.8806, val_acc = 0.5240\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5220\n",
            "d-step 93 epoch 1 : .......... average_loss = 0.3417, train_acc = 0.8831, val_acc = 0.5270\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5260\n",
            "d-step 94 epoch 1 : .......... average_loss = 0.3430, train_acc = 0.8821, val_acc = 0.5300\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5300\n",
            "d-step 95 epoch 1 : .......... average_loss = 0.3520, train_acc = 0.8782, val_acc = 0.5280\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5310\n",
            "d-step 96 epoch 1 : .......... average_loss = 0.3414, train_acc = 0.8834, val_acc = 0.5340\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5300\n",
            "d-step 97 epoch 1 : .......... average_loss = 0.3499, train_acc = 0.8783, val_acc = 0.5270\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5260\n",
            "d-step 98 epoch 1 : .......... average_loss = 0.3459, train_acc = 0.8802, val_acc = 0.5300\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5280\n",
            "d-step 99 epoch 1 : .......... average_loss = 0.3480, train_acc = 0.8810, val_acc = 0.5410\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5370\n",
            "d-step 100 epoch 1 : .......... average_loss = 0.3433, train_acc = 0.8828, val_acc = 0.5330\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5310\n",
            "d-step 101 epoch 1 : .......... average_loss = 0.3443, train_acc = 0.8815, val_acc = 0.5300\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5310\n",
            "d-step 102 epoch 1 : .......... average_loss = 0.3428, train_acc = 0.8825, val_acc = 0.5310\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5330\n",
            "d-step 103 epoch 1 : .......... average_loss = 0.3464, train_acc = 0.8810, val_acc = 0.5360\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5350\n",
            "d-step 104 epoch 1 : .......... average_loss = 0.3387, train_acc = 0.8819, val_acc = 0.5410\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5350\n",
            "d-step 105 epoch 1 : .......... average_loss = 0.3413, train_acc = 0.8835, val_acc = 0.5420\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5450\n",
            "d-step 106 epoch 1 : .......... average_loss = 0.3411, train_acc = 0.8831, val_acc = 0.5360\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5340\n",
            "d-step 107 epoch 1 : .......... average_loss = 0.3420, train_acc = 0.8827, val_acc = 0.5430\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5430\n",
            "d-step 108 epoch 1 : .......... average_loss = 0.3402, train_acc = 0.8827, val_acc = 0.5450\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5440\n",
            "d-step 109 epoch 1 : .......... average_loss = 0.3382, train_acc = 0.8831, val_acc = 0.5360\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5360\n",
            "d-step 110 epoch 1 : .......... average_loss = 0.3343, train_acc = 0.8866, val_acc = 0.5320\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5340\n",
            "d-step 111 epoch 1 : .......... average_loss = 0.3326, train_acc = 0.8878, val_acc = 0.5430\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5480\n",
            "d-step 112 epoch 1 : .......... average_loss = 0.3387, train_acc = 0.8833, val_acc = 0.5480\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5490\n",
            "d-step 113 epoch 1 : .......... average_loss = 0.3349, train_acc = 0.8850, val_acc = 0.5490\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5530\n",
            "d-step 114 epoch 1 : .......... average_loss = 0.3364, train_acc = 0.8859, val_acc = 0.5520\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5490\n",
            "d-step 115 epoch 1 : .......... average_loss = 0.3330, train_acc = 0.8854, val_acc = 0.5530\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5490\n",
            "d-step 116 epoch 1 : .......... average_loss = 0.3355, train_acc = 0.8848, val_acc = 0.5560\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5580\n",
            "d-step 117 epoch 1 : .......... average_loss = 0.3328, train_acc = 0.8869, val_acc = 0.5580\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5510\n",
            "d-step 118 epoch 1 : .......... average_loss = 0.3372, train_acc = 0.8851, val_acc = 0.5510\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5450\n",
            "d-step 119 epoch 1 : .......... average_loss = 0.3254, train_acc = 0.8894, val_acc = 0.5610\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5580\n",
            "d-step 120 epoch 1 : .......... average_loss = 0.3281, train_acc = 0.8878, val_acc = 0.5690\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5680\n",
            "d-step 121 epoch 1 : .......... average_loss = 0.3370, train_acc = 0.8848, val_acc = 0.5730\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5690\n",
            "d-step 122 epoch 1 : .......... average_loss = 0.3262, train_acc = 0.8898, val_acc = 0.5710\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5670\n",
            "d-step 123 epoch 1 : .......... average_loss = 0.3304, train_acc = 0.8875, val_acc = 0.5930\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5880\n",
            "d-step 124 epoch 1 : .......... average_loss = 0.3308, train_acc = 0.8874, val_acc = 0.5710\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5710\n",
            "d-step 125 epoch 1 : .......... average_loss = 0.3255, train_acc = 0.8886, val_acc = 0.5470\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5500\n",
            "d-step 126 epoch 1 : .......... average_loss = 0.3282, train_acc = 0.8883, val_acc = 0.5730\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5740\n",
            "d-step 127 epoch 1 : .......... average_loss = 0.3257, train_acc = 0.8891, val_acc = 0.5670\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5680\n",
            "d-step 128 epoch 1 : .......... average_loss = 0.3204, train_acc = 0.8920, val_acc = 0.5870\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5830\n",
            "d-step 129 epoch 1 : .......... average_loss = 0.3258, train_acc = 0.8902, val_acc = 0.5700\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5700\n",
            "d-step 130 epoch 1 : .......... average_loss = 0.3226, train_acc = 0.8895, val_acc = 0.5830\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5860\n",
            "d-step 131 epoch 1 : .......... average_loss = 0.3230, train_acc = 0.8907, val_acc = 0.5750\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5740\n",
            "d-step 132 epoch 1 : .......... average_loss = 0.3240, train_acc = 0.8901, val_acc = 0.5830\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5820\n",
            "d-step 133 epoch 1 : .......... average_loss = 0.3199, train_acc = 0.8931, val_acc = 0.5940\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5930\n",
            "d-step 134 epoch 1 : .......... average_loss = 0.3243, train_acc = 0.8898, val_acc = 0.5870\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5910\n",
            "d-step 135 epoch 1 : .......... average_loss = 0.3185, train_acc = 0.8933, val_acc = 0.5990\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5980\n",
            "d-step 136 epoch 1 : .......... average_loss = 0.3142, train_acc = 0.8925, val_acc = 0.5980\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.6030\n",
            "d-step 137 epoch 1 : .......... average_loss = 0.3200, train_acc = 0.8933, val_acc = 0.5590\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5630\n",
            "d-step 138 epoch 1 : .......... average_loss = 0.3233, train_acc = 0.8921, val_acc = 0.5840\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5850\n",
            "d-step 139 epoch 1 : .......... average_loss = 0.3161, train_acc = 0.8938, val_acc = 0.5980\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5990\n",
            "d-step 140 epoch 1 : .......... average_loss = 0.3112, train_acc = 0.8976, val_acc = 0.5890\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5920\n",
            "d-step 141 epoch 1 : .......... average_loss = 0.3091, train_acc = 0.8979, val_acc = 0.5540\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5570\n",
            "d-step 142 epoch 1 : .......... average_loss = 0.3152, train_acc = 0.8945, val_acc = 0.5840\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5870\n",
            "d-step 143 epoch 1 : .......... average_loss = 0.3145, train_acc = 0.8951, val_acc = 0.6090\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.6210\n",
            "d-step 144 epoch 1 : .......... average_loss = 0.3087, train_acc = 0.8969, val_acc = 0.6060\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5970\n",
            "d-step 145 epoch 1 : .......... average_loss = 0.3158, train_acc = 0.8956, val_acc = 0.6160\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.6140\n",
            "d-step 146 epoch 1 : .......... average_loss = 0.3077, train_acc = 0.8982, val_acc = 0.5940\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5890\n",
            "d-step 147 epoch 1 : .......... average_loss = 0.3175, train_acc = 0.8922, val_acc = 0.5920\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.6030\n",
            "d-step 148 epoch 1 : .......... average_loss = 0.2962, train_acc = 0.9026, val_acc = 0.6100\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.6150\n",
            "d-step 149 epoch 1 : .......... average_loss = 0.3076, train_acc = 0.8984, val_acc = 0.6320\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.6390\n",
            "d-step 150 epoch 1 : .......... average_loss = 0.3085, train_acc = 0.8971, val_acc = 0.6050\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.6060\n",
            "d-step 151 epoch 1 : .......... average_loss = 0.3034, train_acc = 0.9006, val_acc = 0.5960\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.6050\n",
            "d-step 152 epoch 1 : .......... average_loss = 0.3065, train_acc = 0.8983, val_acc = 0.6010\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.6060\n",
            "d-step 153 epoch 1 : .......... average_loss = 0.2990, train_acc = 0.9024, val_acc = 0.5900\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5910\n",
            "d-step 154 epoch 1 : .......... average_loss = 0.3008, train_acc = 0.9014, val_acc = 0.6170\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.6100\n",
            "d-step 155 epoch 1 : .......... average_loss = 0.2991, train_acc = 0.9022, val_acc = 0.6060\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5980\n",
            "d-step 156 epoch 1 : .......... average_loss = 0.3012, train_acc = 0.9006, val_acc = 0.6240\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.6240\n",
            "d-step 157 epoch 1 : .......... average_loss = 0.2976, train_acc = 0.9022, val_acc = 0.6170\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.6180\n",
            "d-step 158 epoch 1 : .......... average_loss = 0.3020, train_acc = 0.9005, val_acc = 0.6250\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.6190\n",
            "d-step 159 epoch 1 : .......... average_loss = 0.3054, train_acc = 0.8994, val_acc = 0.6350\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.6310\n",
            "d-step 160 epoch 1 : .......... average_loss = 0.2985, train_acc = 0.9031, val_acc = 0.6130\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.6160\n",
            "d-step 161 epoch 1 : .......... average_loss = 0.2937, train_acc = 0.9039, val_acc = 0.5950\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5890\n",
            "d-step 162 epoch 1 : .......... average_loss = 0.2987, train_acc = 0.9019, val_acc = 0.6160\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.6220\n",
            "d-step 163 epoch 1 : .......... average_loss = 0.2969, train_acc = 0.9028, val_acc = 0.6220\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.6140\n",
            "d-step 164 epoch 1 : .......... average_loss = 0.2969, train_acc = 0.9033, val_acc = 0.5960\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5970\n",
            "d-step 165 epoch 1 : .......... average_loss = 0.2936, train_acc = 0.9036, val_acc = 0.6190\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.6150\n",
            "d-step 166 epoch 1 : .......... average_loss = 0.2946, train_acc = 0.9036, val_acc = 0.6250\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.6290\n",
            "d-step 167 epoch 1 : .......... average_loss = 0.2952, train_acc = 0.9041, val_acc = 0.6110\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.6060\n",
            "d-step 168 epoch 1 : .......... average_loss = 0.2862, train_acc = 0.9079, val_acc = 0.6210\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.6170\n",
            "d-step 169 epoch 1 : .......... average_loss = 0.2921, train_acc = 0.9052, val_acc = 0.6480\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.6530\n",
            "d-step 170 epoch 1 : .......... average_loss = 0.2906, train_acc = 0.9048, val_acc = 0.6330\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.6420\n",
            "d-step 171 epoch 1 : .......... average_loss = 0.2837, train_acc = 0.9089, val_acc = 0.6400\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.6440\n",
            "d-step 172 epoch 1 : .......... average_loss = 0.2931, train_acc = 0.9040, val_acc = 0.5940\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5870\n",
            "d-step 173 epoch 1 : .......... average_loss = 0.2921, train_acc = 0.9051, val_acc = 0.6410\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.6290\n",
            "d-step 174 epoch 1 : .......... average_loss = 0.2831, train_acc = 0.9079, val_acc = 0.6320\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.6300\n",
            "d-step 175 epoch 1 : .......... average_loss = 0.2858, train_acc = 0.9073, val_acc = 0.6100\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.6110\n",
            "d-step 176 epoch 1 : .......... average_loss = 0.2807, train_acc = 0.9084, val_acc = 0.6450\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.6480\n",
            "d-step 177 epoch 1 : .......... average_loss = 0.2869, train_acc = 0.9070, val_acc = 0.6460\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.6420\n",
            "d-step 178 epoch 1 : .......... average_loss = 0.2855, train_acc = 0.9085, val_acc = 0.6180\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.6190\n",
            "d-step 179 epoch 1 : .......... average_loss = 0.2881, train_acc = 0.9070, val_acc = 0.6450\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.6440\n",
            "d-step 180 epoch 1 : .......... average_loss = 0.2844, train_acc = 0.9094, val_acc = 0.6500\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.6510\n",
            "d-step 181 epoch 1 : .......... average_loss = 0.2747, train_acc = 0.9120, val_acc = 0.6250\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.6290\n",
            "d-step 182 epoch 1 : .......... average_loss = 0.2778, train_acc = 0.9107, val_acc = 0.6220\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.6220\n",
            "d-step 183 epoch 1 : .......... average_loss = 0.2724, train_acc = 0.9134, val_acc = 0.6680\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.6750\n",
            "d-step 184 epoch 1 : .......... average_loss = 0.2823, train_acc = 0.9093, val_acc = 0.5950\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5920\n",
            "d-step 185 epoch 1 : .......... average_loss = 0.2837, train_acc = 0.9092, val_acc = 0.6440\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.6480\n",
            "d-step 186 epoch 1 : .......... average_loss = 0.2782, train_acc = 0.9112, val_acc = 0.6200\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.6220\n",
            "d-step 187 epoch 1 : .......... average_loss = 0.2791, train_acc = 0.9116, val_acc = 0.6560\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.6580\n",
            "d-step 188 epoch 1 : .......... average_loss = 0.2746, train_acc = 0.9123, val_acc = 0.6500\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.6660\n",
            "d-step 189 epoch 1 : .......... average_loss = 0.2795, train_acc = 0.9109, val_acc = 0.6480\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.6480\n",
            "d-step 190 epoch 1 : .......... average_loss = 0.2800, train_acc = 0.9096, val_acc = 0.6710\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.6690\n",
            "d-step 191 epoch 1 : .......... average_loss = 0.2812, train_acc = 0.9090, val_acc = 0.6740\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.6780\n",
            "d-step 192 epoch 1 : .......... average_loss = 0.2691, train_acc = 0.9150, val_acc = 0.6730\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.6630\n",
            "d-step 193 epoch 1 : .......... average_loss = 0.2663, train_acc = 0.9149, val_acc = 0.6370\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.6340\n",
            "d-step 194 epoch 1 : .......... average_loss = 0.2691, train_acc = 0.9146, val_acc = 0.6560\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.6530\n",
            "d-step 195 epoch 1 : .......... average_loss = 0.2744, train_acc = 0.9116, val_acc = 0.6460\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.6510\n",
            "d-step 196 epoch 1 : .......... average_loss = 0.2736, train_acc = 0.9135, val_acc = 0.6730\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.6740\n",
            "d-step 197 epoch 1 : .......... average_loss = 0.2714, train_acc = 0.9135, val_acc = 0.6100\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.6140\n",
            "d-step 198 epoch 1 : .......... average_loss = 0.2762, train_acc = 0.9114, val_acc = 0.7010\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.6900\n",
            "d-step 199 epoch 1 : .......... average_loss = 0.2663, train_acc = 0.9154, val_acc = 0.6690\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.6630\n",
            "d-step 200 epoch 1 : .......... average_loss = 0.2684, train_acc = 0.9161, val_acc = 0.6750\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.6740\n",
            "d-step 201 epoch 1 : .......... average_loss = 0.2692, train_acc = 0.9148, val_acc = 0.6260\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.6270\n",
            "d-step 202 epoch 1 : .......... average_loss = 0.2696, train_acc = 0.9154, val_acc = 0.6870\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.6870\n",
            "d-step 203 epoch 1 : .......... average_loss = 0.2678, train_acc = 0.9140, val_acc = 0.6730\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.6770\n",
            "d-step 204 epoch 1 : .......... average_loss = 0.2719, train_acc = 0.9129, val_acc = 0.6520\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.6510\n",
            "d-step 205 epoch 1 : .......... average_loss = 0.2587, train_acc = 0.9183, val_acc = 0.6990\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7030\n",
            "d-step 206 epoch 1 : .......... average_loss = 0.2609, train_acc = 0.9183, val_acc = 0.6700\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.6690\n",
            "d-step 207 epoch 1 : .......... average_loss = 0.2671, train_acc = 0.9163, val_acc = 0.6900\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.6850\n",
            "d-step 208 epoch 1 : .......... average_loss = 0.2640, train_acc = 0.9173, val_acc = 0.6800\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.6860\n",
            "d-step 209 epoch 1 : .......... average_loss = 0.2627, train_acc = 0.9173, val_acc = 0.6660\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.6640\n",
            "d-step 210 epoch 1 : .......... average_loss = 0.2591, train_acc = 0.9192, val_acc = 0.6860\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.6840\n",
            "d-step 211 epoch 1 : .......... average_loss = 0.2618, train_acc = 0.9179, val_acc = 0.6900\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.6880\n",
            "d-step 212 epoch 1 : .......... average_loss = 0.2596, train_acc = 0.9188, val_acc = 0.7020\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7020\n",
            "d-step 213 epoch 1 : .......... average_loss = 0.2596, train_acc = 0.9184, val_acc = 0.6990\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.6890\n",
            "d-step 214 epoch 1 : .......... average_loss = 0.2563, train_acc = 0.9200, val_acc = 0.6960\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7020\n",
            "d-step 215 epoch 1 : .......... average_loss = 0.2559, train_acc = 0.9199, val_acc = 0.6970\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7000\n",
            "d-step 216 epoch 1 : .......... average_loss = 0.2575, train_acc = 0.9191, val_acc = 0.6990\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.6920\n",
            "d-step 217 epoch 1 : .......... average_loss = 0.2619, train_acc = 0.9174, val_acc = 0.6670\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.6640\n",
            "d-step 218 epoch 1 : .......... average_loss = 0.2556, train_acc = 0.9210, val_acc = 0.6810\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.6800\n",
            "d-step 219 epoch 1 : .......... average_loss = 0.2549, train_acc = 0.9202, val_acc = 0.6940\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.6980\n",
            "d-step 220 epoch 1 : .......... average_loss = 0.2531, train_acc = 0.9211, val_acc = 0.6810\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.6900\n",
            "d-step 221 epoch 1 : .......... average_loss = 0.2576, train_acc = 0.9202, val_acc = 0.7070\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.6980\n",
            "d-step 222 epoch 1 : .......... average_loss = 0.2621, train_acc = 0.9167, val_acc = 0.6700\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.6590\n",
            "d-step 223 epoch 1 : .......... average_loss = 0.2589, train_acc = 0.9183, val_acc = 0.6740\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.6790\n",
            "d-step 224 epoch 1 : .......... average_loss = 0.2488, train_acc = 0.9234, val_acc = 0.6720\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.6740\n",
            "d-step 225 epoch 1 : .......... average_loss = 0.2610, train_acc = 0.9182, val_acc = 0.6950\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.6990\n",
            "d-step 226 epoch 1 : .......... average_loss = 0.2556, train_acc = 0.9194, val_acc = 0.7000\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7040\n",
            "d-step 227 epoch 1 : .......... average_loss = 0.2565, train_acc = 0.9200, val_acc = 0.6680\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.6630\n",
            "d-step 228 epoch 1 : .......... average_loss = 0.2509, train_acc = 0.9224, val_acc = 0.7060\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7090\n",
            "d-step 229 epoch 1 : .......... average_loss = 0.2554, train_acc = 0.9202, val_acc = 0.6330\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.6310\n",
            "d-step 230 epoch 1 : .......... average_loss = 0.2490, train_acc = 0.9222, val_acc = 0.7060\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7060\n",
            "d-step 231 epoch 1 : .......... average_loss = 0.2447, train_acc = 0.9255, val_acc = 0.7020\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.6960\n",
            "d-step 232 epoch 1 : .......... average_loss = 0.2495, train_acc = 0.9225, val_acc = 0.7000\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7020\n",
            "d-step 233 epoch 1 : .......... average_loss = 0.2452, train_acc = 0.9237, val_acc = 0.6610\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.6560\n",
            "d-step 234 epoch 1 : .......... average_loss = 0.2511, train_acc = 0.9236, val_acc = 0.7220\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7140\n",
            "d-step 235 epoch 1 : .......... average_loss = 0.2449, train_acc = 0.9252, val_acc = 0.6980\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.6950\n",
            "d-step 236 epoch 1 : .......... average_loss = 0.2433, train_acc = 0.9266, val_acc = 0.7010\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7050\n",
            "d-step 237 epoch 1 : .......... average_loss = 0.2429, train_acc = 0.9260, val_acc = 0.6850\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.6880\n",
            "d-step 238 epoch 1 : .......... average_loss = 0.2478, train_acc = 0.9232, val_acc = 0.7160\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7190\n",
            "d-step 239 epoch 1 : .......... average_loss = 0.2508, train_acc = 0.9230, val_acc = 0.6860\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.6830\n",
            "d-step 240 epoch 1 : .......... average_loss = 0.2361, train_acc = 0.9280, val_acc = 0.7050\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7050\n",
            "d-step 241 epoch 1 : .......... average_loss = 0.2418, train_acc = 0.9250, val_acc = 0.6960\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7060\n",
            "d-step 242 epoch 1 : .......... average_loss = 0.2460, train_acc = 0.9242, val_acc = 0.7100\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7030\n",
            "d-step 243 epoch 1 : .......... average_loss = 0.2464, train_acc = 0.9246, val_acc = 0.6540\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.6450\n",
            "d-step 244 epoch 1 : .......... average_loss = 0.2464, train_acc = 0.9248, val_acc = 0.7010\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7030\n",
            "d-step 245 epoch 1 : .......... average_loss = 0.2439, train_acc = 0.9252, val_acc = 0.6920\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.6890\n",
            "d-step 246 epoch 1 : .......... average_loss = 0.2331, train_acc = 0.9300, val_acc = 0.7150\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7200\n",
            "d-step 247 epoch 1 : .......... average_loss = 0.2430, train_acc = 0.9262, val_acc = 0.7100\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.6930\n",
            "d-step 248 epoch 1 : .......... average_loss = 0.2390, train_acc = 0.9286, val_acc = 0.7180\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7240\n",
            "d-step 249 epoch 1 : .......... average_loss = 0.2360, train_acc = 0.9284, val_acc = 0.7180\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7270\n",
            "d-step 250 epoch 1 : .......... average_loss = 0.2327, train_acc = 0.9301, val_acc = 0.7130\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7080\n",
            "d-step 251 epoch 1 : .......... average_loss = 0.2459, train_acc = 0.9245, val_acc = 0.7200\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7250\n",
            "d-step 252 epoch 1 : .......... average_loss = 0.2322, train_acc = 0.9296, val_acc = 0.7160\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7180\n",
            "d-step 253 epoch 1 : .......... average_loss = 0.2329, train_acc = 0.9301, val_acc = 0.7250\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7240\n",
            "d-step 254 epoch 1 : .......... average_loss = 0.2395, train_acc = 0.9279, val_acc = 0.6950\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.6930\n",
            "d-step 255 epoch 1 : .......... average_loss = 0.2429, train_acc = 0.9257, val_acc = 0.7160\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7110\n",
            "d-step 256 epoch 1 : .......... average_loss = 0.2362, train_acc = 0.9295, val_acc = 0.7300\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7240\n",
            "d-step 257 epoch 1 : .......... average_loss = 0.2431, train_acc = 0.9245, val_acc = 0.7050\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7170\n",
            "d-step 258 epoch 1 : .......... average_loss = 0.2322, train_acc = 0.9314, val_acc = 0.7290\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7280\n",
            "d-step 259 epoch 1 : .......... average_loss = 0.2344, train_acc = 0.9286, val_acc = 0.7280\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7250\n",
            "d-step 260 epoch 1 : .......... average_loss = 0.2298, train_acc = 0.9303, val_acc = 0.7130\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7190\n",
            "d-step 261 epoch 1 : .......... average_loss = 0.2330, train_acc = 0.9306, val_acc = 0.7110\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7080\n",
            "d-step 262 epoch 1 : .......... average_loss = 0.2352, train_acc = 0.9286, val_acc = 0.7150\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7150\n",
            "d-step 263 epoch 1 : .......... average_loss = 0.2324, train_acc = 0.9291, val_acc = 0.7000\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.6980\n",
            "d-step 264 epoch 1 : .......... average_loss = 0.2326, train_acc = 0.9305, val_acc = 0.7310\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7230\n",
            "d-step 265 epoch 1 : .......... average_loss = 0.2371, train_acc = 0.9267, val_acc = 0.7520\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7470\n",
            "d-step 266 epoch 1 : .......... average_loss = 0.2335, train_acc = 0.9303, val_acc = 0.7150\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7090\n",
            "d-step 267 epoch 1 : .......... average_loss = 0.2311, train_acc = 0.9304, val_acc = 0.7340\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7390\n",
            "d-step 268 epoch 1 : .......... average_loss = 0.2322, train_acc = 0.9301, val_acc = 0.7580\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7580\n",
            "d-step 269 epoch 1 : .......... average_loss = 0.2327, train_acc = 0.9285, val_acc = 0.7210\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7180\n",
            "d-step 270 epoch 1 : .......... average_loss = 0.2251, train_acc = 0.9335, val_acc = 0.7200\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7180\n",
            "d-step 271 epoch 1 : .......... average_loss = 0.2302, train_acc = 0.9297, val_acc = 0.7270\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7350\n",
            "d-step 272 epoch 1 : .......... average_loss = 0.2252, train_acc = 0.9325, val_acc = 0.7270\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7240\n",
            "d-step 273 epoch 1 : .......... average_loss = 0.2304, train_acc = 0.9310, val_acc = 0.7450\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7440\n",
            "d-step 274 epoch 1 : .......... average_loss = 0.2263, train_acc = 0.9323, val_acc = 0.7470\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7510\n",
            "d-step 275 epoch 1 : .......... average_loss = 0.2300, train_acc = 0.9311, val_acc = 0.7400\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7340\n",
            "d-step 276 epoch 1 : .......... average_loss = 0.2266, train_acc = 0.9343, val_acc = 0.7270\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7190\n",
            "d-step 277 epoch 1 : .......... average_loss = 0.2249, train_acc = 0.9337, val_acc = 0.7160\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7090\n",
            "d-step 278 epoch 1 : .......... average_loss = 0.2255, train_acc = 0.9317, val_acc = 0.7300\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7300\n",
            "d-step 279 epoch 1 : .......... average_loss = 0.2272, train_acc = 0.9325, val_acc = 0.7190\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7200\n",
            "d-step 280 epoch 1 : .......... average_loss = 0.2347, train_acc = 0.9288, val_acc = 0.7510\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7490\n",
            "d-step 281 epoch 1 : .......... average_loss = 0.2234, train_acc = 0.9331, val_acc = 0.7470\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7520\n",
            "d-step 282 epoch 1 : .......... average_loss = 0.2274, train_acc = 0.9333, val_acc = 0.7410\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7420\n",
            "d-step 283 epoch 1 : .......... average_loss = 0.2217, train_acc = 0.9348, val_acc = 0.7520\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7600\n",
            "d-step 284 epoch 1 : .......... average_loss = 0.2307, train_acc = 0.9310, val_acc = 0.6840\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.6870\n",
            "d-step 285 epoch 1 : .......... average_loss = 0.2303, train_acc = 0.9313, val_acc = 0.7340\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7370\n",
            "d-step 286 epoch 1 : .......... average_loss = 0.2248, train_acc = 0.9335, val_acc = 0.7420\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7500\n",
            "d-step 287 epoch 1 : .......... average_loss = 0.2215, train_acc = 0.9348, val_acc = 0.7440\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7380\n",
            "d-step 288 epoch 1 : .......... average_loss = 0.2258, train_acc = 0.9332, val_acc = 0.7320\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7300\n",
            "d-step 289 epoch 1 : .......... average_loss = 0.2203, train_acc = 0.9341, val_acc = 0.7280\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7230\n",
            "d-step 290 epoch 1 : .......... average_loss = 0.2205, train_acc = 0.9345, val_acc = 0.7540\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7490\n",
            "d-step 291 epoch 1 : .......... average_loss = 0.2176, train_acc = 0.9347, val_acc = 0.7430\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7450\n",
            "d-step 292 epoch 1 : .......... average_loss = 0.2224, train_acc = 0.9347, val_acc = 0.7670\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7590\n",
            "d-step 293 epoch 1 : .......... average_loss = 0.2210, train_acc = 0.9345, val_acc = 0.7590\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7540\n",
            "d-step 294 epoch 1 : .......... average_loss = 0.2204, train_acc = 0.9353, val_acc = 0.7480\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7440\n",
            "d-step 295 epoch 1 : .......... average_loss = 0.2310, train_acc = 0.9308, val_acc = 0.7430\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7360\n",
            "d-step 296 epoch 1 : .......... average_loss = 0.2144, train_acc = 0.9381, val_acc = 0.7390\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7580\n",
            "d-step 297 epoch 1 : .......... average_loss = 0.2181, train_acc = 0.9361, val_acc = 0.7420\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7340\n",
            "d-step 298 epoch 1 : .......... average_loss = 0.2129, train_acc = 0.9364, val_acc = 0.7370\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7350\n",
            "d-step 299 epoch 1 : .......... average_loss = 0.2217, train_acc = 0.9334, val_acc = 0.7590\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7580\n",
            "d-step 300 epoch 1 : .......... average_loss = 0.2180, train_acc = 0.9349, val_acc = 0.7470\n",
            "CPU times: user 4min 13s, sys: 1min 42s, total: 5min 55s\n",
            "Wall time: 6min 1s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j8Znhasa7gr5"
      },
      "source": [
        "Состязательное обучение. Обучение генератора на основе обучения с подкреплением"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oELznd8Bs6-q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dce2f51d-3bd5-489f-a7ad-1c7807b2ab2f"
      },
      "source": [
        "test_mle(gen, data_file_tensor_train, data_file_tensor_test)\n",
        "# average_train_NLL = 1.7516 average_test_NLL = 1.9832"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "average_train_NLL = 4.1744 average_test_NLL = 4.5120\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V9gy5KOOuibf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6f33ebc-7c59-43f0-dfd2-2d16ad22edfa"
      },
      "source": [
        "%%time\n",
        "# gen_optimizer = optim.Adagrad(gen.parameters(), lr=0.0005)#Adam #, lr=0.0005\n",
        "# dis_optimizer = optim.Adagrad(dis.parameters())\n",
        "# gen_optimizer = optim.Adam(gen.parameters(), lr=0.0001)#Adam #, lr=0.0005\n",
        "# dis_optimizer = optim.Adagrad(dis.parameters(), lr=0.001)#, lr=0.002\n",
        "\n",
        "# состязательное обучение генератора\n",
        "print('\\nStarting Adversarial Training...')\n",
        "\n",
        "for epoch in range(ADV_TRAIN_EPOCHS):# ADV_TRAIN_EPOCHS\n",
        "    print('\\n--------\\nEPOCH %d\\n--------' % (epoch+1))\n",
        "    # обучение генератора\n",
        "    print('\\nAdversarial Training Generator : ', end='')\n",
        "    train_generator_PG(gen, gen_optimizer, dis, 1)#\n",
        "\n",
        "    # тестирование nll\n",
        "    print('\\nTesting Generator : ', end='')\n",
        "    test_mle(gen, data_file_tensor_train, data_file_tensor_test)\n",
        "\n",
        "    # обучение дискриминатора\n",
        "    print('\\nAdversarial Training Discriminator : ')\n",
        "    train_discriminator(dis, dis_optimizer, data_file_tensor_train, gen, 5, 1)#3, 1\n",
        "\n",
        "# сохранение результата обучения\n",
        "save_models(data_file_tensor_train, gen, dis, gen_optimizer, dis_optimizer,\n",
        "            FILE_PATHS['saved_models'] + r'/' + r'seqgan_adversarial_training.pytorch')\n",
        "# epoch 3 : .......... average_train_NLL = 1.8005 average_test_NLL = 1.9824\n",
        "# average_train_NLL = 1.7340 average_test_NLL = 2.0599"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Starting Adversarial Training...\n",
            "\n",
            "--------\n",
            "EPOCH 1\n",
            "--------\n",
            "\n",
            "Adversarial Training Generator : \n",
            "\n",
            "Testing Generator : average_train_NLL = 4.1758 average_test_NLL = 4.5144\n",
            "\n",
            "Adversarial Training Discriminator : \n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7470\n",
            "d-step 1 epoch 1 : .......... average_loss = 0.2180, train_acc = 0.9357, val_acc = 0.7370\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7450\n",
            "d-step 2 epoch 1 : .......... average_loss = 0.2151, train_acc = 0.9364, val_acc = 0.7250\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7310\n",
            "d-step 3 epoch 1 : .......... average_loss = 0.2179, train_acc = 0.9364, val_acc = 0.7500\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7540\n",
            "d-step 4 epoch 1 : .......... average_loss = 0.2093, train_acc = 0.9377, val_acc = 0.7430\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7480\n",
            "d-step 5 epoch 1 : .......... average_loss = 0.2116, train_acc = 0.9376, val_acc = 0.7600\n",
            "\n",
            "--------\n",
            "EPOCH 2\n",
            "--------\n",
            "\n",
            "Adversarial Training Generator : \n",
            "\n",
            "Testing Generator : average_train_NLL = 4.1776 average_test_NLL = 4.5166\n",
            "\n",
            "Adversarial Training Discriminator : \n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7730\n",
            "d-step 1 epoch 1 : .......... average_loss = 0.2111, train_acc = 0.9384, val_acc = 0.7650\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7750\n",
            "d-step 2 epoch 1 : .......... average_loss = 0.2192, train_acc = 0.9361, val_acc = 0.7840\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7810\n",
            "d-step 3 epoch 1 : .......... average_loss = 0.2103, train_acc = 0.9382, val_acc = 0.7530\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7500\n",
            "d-step 4 epoch 1 : .......... average_loss = 0.2079, train_acc = 0.9397, val_acc = 0.7730\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7730\n",
            "d-step 5 epoch 1 : .......... average_loss = 0.2158, train_acc = 0.9358, val_acc = 0.7740\n",
            "\n",
            "--------\n",
            "EPOCH 3\n",
            "--------\n",
            "\n",
            "Adversarial Training Generator : \n",
            "\n",
            "Testing Generator : average_train_NLL = 4.1780 average_test_NLL = 4.5170\n",
            "\n",
            "Adversarial Training Discriminator : \n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7870\n",
            "d-step 1 epoch 1 : .......... average_loss = 0.2074, train_acc = 0.9399, val_acc = 0.7730\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7570\n",
            "d-step 2 epoch 1 : .......... average_loss = 0.2115, train_acc = 0.9374, val_acc = 0.7740\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7710\n",
            "d-step 3 epoch 1 : .......... average_loss = 0.2126, train_acc = 0.9383, val_acc = 0.7610\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7590\n",
            "d-step 4 epoch 1 : .......... average_loss = 0.2069, train_acc = 0.9404, val_acc = 0.7490\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7470\n",
            "d-step 5 epoch 1 : .......... average_loss = 0.2150, train_acc = 0.9368, val_acc = 0.7740\n",
            "\n",
            "--------\n",
            "EPOCH 4\n",
            "--------\n",
            "\n",
            "Adversarial Training Generator : \n",
            "\n",
            "Testing Generator : average_train_NLL = 4.1771 average_test_NLL = 4.5159\n",
            "\n",
            "Adversarial Training Discriminator : \n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7700\n",
            "d-step 1 epoch 1 : .......... average_loss = 0.2183, train_acc = 0.9356, val_acc = 0.7720\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7760\n",
            "d-step 2 epoch 1 : .......... average_loss = 0.2149, train_acc = 0.9365, val_acc = 0.7810\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7780\n",
            "d-step 3 epoch 1 : .......... average_loss = 0.2099, train_acc = 0.9381, val_acc = 0.7280\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7300\n",
            "d-step 4 epoch 1 : .......... average_loss = 0.2126, train_acc = 0.9375, val_acc = 0.7830\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7780\n",
            "d-step 5 epoch 1 : .......... average_loss = 0.2040, train_acc = 0.9414, val_acc = 0.7710\n",
            "\n",
            "--------\n",
            "EPOCH 5\n",
            "--------\n",
            "\n",
            "Adversarial Training Generator : \n",
            "\n",
            "Testing Generator : average_train_NLL = 4.1762 average_test_NLL = 4.5144\n",
            "\n",
            "Adversarial Training Discriminator : \n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7490\n",
            "d-step 1 epoch 1 : .......... average_loss = 0.2092, train_acc = 0.9397, val_acc = 0.7650\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7640\n",
            "d-step 2 epoch 1 : .......... average_loss = 0.2152, train_acc = 0.9364, val_acc = 0.7550\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7520\n",
            "d-step 3 epoch 1 : .......... average_loss = 0.2127, train_acc = 0.9370, val_acc = 0.7620\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7580\n",
            "d-step 4 epoch 1 : .......... average_loss = 0.2055, train_acc = 0.9406, val_acc = 0.7380\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7350\n",
            "d-step 5 epoch 1 : .......... average_loss = 0.2124, train_acc = 0.9369, val_acc = 0.7340\n",
            "\n",
            "--------\n",
            "EPOCH 6\n",
            "--------\n",
            "\n",
            "Adversarial Training Generator : \n",
            "\n",
            "Testing Generator : average_train_NLL = 4.1764 average_test_NLL = 4.5136\n",
            "\n",
            "Adversarial Training Discriminator : \n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7520\n",
            "d-step 1 epoch 1 : .......... average_loss = 0.2123, train_acc = 0.9365, val_acc = 0.7640\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7700\n",
            "d-step 2 epoch 1 : .......... average_loss = 0.2135, train_acc = 0.9375, val_acc = 0.7710\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7680\n",
            "d-step 3 epoch 1 : .......... average_loss = 0.1999, train_acc = 0.9428, val_acc = 0.7700\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7710\n",
            "d-step 4 epoch 1 : .......... average_loss = 0.2090, train_acc = 0.9383, val_acc = 0.7840\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7790\n",
            "d-step 5 epoch 1 : .......... average_loss = 0.2120, train_acc = 0.9382, val_acc = 0.7820\n",
            "\n",
            "--------\n",
            "EPOCH 7\n",
            "--------\n",
            "\n",
            "Adversarial Training Generator : \n",
            "\n",
            "Testing Generator : average_train_NLL = 4.1787 average_test_NLL = 4.5146\n",
            "\n",
            "Adversarial Training Discriminator : \n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7610\n",
            "d-step 1 epoch 1 : .......... average_loss = 0.2130, train_acc = 0.9375, val_acc = 0.7430\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7530\n",
            "d-step 2 epoch 1 : .......... average_loss = 0.2185, train_acc = 0.9344, val_acc = 0.7590\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7600\n",
            "d-step 3 epoch 1 : .......... average_loss = 0.2086, train_acc = 0.9369, val_acc = 0.7460\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7420\n",
            "d-step 4 epoch 1 : .......... average_loss = 0.2127, train_acc = 0.9369, val_acc = 0.7760\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7680\n",
            "d-step 5 epoch 1 : .......... average_loss = 0.2144, train_acc = 0.9364, val_acc = 0.7170\n",
            "\n",
            "--------\n",
            "EPOCH 8\n",
            "--------\n",
            "\n",
            "Adversarial Training Generator : \n",
            "\n",
            "Testing Generator : average_train_NLL = 4.1823 average_test_NLL = 4.5171\n",
            "\n",
            "Adversarial Training Discriminator : \n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7110\n",
            "d-step 1 epoch 1 : .......... average_loss = 0.2098, train_acc = 0.9382, val_acc = 0.7660\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7600\n",
            "d-step 2 epoch 1 : .......... average_loss = 0.2155, train_acc = 0.9351, val_acc = 0.7650\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7610\n",
            "d-step 3 epoch 1 : .......... average_loss = 0.2204, train_acc = 0.9332, val_acc = 0.7490\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7480\n",
            "d-step 4 epoch 1 : .......... average_loss = 0.2118, train_acc = 0.9371, val_acc = 0.7450\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7470\n",
            "d-step 5 epoch 1 : .......... average_loss = 0.2094, train_acc = 0.9375, val_acc = 0.7460\n",
            "\n",
            "--------\n",
            "EPOCH 9\n",
            "--------\n",
            "\n",
            "Adversarial Training Generator : \n",
            "\n",
            "Testing Generator : average_train_NLL = 4.1860 average_test_NLL = 4.5200\n",
            "\n",
            "Adversarial Training Discriminator : \n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7690\n",
            "d-step 1 epoch 1 : .......... average_loss = 0.2003, train_acc = 0.9408, val_acc = 0.7710\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7730\n",
            "d-step 2 epoch 1 : .......... average_loss = 0.2131, train_acc = 0.9365, val_acc = 0.7630\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7560\n",
            "d-step 3 epoch 1 : .......... average_loss = 0.2008, train_acc = 0.9412, val_acc = 0.7640\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7600\n",
            "d-step 4 epoch 1 : .......... average_loss = 0.2082, train_acc = 0.9381, val_acc = 0.7790\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7870\n",
            "d-step 5 epoch 1 : .......... average_loss = 0.2078, train_acc = 0.9382, val_acc = 0.7800\n",
            "\n",
            "--------\n",
            "EPOCH 10\n",
            "--------\n",
            "\n",
            "Adversarial Training Generator : \n",
            "\n",
            "Testing Generator : average_train_NLL = 4.1888 average_test_NLL = 4.5224\n",
            "\n",
            "Adversarial Training Discriminator : \n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7820\n",
            "d-step 1 epoch 1 : .......... average_loss = 0.2108, train_acc = 0.9375, val_acc = 0.7710\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7740\n",
            "d-step 2 epoch 1 : .......... average_loss = 0.1974, train_acc = 0.9421, val_acc = 0.7700\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7670\n",
            "d-step 3 epoch 1 : .......... average_loss = 0.2000, train_acc = 0.9408, val_acc = 0.7230\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7190\n",
            "d-step 4 epoch 1 : .......... average_loss = 0.2053, train_acc = 0.9389, val_acc = 0.7760\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7740\n",
            "d-step 5 epoch 1 : .......... average_loss = 0.2039, train_acc = 0.9399, val_acc = 0.7440\n",
            "\n",
            "--------\n",
            "EPOCH 11\n",
            "--------\n",
            "\n",
            "Adversarial Training Generator : \n",
            "\n",
            "Testing Generator : average_train_NLL = 4.1898 average_test_NLL = 4.5235\n",
            "\n",
            "Adversarial Training Discriminator : \n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7540\n",
            "d-step 1 epoch 1 : .......... average_loss = 0.2071, train_acc = 0.9381, val_acc = 0.7590\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7620\n",
            "d-step 2 epoch 1 : .......... average_loss = 0.2077, train_acc = 0.9380, val_acc = 0.7620\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7560\n",
            "d-step 3 epoch 1 : .......... average_loss = 0.2057, train_acc = 0.9376, val_acc = 0.7720\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7730\n",
            "d-step 4 epoch 1 : .......... average_loss = 0.2082, train_acc = 0.9365, val_acc = 0.7770\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7770\n",
            "d-step 5 epoch 1 : .......... average_loss = 0.2060, train_acc = 0.9384, val_acc = 0.7540\n",
            "\n",
            "--------\n",
            "EPOCH 12\n",
            "--------\n",
            "\n",
            "Adversarial Training Generator : \n",
            "\n",
            "Testing Generator : average_train_NLL = 4.1894 average_test_NLL = 4.5237\n",
            "\n",
            "Adversarial Training Discriminator : \n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7510\n",
            "d-step 1 epoch 1 : .......... average_loss = 0.2107, train_acc = 0.9377, val_acc = 0.7700\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7730\n",
            "d-step 2 epoch 1 : .......... average_loss = 0.2110, train_acc = 0.9361, val_acc = 0.7710\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7660\n",
            "d-step 3 epoch 1 : .......... average_loss = 0.2008, train_acc = 0.9398, val_acc = 0.7480\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7500\n",
            "d-step 4 epoch 1 : .......... average_loss = 0.2014, train_acc = 0.9394, val_acc = 0.7730\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7740\n",
            "d-step 5 epoch 1 : .......... average_loss = 0.2137, train_acc = 0.9355, val_acc = 0.7700\n",
            "\n",
            "--------\n",
            "EPOCH 13\n",
            "--------\n",
            "\n",
            "Adversarial Training Generator : \n",
            "\n",
            "Testing Generator : average_train_NLL = 4.1886 average_test_NLL = 4.5236\n",
            "\n",
            "Adversarial Training Discriminator : \n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7650\n",
            "d-step 1 epoch 1 : .......... average_loss = 0.2082, train_acc = 0.9367, val_acc = 0.7850\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7830\n",
            "d-step 2 epoch 1 : .......... average_loss = 0.2085, train_acc = 0.9378, val_acc = 0.7770\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7780\n",
            "d-step 3 epoch 1 : .......... average_loss = 0.2013, train_acc = 0.9396, val_acc = 0.7610\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7600\n",
            "d-step 4 epoch 1 : .......... average_loss = 0.2129, train_acc = 0.9355, val_acc = 0.7760\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7730\n",
            "d-step 5 epoch 1 : .......... average_loss = 0.2087, train_acc = 0.9367, val_acc = 0.7720\n",
            "\n",
            "--------\n",
            "EPOCH 14\n",
            "--------\n",
            "\n",
            "Adversarial Training Generator : \n",
            "\n",
            "Testing Generator : average_train_NLL = 4.1881 average_test_NLL = 4.5239\n",
            "\n",
            "Adversarial Training Discriminator : \n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7540\n",
            "d-step 1 epoch 1 : .......... average_loss = 0.2052, train_acc = 0.9384, val_acc = 0.7660\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7690\n",
            "d-step 2 epoch 1 : .......... average_loss = 0.2104, train_acc = 0.9364, val_acc = 0.7820\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7770\n",
            "d-step 3 epoch 1 : .......... average_loss = 0.2038, train_acc = 0.9387, val_acc = 0.7870\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7810\n",
            "d-step 4 epoch 1 : .......... average_loss = 0.2103, train_acc = 0.9368, val_acc = 0.7730\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7660\n",
            "d-step 5 epoch 1 : .......... average_loss = 0.2043, train_acc = 0.9397, val_acc = 0.7640\n",
            "\n",
            "--------\n",
            "EPOCH 15\n",
            "--------\n",
            "\n",
            "Adversarial Training Generator : \n",
            "\n",
            "Testing Generator : average_train_NLL = 4.1880 average_test_NLL = 4.5246\n",
            "\n",
            "Adversarial Training Discriminator : \n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7660\n",
            "d-step 1 epoch 1 : .......... average_loss = 0.2081, train_acc = 0.9362, val_acc = 0.7670\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7590\n",
            "d-step 2 epoch 1 : .......... average_loss = 0.2045, train_acc = 0.9378, val_acc = 0.7820\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7760\n",
            "d-step 3 epoch 1 : .......... average_loss = 0.1982, train_acc = 0.9399, val_acc = 0.7690\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7610\n",
            "d-step 4 epoch 1 : .......... average_loss = 0.2140, train_acc = 0.9341, val_acc = 0.7570\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7550\n",
            "d-step 5 epoch 1 : .......... average_loss = 0.2035, train_acc = 0.9401, val_acc = 0.7470\n",
            "\n",
            "--------\n",
            "EPOCH 16\n",
            "--------\n",
            "\n",
            "Adversarial Training Generator : \n",
            "\n",
            "Testing Generator : average_train_NLL = 4.1889 average_test_NLL = 4.5260\n",
            "\n",
            "Adversarial Training Discriminator : \n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7310\n",
            "d-step 1 epoch 1 : .......... average_loss = 0.2058, train_acc = 0.9368, val_acc = 0.7390\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7390\n",
            "d-step 2 epoch 1 : .......... average_loss = 0.2077, train_acc = 0.9363, val_acc = 0.7480\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7520\n",
            "d-step 3 epoch 1 : .......... average_loss = 0.2002, train_acc = 0.9397, val_acc = 0.7590\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7600\n",
            "d-step 4 epoch 1 : .......... average_loss = 0.2095, train_acc = 0.9357, val_acc = 0.7640\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7630\n",
            "d-step 5 epoch 1 : .......... average_loss = 0.2076, train_acc = 0.9372, val_acc = 0.7640\n",
            "\n",
            "--------\n",
            "EPOCH 17\n",
            "--------\n",
            "\n",
            "Adversarial Training Generator : \n",
            "\n",
            "Testing Generator : average_train_NLL = 4.1906 average_test_NLL = 4.5280\n",
            "\n",
            "Adversarial Training Discriminator : \n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7720\n",
            "d-step 1 epoch 1 : .......... average_loss = 0.1980, train_acc = 0.9405, val_acc = 0.7610\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7500\n",
            "d-step 2 epoch 1 : .......... average_loss = 0.2065, train_acc = 0.9373, val_acc = 0.7540\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7530\n",
            "d-step 3 epoch 1 : .......... average_loss = 0.2049, train_acc = 0.9384, val_acc = 0.7310\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7330\n",
            "d-step 4 epoch 1 : .......... average_loss = 0.2062, train_acc = 0.9376, val_acc = 0.7520\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7530\n",
            "d-step 5 epoch 1 : .......... average_loss = 0.2068, train_acc = 0.9371, val_acc = 0.7610\n",
            "\n",
            "--------\n",
            "EPOCH 18\n",
            "--------\n",
            "\n",
            "Adversarial Training Generator : \n",
            "\n",
            "Testing Generator : average_train_NLL = 4.1928 average_test_NLL = 4.5303\n",
            "\n",
            "Adversarial Training Discriminator : \n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7680\n",
            "d-step 1 epoch 1 : .......... average_loss = 0.2090, train_acc = 0.9361, val_acc = 0.7740\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7740\n",
            "d-step 2 epoch 1 : .......... average_loss = 0.2036, train_acc = 0.9372, val_acc = 0.7590\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7530\n",
            "d-step 3 epoch 1 : .......... average_loss = 0.2027, train_acc = 0.9381, val_acc = 0.7580\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7610\n",
            "d-step 4 epoch 1 : .......... average_loss = 0.2014, train_acc = 0.9388, val_acc = 0.7720\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7740\n",
            "d-step 5 epoch 1 : .......... average_loss = 0.2029, train_acc = 0.9387, val_acc = 0.7650\n",
            "\n",
            "--------\n",
            "EPOCH 19\n",
            "--------\n",
            "\n",
            "Adversarial Training Generator : \n",
            "\n",
            "Testing Generator : average_train_NLL = 4.1955 average_test_NLL = 4.5329\n",
            "\n",
            "Adversarial Training Discriminator : \n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7650\n",
            "d-step 1 epoch 1 : .......... average_loss = 0.2073, train_acc = 0.9376, val_acc = 0.7650\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7630\n",
            "d-step 2 epoch 1 : .......... average_loss = 0.1987, train_acc = 0.9398, val_acc = 0.7630\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7590\n",
            "d-step 3 epoch 1 : .......... average_loss = 0.1977, train_acc = 0.9398, val_acc = 0.7740\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7670\n",
            "d-step 4 epoch 1 : .......... average_loss = 0.1995, train_acc = 0.9376, val_acc = 0.7740\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7710\n",
            "d-step 5 epoch 1 : .......... average_loss = 0.2017, train_acc = 0.9385, val_acc = 0.7790\n",
            "\n",
            "--------\n",
            "EPOCH 20\n",
            "--------\n",
            "\n",
            "Adversarial Training Generator : \n",
            "\n",
            "Testing Generator : average_train_NLL = 4.1987 average_test_NLL = 4.5358\n",
            "\n",
            "Adversarial Training Discriminator : \n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7700\n",
            "d-step 1 epoch 1 : .......... average_loss = 0.2047, train_acc = 0.9371, val_acc = 0.7470\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7490\n",
            "d-step 2 epoch 1 : .......... average_loss = 0.2045, train_acc = 0.9363, val_acc = 0.7660\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7700\n",
            "d-step 3 epoch 1 : .......... average_loss = 0.2015, train_acc = 0.9379, val_acc = 0.7600\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7620\n",
            "d-step 4 epoch 1 : .......... average_loss = 0.1991, train_acc = 0.9388, val_acc = 0.7410\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7400\n",
            "d-step 5 epoch 1 : .......... average_loss = 0.2012, train_acc = 0.9384, val_acc = 0.7610\n",
            "\n",
            "--------\n",
            "EPOCH 21\n",
            "--------\n",
            "\n",
            "Adversarial Training Generator : \n",
            "\n",
            "Testing Generator : average_train_NLL = 4.2025 average_test_NLL = 4.5391\n",
            "\n",
            "Adversarial Training Discriminator : \n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7740\n",
            "d-step 1 epoch 1 : .......... average_loss = 0.2043, train_acc = 0.9360, val_acc = 0.7810\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7850\n",
            "d-step 2 epoch 1 : .......... average_loss = 0.2055, train_acc = 0.9351, val_acc = 0.7840\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7830\n",
            "d-step 3 epoch 1 : .......... average_loss = 0.1999, train_acc = 0.9392, val_acc = 0.7670\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7620\n",
            "d-step 4 epoch 1 : .......... average_loss = 0.1978, train_acc = 0.9399, val_acc = 0.7480\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7500\n",
            "d-step 5 epoch 1 : .......... average_loss = 0.1975, train_acc = 0.9388, val_acc = 0.7800\n",
            "\n",
            "--------\n",
            "EPOCH 22\n",
            "--------\n",
            "\n",
            "Adversarial Training Generator : \n",
            "\n",
            "Testing Generator : average_train_NLL = 4.2071 average_test_NLL = 4.5431\n",
            "\n",
            "Adversarial Training Discriminator : \n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7710\n",
            "d-step 1 epoch 1 : .......... average_loss = 0.2062, train_acc = 0.9355, val_acc = 0.7740\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7610\n",
            "d-step 2 epoch 1 : .......... average_loss = 0.1950, train_acc = 0.9395, val_acc = 0.7800\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7860\n",
            "d-step 3 epoch 1 : .......... average_loss = 0.1931, train_acc = 0.9398, val_acc = 0.7770\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7740\n",
            "d-step 4 epoch 1 : .......... average_loss = 0.1962, train_acc = 0.9389, val_acc = 0.7620\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7610\n",
            "d-step 5 epoch 1 : .......... average_loss = 0.1946, train_acc = 0.9405, val_acc = 0.7830\n",
            "\n",
            "--------\n",
            "EPOCH 23\n",
            "--------\n",
            "\n",
            "Adversarial Training Generator : \n",
            "\n",
            "Testing Generator : average_train_NLL = 4.2120 average_test_NLL = 4.5475\n",
            "\n",
            "Adversarial Training Discriminator : \n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7680\n",
            "d-step 1 epoch 1 : .......... average_loss = 0.1981, train_acc = 0.9381, val_acc = 0.7490\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7540\n",
            "d-step 2 epoch 1 : .......... average_loss = 0.2021, train_acc = 0.9355, val_acc = 0.7720\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7760\n",
            "d-step 3 epoch 1 : .......... average_loss = 0.1941, train_acc = 0.9388, val_acc = 0.7700\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7690\n",
            "d-step 4 epoch 1 : .......... average_loss = 0.1974, train_acc = 0.9374, val_acc = 0.7540\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7580\n",
            "d-step 5 epoch 1 : .......... average_loss = 0.1918, train_acc = 0.9395, val_acc = 0.7660\n",
            "\n",
            "--------\n",
            "EPOCH 24\n",
            "--------\n",
            "\n",
            "Adversarial Training Generator : \n",
            "\n",
            "Testing Generator : average_train_NLL = 4.2166 average_test_NLL = 4.5516\n",
            "\n",
            "Adversarial Training Discriminator : \n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7790\n",
            "d-step 1 epoch 1 : .......... average_loss = 0.1928, train_acc = 0.9385, val_acc = 0.7770\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7800\n",
            "d-step 2 epoch 1 : .......... average_loss = 0.1948, train_acc = 0.9373, val_acc = 0.7470\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7480\n",
            "d-step 3 epoch 1 : .......... average_loss = 0.1937, train_acc = 0.9386, val_acc = 0.7650\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7650\n",
            "d-step 4 epoch 1 : .......... average_loss = 0.1990, train_acc = 0.9363, val_acc = 0.7570\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7620\n",
            "d-step 5 epoch 1 : .......... average_loss = 0.1948, train_acc = 0.9371, val_acc = 0.7640\n",
            "\n",
            "--------\n",
            "EPOCH 25\n",
            "--------\n",
            "\n",
            "Adversarial Training Generator : \n",
            "\n",
            "Testing Generator : average_train_NLL = 4.2210 average_test_NLL = 4.5557\n",
            "\n",
            "Adversarial Training Discriminator : \n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7840\n",
            "d-step 1 epoch 1 : .......... average_loss = 0.1897, train_acc = 0.9405, val_acc = 0.7930\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7930\n",
            "d-step 2 epoch 1 : .......... average_loss = 0.1969, train_acc = 0.9358, val_acc = 0.7820\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7750\n",
            "d-step 3 epoch 1 : .......... average_loss = 0.1893, train_acc = 0.9399, val_acc = 0.7810\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7900\n",
            "d-step 4 epoch 1 : .......... average_loss = 0.1854, train_acc = 0.9415, val_acc = 0.7950\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7830\n",
            "d-step 5 epoch 1 : .......... average_loss = 0.1828, train_acc = 0.9422, val_acc = 0.7990\n",
            "CPU times: user 15min 57s, sys: 10min 51s, total: 26min 48s\n",
            "Wall time: 26min 52s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vs3-xXxc3rQ6"
      },
      "source": [
        "Тестирование генератора на обучающей выборке после состязательного обучения."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CWz3XBxE3nOp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69af031f-1b16-40e0-e8a6-3fb3b1959b09"
      },
      "source": [
        "%%time\n",
        "test_mle(gen, data_file_tensor_train, data_file_tensor_test)\n",
        "# average_train_NLL = 1.5186 average_test_NLL = 2.0730\n",
        "# average_train_NLL = 1.4459 average_test_NLL = 1.9926"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "average_train_NLL = 4.2210 average_test_NLL = 4.5557\n",
            "CPU times: user 626 ms, sys: 174 ms, total: 800 ms\n",
            "Wall time: 821 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vF9S-MHOJm7d"
      },
      "source": [
        "Генерация примеров текстов на основе SeqGAN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cLUxNkP7LhHU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "023657b7-100e-421f-8a92-27d7bb8fb048"
      },
      "source": [
        "# примеры сгенерированных текстов\n",
        "print(\"Примеры генерируемых текстов на основе SeqGAN\")\n",
        "degree = 1\n",
        "print(\"Degree:\", degree)\n",
        "samples = gen.sample(50, degree=degree).cpu().detach().numpy()\n",
        "\n",
        "output_function = []\n",
        "for i, samp in enumerate(samples):\n",
        "  line = [word[x] for x in samp]\n",
        "  line = ' '.join(line)\n",
        "  output_function.append(line)\n",
        "  bleu = BLEU(data_file_test.tolist(), [samp], flag_print=False)\n",
        "  print(\"#\", i, \"\\tПример: \", line, ' '*(100-len(line)), '\\tОценка: ', bleu)"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Примеры генерируемых текстов на основе SeqGAN\n",
            "Degree: 1\n",
            "# 0 \tПример:  что мир у вас у каждого хранить точно                                                                 \tОценка:  [0.8819171036881969, 0.5793377741477417, 0.22957488466614331, 0.13586551826765378]\n",
            "# 1 \tПример:  только русский история и сердце больше не хватало                                                     \tОценка:  [0.5477225575051661, 0.15536162529769298, 0.08555261858712451, 0.06168170862583606]\n",
            "# 2 \tПример:  другой тебе твоя будет и всё что и дело                                                               \tОценка:  [0.816496580927726, 0.20274006651911342, 0.10445522730720386, 0.07236255500755572]\n",
            "# 3 \tПример:  что к тебе а другой вид что он и нас                                                                  \tОценка:  [0.816496580927726, 0.43679023236814946, 0.18575057999133604, 0.11468692082056794]\n",
            "# 4 \tПример:  но вот так что то есть и это                                                                          \tОценка:  [1.0, 0.6299605249474366, 0.24446151121745052, 0.14286904563541653]\n",
            "# 5 \tПример:  отец не беги нам милый где пишешь там                                                                 \tОценка:  [0.6324555320336759, 0.3684031498640387, 0.1634812655665549, 0.10354857884559052]\n",
            "# 6 \tПример:  но раз не смотри в них совсем не тревожит                                                             \tОценка:  [0.7071067811865476, 0.18420157493201939, 0.09720654209069822, 0.06831658446802373]\n",
            "# 7 \tПример:  и не важно что мне до любовь с небес                                                                  \tОценка:  [0.816496580927726, 0.6299605249474366, 0.43472087194499137, 0.2264321778409878]\n",
            "# 8 \tПример:  жизнь ко мне никогда не хочу нам                                                                      \tОценка:  [0.7071067811865476, 0.39685026299204995, 0.17286039232097056, 0.10827448965556544]\n",
            "# 9 \tПример:  жаль что ты не понял мне ни о вечном                                                                  \tОценка:  [0.8819171036881969, 0.5793377741477417, 0.22957488466614331, 0.13586551826765378]\n",
            "# 10 \tПример:  ему не знать мне тем более нечего умереть                                                             \tОценка:  [0.6666666666666666, 0.381571414184444, 0.167844596251862, 0.10575371703212418]\n",
            "# 11 \tПример:  еще о любви с тобой о том что спасает                                                                 \tОценка:  [0.7453559924999299, 0.4110353457217451, 0.17747405280050269, 0.11058026936233441]\n",
            "# 12 \tПример:  пусть не завтра место где где ты в том                                                                \tОценка:  [0.7453559924999299, 0.4110353457217451, 0.17747405280050269, 0.11058026936233441]\n",
            "# 13 \tПример:  что ты слышишь поют себя но ждать пиши                                                                \tОценка:  [0.6666666666666666, 0.381571414184444, 0.167844596251862, 0.10575371703212418]\n",
            "# 14 \tПример:  так я хочу к ногам я плачу без смерти                                                                 \tОценка:  [0.816496580927726, 0.43679023236814946, 0.18575057999133604, 0.11468692082056794]\n",
            "# 15 \tПример:  при том что как здесь когда ночь не на время                                                          \tОценка:  [0.9428090415820634, 0.4807498567691362, 0.1996019880774733, 0.12147912078962296]\n",
            "# 16 \tПример:  правда не место но кто он мне не нужен                                                                \tОценка:  [0.8819171036881969, 0.6631762013160654, 0.537284965911771, 0.4251415002085969]\n",
            "# 17 \tПример:  и главное мир с тобою на ребенка                                                                      \tОценка:  [0.6324555320336759, 0.17099759466766976, 0.09193227152249189, 0.06533473633311172]\n",
            "# 18 \tПример:  что в сердце путь я одна может вновь                                                                  \tОценка:  [0.7453559924999299, 0.5178720843256431, 0.21105340631872638, 0.12702337351164256]\n",
            "# 19 \tПример:  как точка что было зря но только не может не                                                          \tОценка:  [0.816496580927726, 0.5503212081491045, 0.22089591134157885, 0.1317406772862616]\n",
            "# 20 \tПример:  что бы понял просто то внутри теперь опять тайны                                                      \tОценка:  [0.5773502691896257, 0.16091489743427165, 0.08783602619713964, 0.0629952630233744]\n",
            "# 21 \tПример:  я больше и не много играю сквозь бури                                                                 \tОценка:  [0.816496580927726, 0.20274006651911342, 0.10445522730720386, 0.07236255500755572]\n",
            "# 22 \tПример:  и вижу трепет весна когда на виски хоть немножко                                                      \tОценка:  [0.4472135954999579, 0.13572088082974534, 0.07730551756939458, 0.056877191517594156]\n",
            "# 23 \tПример:  нашем человек во всему лишь и буду уже просто уйти                                                    \tОценка:  [0.3333333333333333, 0.11157215834702831, 0.06674094719041482, 0.05056891582288009]\n",
            "# 24 \tПример:  и что всё оно понять на сути рядом                                                                    \tОценка:  [0.6666666666666666, 0.381571414184444, 0.167844596251862, 0.10575371703212418]\n",
            "# 25 \tПример:  что бы ты дал я я даже другой                                                                         \tОценка:  [0.8819171036881969, 0.5793377741477417, 0.22957488466614331, 0.13586551826765378]\n",
            "# 26 \tПример:  не с тобой очень вернуть мне тебя представить                                                         \tОценка:  [0.7453559924999299, 0.5178720843256431, 0.21105340631872638, 0.12702337351164256]\n",
            "# 27 \tПример:  и мой ангел ещё пел зови не стала                                                                     \tОценка:  [0.816496580927726, 0.5503212081491045, 0.22089591134157885, 0.1317406772862616]\n",
            "# 28 \tПример:  и он вообще не в силах видеть мне                                                                     \tОценка:  [0.816496580927726, 0.5503212081491045, 0.22089591134157885, 0.1317406772862616]\n",
            "# 29 \tПример:  раз так пусть есть и что в прошлом                                                                    \tОценка:  [0.8819171036881969, 0.5793377741477417, 0.22957488466614331, 0.13586551826765378]\n",
            "# 30 \tПример:  и здесь другим я в общем не так                                                                       \tОценка:  [0.8819171036881969, 0.7299198566479815, 0.5773502691896257, 0.2841327194679419]\n",
            "# 31 \tПример:  ты или жизнь сын ангела с тоскою всегда                                                               \tОценка:  [0.5477225575051661, 0.3347164750410848, 0.15213646010839674, 0.0977589201004575]\n",
            "# 32 \tПример:  совсем не может быть привет и вас и не может                                                          \tОценка:  [0.816496580927726, 0.43679023236814946, 0.18575057999133604, 0.11468692082056794]\n",
            "# 33 \tПример:  мне губы и не страшно обо мне боль                                                                    \tОценка:  [0.816496580927726, 0.5503212081491045, 0.22089591134157885, 0.1317406772862616]\n",
            "# 34 \tПример:  он шёл с улыбкой и я не забыла                                                                        \tОценка:  [0.7453559924999299, 0.5178720843256431, 0.21105340631872638, 0.12702337351164256]\n",
            "# 35 \tПример:  и что нибудь один теперь для близких где                                                              \tОценка:  [0.7453559924999299, 0.4110353457217451, 0.17747405280050269, 0.11058026936233441]\n",
            "# 36 \tПример:  ведь как же был могла я тебя любить                                                                   \tОценка:  [0.816496580927726, 0.5503212081491045, 0.22089591134157885, 0.1317406772862616]\n",
            "# 37 \tПример:  как вам что узнать то что то там                                                                      \tОценка:  [0.9428090415820634, 0.4807498567691362, 0.1996019880774733, 0.12147912078962296]\n",
            "# 38 \tПример:  ночь тебя мой брат не во сне пока                                                                     \tОценка:  [0.7453559924999299, 0.19078570709222206, 0.09980099403873667, 0.069771433108763]\n",
            "# 39 \tПример:  что не нужен мне веру лучше и не молчи                                                                \tОценка:  [0.8819171036881969, 0.7299198566479815, 0.27301208627090673, 0.15606849733487352]\n",
            "# 40 \tПример:  что вскоре там и не мешает ведь ничего не плачь                                                       \tОценка:  [0.7453559924999299, 0.4110353457217451, 0.17747405280050269, 0.11058026936233441]\n",
            "# 41 \tПример:  чтобы жить не с той так ты так                                                                        \tОценка:  [0.8819171036881969, 0.45982069606352016, 0.19304869754804488, 0.11827780346042588]\n",
            "# 42 \tПример:  люблю я лето с осенью я снова осень                                                                   \tОценка:  [0.7453559924999299, 0.4110353457217451, 0.17747405280050269, 0.11058026936233441]\n",
            "# 43 \tПример:  что это ведь сердце не чай это любовь                                                                 \tОценка:  [0.7453559924999299, 0.4110353457217451, 0.17747405280050269, 0.11058026936233441]\n",
            "# 44 \tПример:  мне как он любит нас от души                                                                          \tОценка:  [0.8366600265340756, 0.5593444710406984, 0.223606797749979, 0.1330324997130986]\n",
            "# 45 \tПример:  он не захотел сказал что создал нас не любить                                                         \tОценка:  [0.7745966692414834, 0.42171633265087466, 0.18092176081223305, 0.11229551070568211]\n",
            "# 46 \tПример:  вот мечтал о том что я не хочу                                                                        \tОценка:  [0.8819171036881969, 0.8355496558274308, 0.7071067811865476, 0.3341625309791344]\n",
            "# 47 \tПример:  за что в душе и нет здесь нет                                                                         \tОценка:  [0.9428090415820634, 0.6933612743506347, 0.2626909894424158, 0.15133029928492392]\n",
            "# 48 \tПример:  не случилось ему дарит временем всегда со мной                                                        \tОценка:  [0.7453559924999299, 0.5928155507483438, 0.49393827371153703, 0.39747323872059626]\n",
            "# 49 \tПример:  но жили такой и солнце темно и скучаю                                                                 \tОценка:  [0.6666666666666666, 0.381571414184444, 0.167844596251862, 0.10575371703212418]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J7ZUtKiv7n88"
      },
      "source": [
        "Оценка качества генерации на основе SeqGAN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tets0DMEuDkC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b63443c3-47bd-40ad-9f47-273973381f56"
      },
      "source": [
        "%%time\n",
        "print(\"Оценка качества генерации текстов на основе BLEU, после обучения с помощью SeqGAN\")\n",
        "degree = 1\n",
        "print(\"Degree:\", degree)\n",
        "# проверка качества обучения\n",
        "BLEU(data_file_test.tolist(), gen.sample(500, degree=degree).cpu().detach().numpy().tolist(), print_iteration=100)"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Оценка качества генерации текстов на основе BLEU, после обучения с помощью SeqGAN\n",
            "Degree: 1\n",
            "--- --- ---\n",
            "Start BLEU\n",
            "2 100 0.756327066391588\n",
            "2 200 0.7551942931955969\n",
            "2 300 0.7592751933861931\n",
            "2 400 0.7548446136656939\n",
            "2 500 0.7570414872078776\n",
            "--- --- ---\n",
            "2 -gram BLEU score :  0.7570414872078776 \n",
            "\n",
            "3 100 0.4479584190894686\n",
            "3 200 0.43899278585143875\n",
            "3 300 0.44134262752863906\n",
            "3 400 0.43509346796894255\n",
            "3 500 0.43604133425918606\n",
            "--- --- ---\n",
            "3 -gram BLEU score :  0.43604133425918606 \n",
            "\n",
            "4 100 0.225955953164321\n",
            "4 200 0.2265542585882442\n",
            "4 300 0.22464085190691174\n",
            "4 400 0.2211950392895392\n",
            "4 500 0.22264702121052837\n",
            "--- --- ---\n",
            "4 -gram BLEU score :  0.22264702121052837 \n",
            "\n",
            "5 100 0.1355252852029599\n",
            "5 200 0.13670329584898577\n",
            "5 300 0.13403863938260258\n",
            "5 400 0.13185758403281145\n",
            "5 500 0.13229657890676344\n",
            "--- --- ---\n",
            "5 -gram BLEU score :  0.13229657890676344 \n",
            "\n",
            "CPU times: user 5min 50s, sys: 127 ms, total: 5min 50s\n",
            "Wall time: 5min 50s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a5RkMEMws99n"
      },
      "source": [
        "Оценка с возведением в степень"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2tZle_Ydnb85",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ca8eb03-e846-480a-8ba4-07038975a57e"
      },
      "source": [
        "# примеры сгенерированных текстов\n",
        "print(\"Примеры генерируемых текстов на основе SeqGAN с возведением в степень\")\n",
        "degree = 1.5\n",
        "print(\"Degree:\", degree)\n",
        "samples = gen.sample(50, degree=degree).cpu().detach().numpy()\n",
        "\n",
        "output_function = []\n",
        "for i, samp in enumerate(samples):\n",
        "  line = [word[x] for x in samp]\n",
        "  line = ' '.join(line)\n",
        "  output_function.append(line)\n",
        "  bleu = BLEU(data_file_test.tolist(), [samp], flag_print=False)\n",
        "  print(\"#\", i, \"\\tПример: \", line, ' '*(100-len(line)), '\\tОценка: ', bleu)"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Примеры генерируемых текстов на основе SeqGAN с возведением в степень\n",
            "Degree: 1.5\n",
            "# 0 \tПример:  и не знаю что я люблю тебя я                                                                          \tОценка:  [1.0, 1.0, 0.6147881529512643, 0.29877904991471826]\n",
            "# 1 \tПример:  и в общем то что жизнь здесь и в конце                                                                \tОценка:  [0.9428090415820634, 0.6057068642773799, 0.42210681263745264, 0.22116053872466884]\n",
            "# 2 \tПример:  а я не могу я жизнь одна                                                                              \tОценка:  [0.8366600265340756, 0.7047298732064892, 0.26591479484724945, 0.15281421358157987]\n",
            "# 3 \tПример:  и я не могу понять не я не могу                                                                       \tОценка:  [0.9428090415820634, 0.7631428283688879, 0.5019724248795793, 0.25404674702328517]\n",
            "# 4 \tПример:  что не хватает нам в жизни не так                                                                     \tОценка:  [0.9428090415820634, 0.82207069144349, 0.631196907822589, 0.3051417552231673]\n",
            "# 5 \tПример:  и я не знаю что я ненавижу он                                                                         \tОценка:  [0.9428090415820634, 0.82207069144349, 0.631196907822589, 0.4836170905888332]\n",
            "# 6 \tПример:  и не пойму что я не смогу я сказать                                                                   \tОценка:  [0.8819171036881969, 0.5793377741477417, 0.22957488466614331, 0.13586551826765378]\n",
            "# 7 \tПример:  что бы ни был вчера не церковь всегда                                                                 \tОценка:  [0.7745966692414834, 0.5313292845913056, 0.21515344521672802, 0.128993668421169]\n",
            "# 8 \tПример:  и он не любил а я не знаю                                                                             \tОценка:  [1.0, 0.9085602964160698, 0.6803749333171202, 0.5135330435446759]\n",
            "# 9 \tПример:  сказал я что не со мной и не уйти                                                                     \tОценка:  [1.0, 0.8549879733383485, 0.6500593260343691, 0.31241519207647167]\n",
            "# 10 \tПример:  и то что не так и не надо                                                                             \tОценка:  [1.0, 1.0, 0.8694417438899827, 0.6248303841529433]\n",
            "# 11 \tПример:  а я не знаю а впрочем как ты                                                                          \tОценка:  [0.8819171036881969, 0.7299198566479815, 0.4854917717073234, 0.24735189898367643]\n",
            "# 12 \tПример:  ты не мой и не любовь не узнаешь                                                                      \tОценка:  [1.0, 0.8549879733383485, 0.6500593260343691, 0.31241519207647167]\n",
            "# 13 \tПример:  что все было так не было мне жаль                                                                     \tОценка:  [1.0, 0.6299605249474366, 0.43472087194499137, 0.2264321778409878]\n",
            "# 14 \tПример:  и ты не понимаешь что я не знаю                                                                       \tОценка:  [0.9428090415820634, 0.82207069144349, 0.631196907822589, 0.4836170905888332]\n",
            "# 15 \tПример:  и не в том что ты не поймешь                                                                          \tОценка:  [0.8819171036881969, 0.7299198566479815, 0.5773502691896257, 0.2841327194679419]\n",
            "# 16 \tПример:  что не могу не любить жизни и не жалко                                                                \tОценка:  [0.816496580927726, 0.5503212081491045, 0.22089591134157885, 0.1317406772862616]\n",
            "# 17 \tПример:  и как бы не было тебя не надо                                                                         \tОценка:  [0.9428090415820634, 0.7631428283688879, 0.5019724248795793, 0.25404674702328517]\n",
            "# 18 \tПример:  и не могу я понять ты не спишь                                                                        \tОценка:  [0.9428090415820634, 0.7631428283688879, 0.5019724248795793, 0.25404674702328517]\n",
            "# 19 \tПример:  но не могу я не могу не забыть                                                                        \tОценка:  [0.8819171036881969, 0.7862823300527556, 0.5133450480401704, 0.25864092898589325]\n",
            "# 20 \tПример:  не знаю ты ты не та что счастье                                                                       \tОценка:  [1.0, 0.6299605249474366, 0.24446151121745052, 0.14286904563541653]\n",
            "# 21 \tПример:  мне бы не встретить тебя не был в век                                                                 \tОценка:  [0.8819171036881969, 0.5793377741477417, 0.22957488466614331, 0.13586551826765378]\n",
            "# 22 \tПример:  ведь завтра я не так уж не нужен                                                                      \tОценка:  [0.9428090415820634, 0.7631428283688879, 0.5019724248795793, 0.25404674702328517]\n",
            "# 23 \tПример:  и что то было не с и не тая                                                                           \tОценка:  [0.8819171036881969, 0.45982069606352016, 0.19304869754804488, 0.11827780346042588]\n",
            "# 24 \tПример:  и вот и что же с ней играть                                                                           \tОценка:  [0.8819171036881969, 0.45982069606352016, 0.19304869754804488, 0.11827780346042588]\n",
            "# 25 \tПример:  и что бы мог бы я бы не знаю                                                                          \tОценка:  [0.9486832980505138, 0.7663094323935531, 0.2831578580469335, 0.1606914037667553]\n",
            "# 26 \tПример:  в ней не было не хватает и ни рая                                                                     \tОценка:  [0.9428090415820634, 0.4807498567691362, 0.1996019880774733, 0.12147912078962296]\n",
            "# 27 \tПример:  я не могу тебя люблю я знаю что                                                                       \tОценка:  [0.9428090415820634, 0.7631428283688879, 0.28227983861579553, 0.16029266087564348]\n",
            "# 28 \tПример:  как я ощущаю что ты не сказал что                                                                     \tОценка:  [0.9428090415820634, 0.6057068642773799, 0.23736810439041958, 0.139542866217526]\n",
            "# 29 \tПример:  и не важно что я тебя не любил                                                                        \tОценка:  [1.0, 0.9085602964160698, 0.7529586373193689, 0.35138777297455254]\n",
            "# 30 \tПример:  и не было бы ни когда не вернуть                                                                      \tОценка:  [1.0, 0.8549879733383485, 0.3073940764756322, 0.17160350157230692]\n",
            "# 31 \tПример:  что не так плохо лишь нам не нужно                                                                    \tОценка:  [0.816496580927726, 0.6933612743506347, 0.5555238068023582, 0.4366484170785404]\n",
            "# 32 \tПример:  нет больше не надо не с вами быть                                                                     \tОценка:  [0.9428090415820634, 0.6933612743506347, 0.2626909894424158, 0.15133029928492392]\n",
            "# 33 \tПример:  и как же не всего то что не вышло                                                                     \tОценка:  [0.9428090415820634, 0.6057068642773799, 0.23736810439041958, 0.139542866217526]\n",
            "# 34 \tПример:  не дальше жить с утра до последнего                                                                   \tОценка:  [0.6324555320336759, 0.17099759466766976, 0.09193227152249189, 0.06533473633311172]\n",
            "# 35 \tПример:  и не могу я говорить что ты такой                                                                     \tОценка:  [0.9428090415820634, 0.7631428283688879, 0.28227983861579553, 0.16029266087564348]\n",
            "# 36 \tПример:  я не знаю что б ты не была                                                                            \tОценка:  [1.0, 0.8549879733383485, 0.6500593260343691, 0.31241519207647167]\n",
            "# 37 \tПример:  а мне так хочется о любви и не забыть                                                                 \tОценка:  [0.9428090415820634, 0.7631428283688879, 0.28227983861579553, 0.16029266087564348]\n",
            "# 38 \tПример:  я не знаю что я не могу даже                                                                          \tОценка:  [0.9428090415820634, 0.8735804647362989, 0.5555238068023581, 0.2755065257113557]\n",
            "# 39 \tПример:  и в доме бог не был и не буду                                                                         \tОценка:  [0.8819171036881969, 0.7862823300527556, 0.6104735835807844, 0.29710040966100054]\n",
            "# 40 \tПример:  и не так как в жизни не так                                                                           \tОценка:  [1.0, 0.9085602964160698, 0.6803749333171202, 0.32401744545778005]\n",
            "# 41 \tПример:  как девчонка о тебе о тебе я не знаю                                                                  \tОценка:  [0.8819171036881969, 0.6631762013160654, 0.537284965911771, 0.26824615199994184]\n",
            "# 42 \tПример:  и не знаю что она у меня в нас                                                                        \tОценка:  [0.9428090415820634, 0.82207069144349, 0.2984745896009823, 0.1676083462016725]\n",
            "# 43 \tПример:  а я не люблю и ни о чем                                                                               \tОценка:  [1.0, 0.8549879733383485, 0.6500593260343691, 0.49514471114343117]\n",
            "# 44 \tПример:  но не из за вас и не было                                                                             \tОценка:  [1.0, 0.7211247851537042, 0.48109772909788073, 0.24555930495936829]\n",
            "# 45 \tПример:  когда я не знаю как я верю что                                                                        \tОценка:  [1.0, 0.8549879733383485, 0.6500593260343691, 0.31241519207647167]\n",
            "# 46 \tПример:  но я не знаю что бесполезно и не                                                                      \tОценка:  [0.8819171036881969, 0.7299198566479815, 0.5773502691896257, 0.2841327194679419]\n",
            "# 47 \tПример:  не знаю тех кто был я всем сердцем                                                                    \tОценка:  [0.9428090415820634, 0.6933612743506347, 0.4671379777282001, 0.2398423611497788]\n",
            "# 48 \tПример:  и не хочу сказать что мне не спится                                                                   \tОценка:  [1.0, 0.9085602964160698, 0.6803749333171202, 0.5135330435446759]\n",
            "# 49 \tПример:  а для тебя и кто то что я                                                                             \tОценка:  [1.0, 0.7211247851537042, 0.2705411345269699, 0.154937446969565]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ATYRFjknb85",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20101221-8165-4929-8e59-ba01cf4126b4"
      },
      "source": [
        "%%time\n",
        "print(\"Оценка качества генерации текстов на основе BLEU, после обучения с помощью SeqGAN\")\n",
        "# проверка качества обучения\n",
        "BLEU(data_file_test.tolist(), gen.sample(500, degree=degree).cpu().detach().numpy().tolist(), print_iteration=100)"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Оценка качества генерации текстов на основе BLEU, после обучения с помощью SeqGAN\n",
            "--- --- ---\n",
            "Start BLEU\n",
            "2 100 0.9352075650568834\n",
            "2 200 0.9291563408758435\n",
            "2 300 0.9282022814564931\n",
            "2 400 0.9259652759971634\n",
            "2 500 0.925982021812217\n",
            "--- --- ---\n",
            "2 -gram BLEU score :  0.925982021812217 \n",
            "\n",
            "3 100 0.7208715349142032\n",
            "3 200 0.7159446183904312\n",
            "3 300 0.7150713953092783\n",
            "3 400 0.7162938237004007\n",
            "3 500 0.7200018075100502\n",
            "--- --- ---\n",
            "3 -gram BLEU score :  0.7200018075100502 \n",
            "\n",
            "4 100 0.44950025039298047\n",
            "4 200 0.42683411306066005\n",
            "4 300 0.43388785470455454\n",
            "4 400 0.44002929573821903\n",
            "4 500 0.44385890784792853\n",
            "--- --- ---\n",
            "4 -gram BLEU score :  0.44385890784792853 \n",
            "\n",
            "5 100 0.25507868622560825\n",
            "5 200 0.24027600196763424\n",
            "5 300 0.24244563488438728\n",
            "5 400 0.24952739811011998\n",
            "5 500 0.2525968934982302\n",
            "--- --- ---\n",
            "5 -gram BLEU score :  0.2525968934982302 \n",
            "\n",
            "CPU times: user 5min 47s, sys: 139 ms, total: 5min 47s\n",
            "Wall time: 5min 47s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VhrWW-2bKH9E"
      },
      "source": [
        "Загрузка сохраненной модели"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mHsreqY23P-T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3eecc705-643b-4d32-bba6-2da322be4575"
      },
      "source": [
        "# загрузка моделей\n",
        "[data_file_tensor_train, gen, dis, gen_optimizer, dis_optimizer,\n",
        "VOCAB_SIZE, MAX_SEQ_LEN, GEN_EMBEDDING_DIM, GEN_HIDDEN_DIM, DIS_EMBEDDING_DIM,\n",
        " DIS_HIDDEN_DIM] = load_models(FILE_PATHS['saved_models'] + r'/' + r'seqgan_adversarial_training.pytorch')#[seqgan_mle, seqgan_pretraining_dis, seqgan_adversarial_training]\n",
        "\n",
        "if(CUDA):\n",
        "  gen = gen.cuda()\n",
        "  dis = dis.cuda()\n",
        "  data_file_tensor_train = torch.tensor(data_file_tensor_train).cuda()\n",
        "  data_file_tensor_test = torch.tensor(data_file_test).cuda()"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "state\n",
            "default_parameters\n",
            "data_file_tensor_train\n",
            "Generator\n",
            "Discriminator\n",
            "CUDA\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  if __name__ == '__main__':\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OxiSFluHn55b"
      },
      "source": [
        "Оценка разнообразия текста"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WWqjB09kjCHN"
      },
      "source": [
        "degree = 1.5"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KhYDh_ByyqIS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3301d43-2fa4-4282-abee-9c8ba577d054"
      },
      "source": [
        "# плагиат из обучающей выборки\n",
        "samples = gen.sample(1500, degree=degree).cpu().detach().numpy().tolist()\n",
        "# samples = data_file_test.tolist()[:500]\n",
        "train_samples = data_file_train.tolist()\n",
        "n = 0\n",
        "for i in range(len(samples)):\n",
        "  if samples[i] in train_samples:\n",
        "    n += 1\n",
        "  if i%(len(samples)//10) == 0:\n",
        "    print(i/len(samples)*100, \"%\")\n",
        "print(\"Совпало сгенерированных примеров с обучающей выборкой: \", n, \"из\", len(samples))\n",
        "print(\"Плагиат: \", n/len(samples)*100, \"%\")"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.0 %\n",
            "10.0 %\n",
            "20.0 %\n",
            "30.0 %\n",
            "40.0 %\n",
            "50.0 %\n",
            "60.0 %\n",
            "70.0 %\n",
            "80.0 %\n",
            "90.0 %\n",
            "Совпало сгенерированных примеров с обучающей выборкой:  1 из 1500\n",
            "Плагиат:  0.06666666666666667 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gOzmSGPN7Jc6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e696090-3f99-4295-8eed-119bce0a39e3"
      },
      "source": [
        "# оригинальность примеров\n",
        "N_samples = 1500\n",
        "samples_1 = gen.sample(N_samples, degree=degree).cpu().detach().numpy().tolist()\n",
        "samples_2 = gen.sample(N_samples, degree=degree).cpu().detach().numpy().tolist()\n",
        "\n",
        "n = 0\n",
        "for i in range(len(samples_1)):\n",
        "  if samples_1[i] in samples_2:\n",
        "    n += 1\n",
        "  if i%(len(samples_1)//10) == 0:\n",
        "    print(i/len(samples_1)*100, \"%\")\n",
        "\n",
        "print(\"Оригинальность генерируемых примеров\")\n",
        "print(\"Совпало примеров из выборки 1 с примерами из выборки 2: \", n, \"из\", len(samples_1))\n",
        "print(\"Плагиат: \", n/len(samples_1)*100, \"%\")\n",
        "print(\"Оригинальность: \", (1-n/len(samples_1))*100, \"%\")"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.0 %\n",
            "10.0 %\n",
            "20.0 %\n",
            "30.0 %\n",
            "40.0 %\n",
            "50.0 %\n",
            "60.0 %\n",
            "70.0 %\n",
            "80.0 %\n",
            "90.0 %\n",
            "Оригинальность генерируемых примеров\n",
            "Совпало примеров из выборки 1 с примерами из выборки 2:  3 из 1500\n",
            "Плагиат:  0.2 %\n",
            "Оригинальность:  99.8 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AY0ev9FO94ll",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70d99635-a33a-4aa9-9001-21f177cfb447"
      },
      "source": [
        "# оригинальность примеров подход 2\n",
        "N_samples = 1500\n",
        "samples = gen.sample(N_samples, degree=degree).cpu().detach().numpy().tolist()\n",
        "\n",
        "i = 0\n",
        "n = 0\n",
        "while len(samples)>0:\n",
        "  if samples[0] not in samples[1:]:\n",
        "    n += 1\n",
        "  if i%(N_samples//10) == 0:\n",
        "    print(i/N_samples*100, \"%\")\n",
        "  del(samples[0])\n",
        "  i += 1\n",
        "\n",
        "print(\"Оригинальность генерируемых примеров\")\n",
        "print(\"Сгенерировано оригинальных примеров: \", n, \"из\", N_samples)\n",
        "print(\"Оригинальность: \", n/N_samples*100, \"%\")\n",
        "print(\"Плагиат: \", (1-n/N_samples)*100, \"%\")"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.0 %\n",
            "10.0 %\n",
            "20.0 %\n",
            "30.0 %\n",
            "40.0 %\n",
            "50.0 %\n",
            "60.0 %\n",
            "70.0 %\n",
            "80.0 %\n",
            "90.0 %\n",
            "Оригинальность генерируемых примеров\n",
            "Сгенерировано оригинальных примеров:  1497 из 1500\n",
            "Оригинальность:  99.8 %\n",
            "Плагиат:  0.20000000000000018 %\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}