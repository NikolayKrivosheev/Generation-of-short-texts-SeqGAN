{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "PyTorch SeqGAN для статьи.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kSAtCAGcQgJP"
      },
      "source": [
        "**Предисловие:**\n",
        "\n",
        "**Реализация основана на работе:** ...\n",
        "\n",
        "**Результаты данной работы представлены в статье (при использовании просьба ссылаться на следующую работу):** ...\n",
        "\n",
        "**Выборки данных:**\n",
        ">*    Подписи к изображениям на английском языке из выборки COCO Image Captions\n",
        "*    Стихи на русском языке с сайта stihi.ru\n",
        "\n",
        "**Описание работы:**\n",
        "> В данной работе проведены реализация, обучение и тестирование нейронных сетей для генерации случайных коротких текстов. Используются такие нейронные сети как LSTM и SeqGAN. Проведена оценка качества генерации текста на основе метрики BLEU. Для обучения и тестирования используются следующие выборки данных:\n",
        "*   Подписи к изображениям на английском языке из выборки COCO Image Captions\n",
        "*   Стихи на русском языке с сайта stihi.ru\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dBqFdGkPPxCg"
      },
      "source": [
        "Список всех установленных библиотек и их версии"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CAl5Uo2vP12W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "384ec260-3fe7-4ace-df27-f429970cd62a"
      },
      "source": [
        "!pip list"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Package                       Version        \n",
            "----------------------------- ---------------\n",
            "absl-py                       0.10.0         \n",
            "alabaster                     0.7.12         \n",
            "albumentations                0.1.12         \n",
            "altair                        4.1.0          \n",
            "argon2-cffi                   20.1.0         \n",
            "asgiref                       3.3.1          \n",
            "astor                         0.8.1          \n",
            "astropy                       4.1            \n",
            "astunparse                    1.6.3          \n",
            "async-generator               1.10           \n",
            "atari-py                      0.2.6          \n",
            "atomicwrites                  1.4.0          \n",
            "attrs                         20.3.0         \n",
            "audioread                     2.1.9          \n",
            "autograd                      1.3            \n",
            "Babel                         2.9.0          \n",
            "backcall                      0.2.0          \n",
            "beautifulsoup4                4.6.3          \n",
            "bleach                        3.2.1          \n",
            "blis                          0.4.1          \n",
            "bokeh                         2.1.1          \n",
            "Bottleneck                    1.3.2          \n",
            "branca                        0.4.1          \n",
            "bs4                           0.0.1          \n",
            "CacheControl                  0.12.6         \n",
            "cachetools                    4.1.1          \n",
            "catalogue                     1.0.0          \n",
            "certifi                       2020.11.8      \n",
            "cffi                          1.14.3         \n",
            "chainer                       7.4.0          \n",
            "chardet                       3.0.4          \n",
            "click                         7.1.2          \n",
            "cloudpickle                   1.3.0          \n",
            "cmake                         3.12.0         \n",
            "cmdstanpy                     0.9.5          \n",
            "colorlover                    0.3.0          \n",
            "community                     1.0.0b1        \n",
            "contextlib2                   0.5.5          \n",
            "convertdate                   2.3.0          \n",
            "coverage                      3.7.1          \n",
            "coveralls                     0.5            \n",
            "crcmod                        1.7            \n",
            "cufflinks                     0.17.3         \n",
            "cupy-cuda101                  7.4.0          \n",
            "cvxopt                        1.2.5          \n",
            "cvxpy                         1.0.31         \n",
            "cycler                        0.10.0         \n",
            "cymem                         2.0.4          \n",
            "Cython                        0.29.21        \n",
            "daft                          0.0.4          \n",
            "dask                          2.12.0         \n",
            "dataclasses                   0.8            \n",
            "datascience                   0.10.6         \n",
            "debugpy                       1.0.0          \n",
            "decorator                     4.4.2          \n",
            "defusedxml                    0.6.0          \n",
            "descartes                     1.1.0          \n",
            "dill                          0.3.3          \n",
            "distributed                   1.25.3         \n",
            "Django                        3.1.3          \n",
            "dlib                          19.18.0        \n",
            "dm-tree                       0.1.5          \n",
            "docopt                        0.6.2          \n",
            "docutils                      0.16           \n",
            "dopamine-rl                   1.0.5          \n",
            "earthengine-api               0.1.238        \n",
            "easydict                      1.9            \n",
            "ecos                          2.0.7.post1    \n",
            "editdistance                  0.5.3          \n",
            "en-core-web-sm                2.2.5          \n",
            "entrypoints                   0.3            \n",
            "ephem                         3.7.7.1        \n",
            "et-xmlfile                    1.0.1          \n",
            "fa2                           0.3.5          \n",
            "fancyimpute                   0.4.3          \n",
            "fastai                        1.0.61         \n",
            "fastdtw                       0.3.4          \n",
            "fastprogress                  1.0.0          \n",
            "fastrlock                     0.5            \n",
            "fbprophet                     0.7.1          \n",
            "feather-format                0.4.1          \n",
            "filelock                      3.0.12         \n",
            "firebase-admin                4.4.0          \n",
            "fix-yahoo-finance             0.0.22         \n",
            "Flask                         1.1.2          \n",
            "flatbuffers                   1.12           \n",
            "folium                        0.8.3          \n",
            "future                        0.16.0         \n",
            "gast                          0.3.3          \n",
            "GDAL                          2.2.2          \n",
            "gdown                         3.6.4          \n",
            "gensim                        3.6.0          \n",
            "geographiclib                 1.50           \n",
            "geopy                         1.17.0         \n",
            "gin-config                    0.3.0          \n",
            "glob2                         0.7            \n",
            "google                        2.0.3          \n",
            "google-api-core               1.16.0         \n",
            "google-api-python-client      1.7.12         \n",
            "google-auth                   1.17.2         \n",
            "google-auth-httplib2          0.0.4          \n",
            "google-auth-oauthlib          0.4.2          \n",
            "google-cloud-bigquery         1.21.0         \n",
            "google-cloud-bigquery-storage 1.1.0          \n",
            "google-cloud-core             1.0.3          \n",
            "google-cloud-datastore        1.8.0          \n",
            "google-cloud-firestore        1.7.0          \n",
            "google-cloud-language         1.2.0          \n",
            "google-cloud-storage          1.18.1         \n",
            "google-cloud-translate        1.5.0          \n",
            "google-colab                  1.0.0          \n",
            "google-pasta                  0.2.0          \n",
            "google-resumable-media        0.4.1          \n",
            "googleapis-common-protos      1.52.0         \n",
            "googledrivedownloader         0.4            \n",
            "graphviz                      0.10.1         \n",
            "grpcio                        1.33.2         \n",
            "gspread                       3.0.1          \n",
            "gspread-dataframe             3.0.8          \n",
            "gym                           0.17.3         \n",
            "h5py                          2.10.0         \n",
            "HeapDict                      1.0.1          \n",
            "holidays                      0.10.3         \n",
            "holoviews                     1.13.5         \n",
            "html5lib                      1.0.1          \n",
            "httpimport                    0.5.18         \n",
            "httplib2                      0.17.4         \n",
            "httplib2shim                  0.0.3          \n",
            "humanize                      0.5.1          \n",
            "hyperopt                      0.1.2          \n",
            "ideep4py                      2.0.0.post3    \n",
            "idna                          2.10           \n",
            "image                         1.5.33         \n",
            "imageio                       2.4.1          \n",
            "imagesize                     1.2.0          \n",
            "imbalanced-learn              0.4.3          \n",
            "imblearn                      0.0            \n",
            "imgaug                        0.2.9          \n",
            "importlib-metadata            2.0.0          \n",
            "importlib-resources           3.3.0          \n",
            "imutils                       0.5.3          \n",
            "inflect                       2.1.0          \n",
            "iniconfig                     1.1.1          \n",
            "intel-openmp                  2020.0.133     \n",
            "intervaltree                  2.1.0          \n",
            "ipykernel                     4.10.1         \n",
            "ipython                       5.5.0          \n",
            "ipython-genutils              0.2.0          \n",
            "ipython-sql                   0.3.9          \n",
            "ipywidgets                    7.5.1          \n",
            "itsdangerous                  1.1.0          \n",
            "jax                           0.2.6          \n",
            "jaxlib                        0.1.57+cuda101 \n",
            "jdcal                         1.4.1          \n",
            "jedi                          0.17.2         \n",
            "jieba                         0.42.1         \n",
            "Jinja2                        2.11.2         \n",
            "joblib                        0.17.0         \n",
            "jpeg4py                       0.1.4          \n",
            "jsonschema                    2.6.0          \n",
            "jupyter                       1.0.0          \n",
            "jupyter-client                5.3.5          \n",
            "jupyter-console               5.2.0          \n",
            "jupyter-core                  4.7.0          \n",
            "jupyterlab-pygments           0.1.2          \n",
            "kaggle                        1.5.9          \n",
            "kapre                         0.1.3.1        \n",
            "Keras                         2.4.3          \n",
            "Keras-Preprocessing           1.1.2          \n",
            "keras-vis                     0.4.1          \n",
            "kiwisolver                    1.3.1          \n",
            "knnimpute                     0.1.0          \n",
            "korean-lunar-calendar         0.2.1          \n",
            "librosa                       0.6.3          \n",
            "lightgbm                      2.2.3          \n",
            "llvmlite                      0.31.0         \n",
            "lmdb                          0.99           \n",
            "lucid                         0.3.8          \n",
            "LunarCalendar                 0.0.9          \n",
            "lxml                          4.2.6          \n",
            "Markdown                      3.3.3          \n",
            "MarkupSafe                    1.1.1          \n",
            "matplotlib                    3.2.2          \n",
            "matplotlib-venn               0.11.6         \n",
            "missingno                     0.4.2          \n",
            "mistune                       0.8.4          \n",
            "mizani                        0.6.0          \n",
            "mkl                           2019.0         \n",
            "mlxtend                       0.14.0         \n",
            "more-itertools                8.6.0          \n",
            "moviepy                       0.2.3.5        \n",
            "mpmath                        1.1.0          \n",
            "msgpack                       1.0.0          \n",
            "multiprocess                  0.70.11.1      \n",
            "multitasking                  0.0.9          \n",
            "murmurhash                    1.0.4          \n",
            "music21                       5.5.0          \n",
            "natsort                       5.5.0          \n",
            "nbclient                      0.5.1          \n",
            "nbconvert                     5.6.1          \n",
            "nbformat                      5.0.8          \n",
            "nest-asyncio                  1.4.3          \n",
            "networkx                      2.5            \n",
            "nibabel                       3.0.2          \n",
            "nltk                          3.2.5          \n",
            "notebook                      5.3.1          \n",
            "np-utils                      0.5.12.1       \n",
            "numba                         0.48.0         \n",
            "numexpr                       2.7.1          \n",
            "numpy                         1.18.5         \n",
            "nvidia-ml-py3                 7.352.0        \n",
            "oauth2client                  4.1.3          \n",
            "oauthlib                      3.1.0          \n",
            "okgrade                       0.4.3          \n",
            "opencv-contrib-python         4.1.2.30       \n",
            "opencv-python                 4.1.2.30       \n",
            "openpyxl                      2.5.9          \n",
            "opt-einsum                    3.3.0          \n",
            "osqp                          0.6.1          \n",
            "packaging                     20.4           \n",
            "palettable                    3.3.0          \n",
            "pandas                        1.1.4          \n",
            "pandas-datareader             0.9.0          \n",
            "pandas-gbq                    0.13.3         \n",
            "pandas-profiling              1.4.1          \n",
            "pandocfilters                 1.4.3          \n",
            "panel                         0.9.7          \n",
            "param                         1.10.0         \n",
            "parso                         0.7.1          \n",
            "pathlib                       1.0.1          \n",
            "patsy                         0.5.1          \n",
            "pexpect                       4.8.0          \n",
            "pickleshare                   0.7.5          \n",
            "Pillow                        7.0.0          \n",
            "pip                           19.3.1         \n",
            "pip-tools                     4.5.1          \n",
            "plac                          1.1.3          \n",
            "plotly                        4.4.1          \n",
            "plotnine                      0.6.0          \n",
            "pluggy                        0.7.1          \n",
            "portpicker                    1.3.1          \n",
            "prefetch-generator            1.0.1          \n",
            "preshed                       3.0.4          \n",
            "prettytable                   2.0.0          \n",
            "progressbar2                  3.38.0         \n",
            "prometheus-client             0.9.0          \n",
            "promise                       2.3            \n",
            "prompt-toolkit                1.0.18         \n",
            "protobuf                      3.12.4         \n",
            "psutil                        5.4.8          \n",
            "psycopg2                      2.7.6.1        \n",
            "ptyprocess                    0.6.0          \n",
            "py                            1.9.0          \n",
            "pyarrow                       0.14.1         \n",
            "pyasn1                        0.4.8          \n",
            "pyasn1-modules                0.2.8          \n",
            "pycocotools                   2.0.2          \n",
            "pycparser                     2.20           \n",
            "pyct                          0.4.8          \n",
            "pydata-google-auth            1.1.0          \n",
            "pydot                         1.3.0          \n",
            "pydot-ng                      2.0.0          \n",
            "pydotplus                     2.0.2          \n",
            "PyDrive                       1.3.1          \n",
            "pyemd                         0.5.1          \n",
            "pyglet                        1.5.0          \n",
            "Pygments                      2.6.1          \n",
            "pygobject                     3.26.1         \n",
            "pymc3                         3.7            \n",
            "PyMeeus                       0.3.7          \n",
            "pymongo                       3.11.1         \n",
            "pymystem3                     0.2.0          \n",
            "PyOpenGL                      3.1.5          \n",
            "pyparsing                     2.4.7          \n",
            "pyrsistent                    0.17.3         \n",
            "pysndfile                     1.3.8          \n",
            "PySocks                       1.7.1          \n",
            "pystan                        2.19.1.1       \n",
            "pytest                        3.6.4          \n",
            "python-apt                    1.6.5+ubuntu0.3\n",
            "python-chess                  0.23.11        \n",
            "python-dateutil               2.8.1          \n",
            "python-louvain                0.14           \n",
            "python-slugify                4.0.1          \n",
            "python-utils                  2.4.0          \n",
            "pytz                          2018.9         \n",
            "pyviz-comms                   0.7.6          \n",
            "PyWavelets                    1.1.1          \n",
            "PyYAML                        3.13           \n",
            "pyzmq                         20.0.0         \n",
            "qtconsole                     4.7.7          \n",
            "QtPy                          1.9.0          \n",
            "regex                         2019.12.20     \n",
            "requests                      2.23.0         \n",
            "requests-oauthlib             1.3.0          \n",
            "resampy                       0.2.2          \n",
            "retrying                      1.3.3          \n",
            "rpy2                          3.2.7          \n",
            "rsa                           4.6            \n",
            "scikit-image                  0.16.2         \n",
            "scikit-learn                  0.22.2.post1   \n",
            "scipy                         1.4.1          \n",
            "screen-resolution-extra       0.0.0          \n",
            "scs                           2.1.2          \n",
            "seaborn                       0.11.0         \n",
            "Send2Trash                    1.5.0          \n",
            "setuptools                    50.3.2         \n",
            "setuptools-git                1.2            \n",
            "Shapely                       1.7.1          \n",
            "simplegeneric                 0.8.1          \n",
            "six                           1.15.0         \n",
            "sklearn                       0.0            \n",
            "sklearn-pandas                1.8.0          \n",
            "slugify                       0.0.1          \n",
            "smart-open                    3.0.0          \n",
            "snowballstemmer               2.0.0          \n",
            "sortedcontainers              2.3.0          \n",
            "spacy                         2.2.4          \n",
            "Sphinx                        1.8.5          \n",
            "sphinxcontrib-serializinghtml 1.1.4          \n",
            "sphinxcontrib-websupport      1.2.4          \n",
            "SQLAlchemy                    1.3.20         \n",
            "sqlparse                      0.4.1          \n",
            "srsly                         1.0.4          \n",
            "statsmodels                   0.10.2         \n",
            "sympy                         1.1.1          \n",
            "tables                        3.4.4          \n",
            "tabulate                      0.8.7          \n",
            "tblib                         1.7.0          \n",
            "tensorboard                   2.3.0          \n",
            "tensorboard-plugin-wit        1.7.0          \n",
            "tensorboardcolab              0.0.22         \n",
            "tensorflow                    2.3.0          \n",
            "tensorflow-addons             0.8.3          \n",
            "tensorflow-datasets           4.0.1          \n",
            "tensorflow-estimator          2.3.0          \n",
            "tensorflow-gcs-config         2.3.0          \n",
            "tensorflow-hub                0.10.0         \n",
            "tensorflow-metadata           0.25.0         \n",
            "tensorflow-privacy            0.2.2          \n",
            "tensorflow-probability        0.11.0         \n",
            "termcolor                     1.1.0          \n",
            "terminado                     0.9.1          \n",
            "testpath                      0.4.4          \n",
            "text-unidecode                1.3            \n",
            "textblob                      0.15.3         \n",
            "textgenrnn                    1.4.1          \n",
            "Theano                        1.0.5          \n",
            "thinc                         7.4.0          \n",
            "tifffile                      2020.9.3       \n",
            "toml                          0.10.2         \n",
            "toolz                         0.11.1         \n",
            "torch                         1.7.0+cu101    \n",
            "torchsummary                  1.5.1          \n",
            "torchtext                     0.3.1          \n",
            "torchvision                   0.8.1+cu101    \n",
            "tornado                       5.1.1          \n",
            "tqdm                          4.41.1         \n",
            "traitlets                     4.3.3          \n",
            "tweepy                        3.6.0          \n",
            "typeguard                     2.7.1          \n",
            "typing-extensions             3.7.4.3        \n",
            "tzlocal                       1.5.1          \n",
            "umap-learn                    0.4.6          \n",
            "uritemplate                   3.0.1          \n",
            "urllib3                       1.24.3         \n",
            "vega-datasets                 0.8.0          \n",
            "wasabi                        0.8.0          \n",
            "wcwidth                       0.2.5          \n",
            "webencodings                  0.5.1          \n",
            "Werkzeug                      1.0.1          \n",
            "wheel                         0.35.1         \n",
            "widgetsnbextension            3.5.1          \n",
            "wordcloud                     1.5.0          \n",
            "wrapt                         1.12.1         \n",
            "xarray                        0.15.1         \n",
            "xgboost                       0.90           \n",
            "xkit                          0.0.0          \n",
            "xlrd                          1.1.0          \n",
            "xlwt                          1.3.0          \n",
            "yellowbrick                   0.9.1          \n",
            "zict                          2.0.0          \n",
            "zipp                          3.4.0          \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1mRG9mlM3z69"
      },
      "source": [
        "Подключение к Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kzB9Qsf7QeUk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d929afbd-3366-4768-c765-dd75d3bea9a6"
      },
      "source": [
        "#подключение к гугл диску\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VqRu97X9S9A9"
      },
      "source": [
        "import os\n",
        "\n",
        "path = '/content/drive/My Drive/SeqGAN/'\n",
        "os.chdir(path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CInBwn4iUsK7"
      },
      "source": [
        "Объявление параметров по умолчанию"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QbtQOz8UUn0Q"
      },
      "source": [
        "from __future__ import print_function\n",
        "from math import ceil\n",
        "import numpy as np\n",
        "import sys\n",
        "\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "\n",
        "import torch.autograd as autograd\n",
        "import torch.nn.functional as F\n",
        "import torch.nn.init as init\n",
        "\n",
        "import helpers # перетащить функции в код\n",
        "\n",
        "DATASET = 'coco_image_captions' # название выборки данных список выборок: ['stihi_ru', 'coco_image_captions']\n",
        "CUDA = True # использование cuda (gpu/tpu): True/False\n",
        "BATCH_SIZE = 500 # количество примеров в партии/батче\n",
        "MLE_TRAIN_EPOCHS = 20 # количество эпох при обучении генератора на основе MLE\n",
        "DIS_TRAIN_ITERATIONS = 250 # количество итераций при обучении дискриминатора (итерации содержит несколько эпох, на каждой итерации данные для обучения обновляются)\n",
        "DIS_TRAIN_EPOCHS = 1 # количество эпох в одной итерации обучения дискриминатора\n",
        "ADV_TRAIN_EPOCHS = 15 # количество эпох при обучении генератора на основе соревновательного обучения / обучения с подкреплением\n",
        "POS_NEG_SAMPLES = 10000\n",
        "\n",
        "GEN_EMBEDDING_DIM = 150 # ширина слоя Embedding генератора\n",
        "GEN_HIDDEN_DIM = 150 # количество нейронов в слоях генератора\n",
        "DIS_EMBEDDING_DIM = 150 # ширина слоя Embedding дискриминатора\n",
        "DIS_HIDDEN_DIM = 150 # количество нейронов в слоях дискриминатора\n",
        "\n",
        "# параметры START_LETTER, VOCAB_SIZE, MAX_SEQ_LEN и FILE_PATHS задаются автоматически ниже\n",
        "START_LETTER = None #! стартовое слово (слово которое подается первым на нейронную сеть генератор)\n",
        "MAX_SEQ_LEN = None # длина генерируемого примера\n",
        "VOCAB_SIZE = None # количество слов в словаре\n",
        "FILE_PATHS = None # пути к файлам набора данных\n",
        "CLOSING_WORD = None # заключительное слово / слово заполнитель ставящееся в конце предложения\n",
        "\n",
        "# выбор набора данных и инициализация соответствующих глобальных параметров\n",
        "if DATASET == 'stihi_ru': # выборка с русскими стихами с сайта stihi_ru (длина примера 10 слов, размер словаря 5 000 слов)\n",
        "  START_LETTER = 0\n",
        "  MAX_SEQ_LEN = 10\n",
        "  VOCAB_SIZE = 5000\n",
        "  CLOSING_WORD = 4999#4997\n",
        "  FILE_PATHS = {'train': r'datasets/stihi_ru/stihi_ru_realtrain_cotra.txt', 'test': r'datasets/stihi_ru/stihi_ru_realtest_coco.txt',\n",
        "                'vocab': r'datasets/stihi_ru/stihi_ru_vocab_cotra.pkl', 'saved_models': r'saved_models/stihi_ru'}\n",
        "elif DATASET == 'coco_image_captions': # выборка COCO Image Captions (длина примера 20 слов, размер словаря 4980 слов)\n",
        "  START_LETTER = 0\n",
        "  MAX_SEQ_LEN = 20\n",
        "  VOCAB_SIZE = 4838\n",
        "  CLOSING_WORD = 1814\n",
        "  FILE_PATHS = {'train': r'datasets/coco_image_captions/coco_image_captions_train.txt', 'test': r'datasets/coco_image_captions/coco_image_captions_test.txt',\n",
        "                'vocab': r'datasets/coco_image_captions/coco_image_captions_vocab_cotra_test.pkl', 'saved_models': r'saved_models/coco_image_captions'}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-nZvyD7AVMWl"
      },
      "source": [
        "Инициализация генераторов случайных чисел."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fXQAcf0yVL6Q"
      },
      "source": [
        "# инициализация генераторов случайных чисел.\n",
        "torch.random.manual_seed(25)\n",
        "np.random.seed(25)\n",
        "#системный рандом!!!"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D22oWzXQ3-A-"
      },
      "source": [
        "Объявление класса Генератора"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NWxd3fgqvLbz"
      },
      "source": [
        "class Generator(nn.Module):\n",
        "\n",
        "  def __init__(self, embedding_dim, hidden_dim, vocab_size, max_seq_len, gpu=False):\n",
        "    super(Generator, self).__init__()\n",
        "    self.hidden_dim = hidden_dim # количество элементов на скрытом слое\n",
        "    self.embedding_dim = embedding_dim # размер слоя embedding\n",
        "    self.max_seq_len = max_seq_len # длина генерируемых примеров\n",
        "    self.vocab_size = vocab_size # размер словаря использующегося при генерации\n",
        "    self.gpu = gpu # использование cuda (True/False)\n",
        "    self.lstm_num_layers = 1 # количество LSTM слоев\n",
        "\n",
        "    self.embeddings = nn.Embedding(vocab_size, embedding_dim) # объявление слоя embeddings\n",
        "    self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers=self.lstm_num_layers) # объявление LSTM слоев\n",
        "    self.lstm2out = nn.Linear(hidden_dim, vocab_size) # объявление выходного слоя\n",
        "\n",
        "  def init_hidden(self, batch_size=1):\n",
        "    # инициализация состояния LSTM слоев\n",
        "    h = autograd.Variable(torch.zeros(self.lstm_num_layers, batch_size, self.hidden_dim)) \n",
        "    c = autograd.Variable(torch.zeros(self.lstm_num_layers, batch_size, self.hidden_dim))\n",
        "\n",
        "    if self.gpu:\n",
        "        return h.cuda(), c.cuda()\n",
        "    else:\n",
        "        return h, c\n",
        "\n",
        "  def forward(self, inp, hidden, c):\n",
        "    \"\"\"\n",
        "    Embeds input and applies LSTM one token at a time (seq_len = 1)\n",
        "    \"\"\"\n",
        "    # input dim                                             # batch_size\n",
        "    emb = self.embeddings(inp)                              # batch_size x embedding_dim\n",
        "    emb = emb.view(1, -1, self.embedding_dim)               # 1 x batch_size x embedding_dim\n",
        "    out, (hidden, c) = self.lstm(emb, (hidden, c))                    # 1 x batch_size x hidden_dim (out)\n",
        "    out = self.lstm2out(out.view(-1, self.hidden_dim))       # batch_size x vocab_size\n",
        "    out = F.log_softmax(out, dim=1)\n",
        "    return out, hidden, c\n",
        "\n",
        "  def sample(self, num_samples, start_letter=0, degree=1):\n",
        "    \"\"\"\n",
        "    Samples the network and returns num_samples samples of length max_seq_len.\n",
        "\n",
        "    Outputs: samples, hidden\n",
        "        - samples: num_samples x max_seq_length (a sampled sequence in each row)\n",
        "    \"\"\"\n",
        "\n",
        "    samples = torch.zeros(num_samples, self.max_seq_len).type(torch.LongTensor)\n",
        "\n",
        "    h, c = self.init_hidden(num_samples)\n",
        "    inp = autograd.Variable(torch.LongTensor([start_letter]*num_samples))\n",
        "    if self.gpu:\n",
        "        samples = samples.cuda()\n",
        "        inp = inp.cuda()\n",
        "\n",
        "    for i in range(self.max_seq_len):\n",
        "        out, h, c = self.forward(inp, h, c)               # out: num_samples x vocab_size\n",
        "        out = torch.exp(out)**degree\n",
        "        out = torch.multinomial(out, 1)  # num_samples x 1 (sampling from each row)\n",
        "        samples[:, i] = out.view(-1).data\n",
        "\n",
        "        inp = out.view(-1)\n",
        "\n",
        "    return samples\n",
        "\n",
        "  def batchNLLLoss(self, inp, target):\n",
        "    \"\"\"\n",
        "    Returns the NLL Loss for predicting target sequence.\n",
        "\n",
        "    Inputs: inp, target\n",
        "        - inp: batch_size x seq_len\n",
        "        - target: batch_size x seq_len\n",
        "\n",
        "        inp should be target with <s> (start letter) prepended\n",
        "    \"\"\"\n",
        "\n",
        "    loss_fn = nn.NLLLoss()\n",
        "    batch_size, seq_len = inp.size()\n",
        "    inp = inp.permute(1, 0)           # seq_len x batch_size\n",
        "    target = target.permute(1, 0)     # seq_len x batch_size\n",
        "    h, c = self.init_hidden(batch_size)\n",
        "\n",
        "    loss = 0\n",
        "    for i in range(seq_len):\n",
        "        out, h, c = self.forward(inp[i], h, c)\n",
        "        loss += loss_fn(out, target[i])\n",
        "\n",
        "    return loss     # per batch\n",
        "\n",
        "  def batchPGLoss(self, inp, target, reward):\n",
        "    \"\"\"\n",
        "    Returns a pseudo-loss that gives corresponding policy gradients (on calling .backward()).\n",
        "    Inspired by the example in http://karpathy.github.io/2016/05/31/rl/\n",
        "\n",
        "    Inputs: inp, target\n",
        "        - inp: batch_size x seq_len\n",
        "        - target: batch_size x seq_len\n",
        "        - reward: batch_size (discriminator reward for each sentence, applied to each token of the corresponding\n",
        "                  sentence)\n",
        "\n",
        "        inp should be target with <s> (start letter) prepended\n",
        "    \"\"\"\n",
        "\n",
        "    batch_size, seq_len = inp.size()\n",
        "    inp = inp.permute(1, 0)          # seq_len x batch_size\n",
        "    target = target.permute(1, 0)    # seq_len x batch_size\n",
        "    h, c = self.init_hidden(batch_size)\n",
        "\n",
        "    loss = 0\n",
        "    for i in range(seq_len):\n",
        "        out, h, c = self.forward(inp[i], h, c)\n",
        "        # TODO: should h be detached from graph (.detach())?\n",
        "        for j in range(batch_size):\n",
        "            loss += -out[j][target.data[i][j]]*reward[j]#     # log(P(y_t|Y_1:Y_{t-1})) * Q\n",
        "\n",
        "    return loss/batch_size"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ut2px_RD4HIi"
      },
      "source": [
        "Объявяление класса Дискриминатора"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zUIXW8JMzAWk"
      },
      "source": [
        "class Discriminator(nn.Module):\n",
        "\n",
        "    def __init__(self, embedding_dim, hidden_dim, vocab_size, max_seq_len, gpu=False, dropout=0.2):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.hidden_dim = hidden_dim # размер скрытого слоя\n",
        "        self.embedding_dim = embedding_dim # ширина слоя embedding\n",
        "        self.max_seq_len = max_seq_len # длина входного примера\n",
        "        self.gpu = gpu # использование cuda (True/False)\n",
        "\n",
        "        self.embeddings = nn.Embedding(vocab_size, embedding_dim) # объявление слоя Embedding\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers=3, bidirectional=True, dropout=dropout) # объявление LSTM слоев\n",
        "\n",
        "        self.lstm2hidden = nn.Linear(2*3*hidden_dim, hidden_dim) # объявление скрытого слоя\n",
        "        # self.lstm2hidden = nn.Linear(max_seq_len*hidden_dim*2, hidden_dim) # объявление скрытого слоя\n",
        "\n",
        "        self.dropout_linear = nn.Dropout(p=dropout)\n",
        "        self.hidden2out = nn.Linear(hidden_dim, 1) # объявление выходного слоя\n",
        "\n",
        "    def init_hidden(self, batch_size):\n",
        "        # инициализация LSTM слоев\n",
        "        h = autograd.Variable(torch.zeros(2*3*1, batch_size, self.hidden_dim))\n",
        "        c = autograd.Variable(torch.zeros(2*3*1, batch_size, self.hidden_dim))\n",
        "\n",
        "        if self.gpu:\n",
        "            return h.cuda(), c.cuda()\n",
        "        else:\n",
        "            return h, c\n",
        "\n",
        "    def forward(self, input, hidden, c):\n",
        "        # input dim                                                # batch_size x seq_len\n",
        "        # print(input.shape)\n",
        "        emb = self.embeddings(input)                               # batch_size x seq_len x embedding_dim\n",
        "        # print(emb.shape)\n",
        "        emb = emb.permute(1, 0, 2)                                 # seq_len x batch_size x embedding_dim\n",
        "        # print(emb.shape)\n",
        "        out_lstm, (hidden, c) = self.lstm(emb, (hidden, c))                          # 4 x batch_size x hidden_dim\n",
        "\n",
        "        hidden = hidden.permute(1, 0, 2).contiguous()              # batch_size x 4 x hidden_dim\n",
        "        # hidden = out_lstm\n",
        "        # print(hidden.shape, hidden.view(-1, self.max_seq_len*self.hidden_dim).shape)\n",
        "        # print(hidden.permute(1, 0, 2).contiguous().shape, hidden.permute(1, 0, 2).contiguous().view(-1, self.max_seq_len*self.hidden_dim*2).shape)\n",
        "\n",
        "        out = self.lstm2hidden(hidden.view(-1, 6*self.hidden_dim))  # batch_size x 4*hidden_dim\n",
        "        # out = self.lstm2hidden(hidden.view(-1, self.max_seq_len*self.hidden_dim*2))  # batch_size x 4*hidden_dim\n",
        "        \n",
        "        out = torch.relu(out)\n",
        "        # out = out * torch.sigmoid(0.1 * out) # функция активации Swish: x * sigmoid(b*x)\n",
        "        out = self.dropout_linear(out)\n",
        "        out = self.hidden2out(out)                                 # batch_size x 1\n",
        "        out = torch.sigmoid(out)\n",
        "        return out\n",
        "\n",
        "    def batchClassify(self, inp):\n",
        "        \"\"\"\n",
        "        Classifies a batch of sequences.\n",
        "\n",
        "        Inputs: inp\n",
        "            - inp: batch_size x seq_len\n",
        "\n",
        "        Returns: out\n",
        "            - out: batch_size ([0,1] score)\n",
        "        \"\"\"\n",
        "\n",
        "        h, c = self.init_hidden(inp.size()[0])\n",
        "        out = self.forward(inp, h, c)\n",
        "        return out.view(-1)\n",
        "\n",
        "    def batchBCELoss(self, inp, target):\n",
        "        \"\"\"\n",
        "        Returns Binary Cross Entropy Loss for discriminator.\n",
        "\n",
        "         Inputs: inp, target\n",
        "            - inp: batch_size x seq_len\n",
        "            - target: batch_size (binary 1/0)\n",
        "        \"\"\"\n",
        "\n",
        "        loss_fn = nn.BCELoss()\n",
        "        h, c = self.init_hidden(inp.size()[0])\n",
        "        out = self.forward(inp, h, c)\n",
        "        return loss_fn(out, target)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "czr-pzJe4KTW"
      },
      "source": [
        "Объявление функций возвращающих данные"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cKQ2qmEm3xZ9"
      },
      "source": [
        "# функция генерации реалиных данных\n",
        "def sampler_example(batch_size):\n",
        "  x = data_file_train[np.random.randint(0, len(data_file_train), batch_size)]\n",
        "  y = np.concatenate([x[:, 1:], np.zeros([batch_size, 1])+VOCAB_SIZE-2], axis=-1)\n",
        "  return x, y\n",
        "\n",
        "# функция генерации реалиных данных\n",
        "def sampler_example_test(batch_size):\n",
        "  x = data_file_test[np.random.randint(0, len(data_file_test), batch_size)]\n",
        "  y = np.concatenate([x[:, 1:], np.zeros([batch_size, 1])+VOCAB_SIZE-2], axis=-1)\n",
        "  return x, y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-YpbTp_a5L1W"
      },
      "source": [
        "Функции обучения генератора"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jx23T6ef5MTA"
      },
      "source": [
        "# функция обучения генератора на основе MLE\n",
        "def train_generator_MLE(gen, gen_opt, real_samples_train, real_samples_test, epochs):\n",
        "    \"\"\"\n",
        "    Max Likelihood Pretraining for the generator\n",
        "    \"\"\"\n",
        "    for epoch in range(epochs):\n",
        "        print('epoch %d : ' % (epoch + 1), end='')\n",
        "        sys.stdout.flush()\n",
        "        total_loss = 0\n",
        "\n",
        "        # обучение\n",
        "        for i in range(0, len(real_samples_train), BATCH_SIZE):\n",
        "            inp_train, target_train = helpers.prepare_generator_batch(real_samples_train[i:i + BATCH_SIZE], start_letter=START_LETTER,\n",
        "                                                          gpu=CUDA)\n",
        "            gen_opt.zero_grad()\n",
        "            loss = gen.batchNLLLoss(inp_train, target_train)\n",
        "            loss.backward()\n",
        "            gen_opt.step()\n",
        "\n",
        "            total_loss += loss.data.item()\n",
        "\n",
        "            if (i / BATCH_SIZE) % ceil(\n",
        "                            ceil(len(real_samples_train) / float(BATCH_SIZE)) / 10.) == 0:  # roughly every 10% of an epoch\n",
        "                print('.', end='')\n",
        "                sys.stdout.flush()\n",
        "\n",
        "        # each loss in a batch is loss per sample\n",
        "        total_loss = total_loss / ceil(len(real_samples_train) / float(BATCH_SIZE)) / MAX_SEQ_LEN\n",
        "        print(' average_train_NLL = %.4f' % total_loss, end='')\n",
        "\n",
        "        # тестирование\n",
        "        test_loss = 0\n",
        "\n",
        "        for i in range(0, len(real_samples_test), BATCH_SIZE):\n",
        "            inp_test, target_test = helpers.prepare_generator_batch(real_samples_test[i:i + BATCH_SIZE], start_letter=START_LETTER,\n",
        "                                                              gpu=CUDA)\n",
        "            loss = gen.batchNLLLoss(inp_test, target_test)\n",
        "            test_loss += loss.data.item()\n",
        "        test_loss = test_loss / ceil(len(real_samples_test) / float(BATCH_SIZE)) / MAX_SEQ_LEN\n",
        "        print(' average_test_NLL = %.4f' % test_loss)\n",
        "\n",
        "def test_mle(gen, real_samples_train, real_samples_test):\n",
        "  '''\n",
        "  Тестирование генератора на обучающей и тестовой выборках.\n",
        "  '''\n",
        "  # тестирование на обучающей\n",
        "  test_loss = 0\n",
        "  for i in range(0, len(real_samples_train), BATCH_SIZE):\n",
        "      inp_test, target_test = helpers.prepare_generator_batch(real_samples_train[i:i + BATCH_SIZE], start_letter=START_LETTER,\n",
        "                                                        gpu=CUDA)\n",
        "      loss = gen.batchNLLLoss(inp_test, target_test)\n",
        "      test_loss += loss.data.item()\n",
        "  test_loss = test_loss / ceil(len(real_samples_train) / float(BATCH_SIZE)) / MAX_SEQ_LEN\n",
        "  print('average_train_NLL = %.4f' % test_loss, end='')\n",
        "\n",
        "  # тестирование на тестовой\n",
        "  test_loss = 0\n",
        "  for i in range(0, len(real_samples_test), BATCH_SIZE):\n",
        "      inp_test, target_test = helpers.prepare_generator_batch(real_samples_test[i:i + BATCH_SIZE], start_letter=START_LETTER,\n",
        "                                                        gpu=CUDA)\n",
        "      loss = gen.batchNLLLoss(inp_test, target_test)\n",
        "      test_loss += loss.data.item()\n",
        "  test_loss = test_loss / ceil(len(real_samples_test) / float(BATCH_SIZE)) / MAX_SEQ_LEN\n",
        "  print(' average_test_NLL = %.4f' % test_loss)\n",
        "\n",
        "# функция обучения генератора на основе обучения с подкреплением RL\n",
        "def train_generator_PG(gen, gen_opt, dis, num_batches): # !переименовать!\n",
        "    \"\"\"\n",
        "    The generator is trained using policy gradients, using the reward from the discriminator.\n",
        "    Training is done for num_batches batches.\n",
        "    \"\"\"\n",
        "\n",
        "    for batch in range(num_batches):\n",
        "        s = gen.sample(BATCH_SIZE*4)        # 64 works best\n",
        "        inp, target = helpers.prepare_generator_batch(s, start_letter=START_LETTER, gpu=CUDA)\n",
        "        rewards = dis.batchClassify(target)\n",
        "\n",
        "        gen_opt.zero_grad()\n",
        "        pg_loss = gen.batchPGLoss(inp, target, rewards)\n",
        "        pg_loss.backward()\n",
        "        gen_opt.step()\n",
        "    print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bx5xFCA35pKw"
      },
      "source": [
        "Функция обучения дискриминатора"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bSi-RHh45pk3"
      },
      "source": [
        "# функция обучения дискриминатора\n",
        "def train_discriminator(discriminator, dis_opt, real_data_samples, generator, d_steps, epochs):\n",
        "    \"\"\"\n",
        "    Training the discriminator on real_data_samples (positive) and generated samples from generator (negative).\n",
        "    Samples are drawn d_steps times, and the discriminator is trained for epochs epochs.\n",
        "    \"\"\"\n",
        "\n",
        "    # generating a small validation set before training\n",
        "    pos_val = real_data_samples[np.random.randint(0, len(real_data_samples), 500)] #sampler_example(250)\n",
        "    neg_val = generator.sample(500)\n",
        "    val_inp, val_target = helpers.prepare_discriminator_data(pos_val, neg_val, gpu=CUDA)\n",
        "\n",
        "    for d_step in range(d_steps):\n",
        "        s = helpers.batchwise_sample(generator, POS_NEG_SAMPLES, BATCH_SIZE)\n",
        "        dis_inp, dis_target = helpers.prepare_discriminator_data(real_data_samples, s, gpu=CUDA)\n",
        "        val_pred = discriminator.batchClassify(val_inp)\n",
        "        print('ДО ОБУЧЕНИЯ: val_acc = %.4f' % (\n",
        "            torch.sum((val_pred>0.5)==(val_target>0.5)).data.item()/1000.))\n",
        "        for epoch in range(epochs):\n",
        "            print('d-step %d epoch %d : ' % (d_step + 1, epoch + 1), end='')\n",
        "            sys.stdout.flush()\n",
        "            total_loss = 0\n",
        "            total_acc = 0\n",
        "\n",
        "            for i in range(0, 2 * POS_NEG_SAMPLES, BATCH_SIZE):\n",
        "                inp, target = dis_inp[i:i + BATCH_SIZE], dis_target[i:i + BATCH_SIZE]\n",
        "                dis_opt.zero_grad()\n",
        "                out = discriminator.batchClassify(inp)\n",
        "                loss_fn = nn.BCELoss()\n",
        "                loss = loss_fn(out, target)\n",
        "                loss.backward()\n",
        "                dis_opt.step()\n",
        "\n",
        "                total_loss += loss.data.item()\n",
        "                total_acc += torch.sum((out>0.5)==(target>0.5)).data.item()\n",
        "\n",
        "                if (i / BATCH_SIZE) % ceil(ceil(2 * POS_NEG_SAMPLES / float(\n",
        "                        BATCH_SIZE)) / 10.) == 0:  # roughly every 10% of an epoch\n",
        "                    print('.', end='')\n",
        "                    sys.stdout.flush()\n",
        "\n",
        "            total_loss /= ceil(2 * POS_NEG_SAMPLES / float(BATCH_SIZE))\n",
        "            total_acc /= float(2 * POS_NEG_SAMPLES)\n",
        "\n",
        "            val_pred = discriminator.batchClassify(val_inp)\n",
        "            print(' average_loss = %.4f, train_acc = %.4f, val_acc = %.4f' % (\n",
        "                total_loss, total_acc, torch.sum((val_pred>0.5)==(val_target>0.5)).data.item()/1000.))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OBuFdlsb55XU"
      },
      "source": [
        "Функция оценки качества генерации текста"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P_D3lTI654PU"
      },
      "source": [
        "# оценка качества по BLEU метрике\n",
        "from nltk.translate.bleu_score import SmoothingFunction\n",
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "from datetime import datetime\n",
        "import nltk\n",
        "import random\n",
        "from scipy import stats\n",
        "\n",
        "# функция оценки качества генерации текста по метрике BLEU\n",
        "def BLEU(reference_sample, test_sample, print_iteration=100, flag_print=True):\n",
        "  if flag_print:\n",
        "    print(\"--- --- ---\\nStart BLEU\")\n",
        "  pad = CLOSING_WORD\n",
        "  #################################################\n",
        "  reference = []\n",
        "  for line in reference_sample:\n",
        "    candidate = []\n",
        "    for i in line:\n",
        "      if i == pad:\n",
        "        break\n",
        "      candidate.append(i)\n",
        "\n",
        "    reference.append(candidate)\n",
        "  #################################################\n",
        "  hypothesis_list_leakgan = []\n",
        "  for line in test_sample:\n",
        "    while line[-1] == str(pad):\n",
        "      line.remove(str(pad))\n",
        "    hypothesis_list_leakgan.append(line)\n",
        "  #################################################\n",
        "  random.shuffle(hypothesis_list_leakgan)\n",
        "  #################################################\n",
        "\n",
        "  smoothing_function = SmoothingFunction().method1\n",
        "\n",
        "  mass_bleu = []\n",
        "  for ngram in range(2,6):\n",
        "      weight = tuple((1. / ngram for _ in range(ngram)))\n",
        "      bleu_leakgan = []\n",
        "      bleu_supervise = []\n",
        "      bleu_base2 = []\n",
        "      num = 0\n",
        "      for h in hypothesis_list_leakgan:\n",
        "          BLEUscore = nltk.translate.bleu_score.sentence_bleu(reference, h, weight, smoothing_function = smoothing_function)\n",
        "          num += 1\n",
        "          bleu_leakgan.append(BLEUscore)\n",
        "\n",
        "          if num%print_iteration == 0 and flag_print:\n",
        "            print(ngram, num, sum(bleu_leakgan)/len(bleu_leakgan))\n",
        "          \n",
        "      mass_bleu.append(1.0 * sum(bleu_leakgan) / len(bleu_leakgan))\n",
        "      if flag_print:\n",
        "        print('--- --- ---')\n",
        "        print(len(weight), '-gram BLEU score : ', 1.0 * sum(bleu_leakgan) / len(bleu_leakgan), \"\\n\")\n",
        "  return mass_bleu"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XlNNlpWxIEM0"
      },
      "source": [
        "Функция сохранения моделей"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "idULo4Q_IC6z"
      },
      "source": [
        "# функция сохранения моделей (сериализация: моделей генератора и дискриминатора, параметров по умолчанию, обучающих данных)\n",
        "def save_models(data_file_tensor_train, gen, dis, gen_optimizer, dis_optimizer, name):\n",
        "  state = {\n",
        "      'default_parameters': {'VOCAB_SIZE': VOCAB_SIZE, 'MAX_SEQ_LEN': MAX_SEQ_LEN, 'GEN_EMBEDDING_DIM': GEN_EMBEDDING_DIM,\n",
        "                             'GEN_HIDDEN_DIM': GEN_HIDDEN_DIM, 'DIS_EMBEDDING_DIM': DIS_EMBEDDING_DIM, 'DIS_HIDDEN_DIM': DIS_HIDDEN_DIM},\n",
        "      'data_file_tensor_train': data_file_tensor_train,\n",
        "      'gen_state_dict': gen.state_dict(),\n",
        "      'dis_state_dict': dis.state_dict(),\n",
        "      'gen_optimizer': gen_optimizer.state_dict(),\n",
        "      'dis_optimizer': dis_optimizer.state_dict(),\n",
        "  }\n",
        "  torch.save(state, name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bg9nWuCKHgZQ"
      },
      "source": [
        "Функция загрузки моделей"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iAlKsfNiHUnZ"
      },
      "source": [
        "# функция загрузки моделей (десериализация: моделей генератора и дискриминатора, параметров по умолчанию, обучающих данных)\n",
        "def load_models(name):\n",
        "  if CUDA:\n",
        "    device = torch.device('cuda')\n",
        "  else:\n",
        "    device = torch.device('cpu')\n",
        "\n",
        "  print('state')\n",
        "  state = torch.load(name, map_location=device)\n",
        "\n",
        "  print('default_parameters')\n",
        "  VOCAB_SIZE = state['default_parameters']['VOCAB_SIZE']\n",
        "  MAX_SEQ_LEN = state['default_parameters']['MAX_SEQ_LEN']\n",
        "  GEN_EMBEDDING_DIM = state['default_parameters']['GEN_EMBEDDING_DIM']\n",
        "  GEN_HIDDEN_DIM = state['default_parameters']['GEN_HIDDEN_DIM']\n",
        "  DIS_EMBEDDING_DIM = state['default_parameters']['DIS_EMBEDDING_DIM']\n",
        "  DIS_HIDDEN_DIM = state['default_parameters']['DIS_HIDDEN_DIM']\n",
        "\n",
        "  print('data_file_tensor_train')\n",
        "  data_file_tensor_train = torch.tensor(state['data_file_tensor_train'])\n",
        "\n",
        "  print('Generator')\n",
        "  gen = Generator(GEN_EMBEDDING_DIM, GEN_HIDDEN_DIM, VOCAB_SIZE, MAX_SEQ_LEN, gpu=CUDA)\n",
        "  gen.load_state_dict(state['gen_state_dict'])\n",
        "  gen_optimizer = optim.Adam(gen.parameters(), lr=0.001)\n",
        "  gen_optimizer.load_state_dict(state['gen_optimizer'])\n",
        "\n",
        "  print('Discriminator')\n",
        "  dis = Discriminator(DIS_EMBEDDING_DIM, DIS_HIDDEN_DIM, VOCAB_SIZE, MAX_SEQ_LEN, gpu=CUDA)\n",
        "  dis.load_state_dict(state['dis_state_dict'])\n",
        "  dis_optimizer = optim.Adagrad(dis.parameters())\n",
        "  dis_optimizer.load_state_dict(state['dis_optimizer'])\n",
        "\n",
        "  print('CUDA')\n",
        "  if CUDA:\n",
        "    data_file_tensor_train = data_file_tensor_train.cuda()\n",
        "    gen = gen.cuda()\n",
        "    dis = dis.cuda()\n",
        "  \n",
        "  return [data_file_tensor_train, gen, dis, gen_optimizer, dis_optimizer,\n",
        "          VOCAB_SIZE, MAX_SEQ_LEN, GEN_EMBEDDING_DIM, GEN_HIDDEN_DIM, DIS_EMBEDDING_DIM, DIS_HIDDEN_DIM]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vorPpC0M65Lv"
      },
      "source": [
        "Загрузка набора данных"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vB8boRQzJ_sb"
      },
      "source": [
        "# загрузка словаря\n",
        "import pickle\n",
        "\n",
        "vocab_file = FILE_PATHS['vocab']\n",
        "word, vocab = pickle.load(open(vocab_file, 'rb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4MmMIx2VQmal",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "598dbc0f-e4a3-4089-c747-75478dc3278f"
      },
      "source": [
        "# загрузка обучающей выборки\n",
        "f = open(FILE_PATHS['train'], 'r')\n",
        "data_file_train = []\n",
        "for line in f:\n",
        "  line = line.replace('\\n', '')\n",
        "  line = line.split()\n",
        "  for i in range(len(line)):\n",
        "    line[i] = int(line[i])\n",
        "  data_file_train.append(line)\n",
        "data_file_train = np.array(data_file_train)[:, :MAX_SEQ_LEN]\n",
        "print(\"Примеров в обучающей выборке: \", len(data_file_train))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Примеров в обучающей выборке:  80000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QHY_LhDP_o9n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71a0febc-8e3e-4cb9-e80b-03d5bf589400"
      },
      "source": [
        "# загрузка тестовой выборки\n",
        "f = open(FILE_PATHS['test'], 'r')\n",
        "data_file_test = []\n",
        "for line in f:\n",
        "  line = line.replace('\\n', '')\n",
        "  line = line.split()\n",
        "  for i in range(len(line)):\n",
        "    line[i] = int(line[i])\n",
        "  data_file_test.append(line)\n",
        "data_file_test = np.array(data_file_test)[:, :MAX_SEQ_LEN]\n",
        "print(\"Примеров в тестовой выборке: \", len(data_file_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Примеров в тестовой выборке:  5000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zc9jtz0qaQHO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e539cd6-63f9-4dea-c422-558ed8e35105"
      },
      "source": [
        "# примеры из обучающей выборки\n",
        "print(\"Примеры из обучающей выборки\")\n",
        "samples = sampler_example(50)[0]\n",
        "output_function = []\n",
        "for samp in samples:\n",
        "  line = [word[x] for x in samp]\n",
        "  line = ' '.join(line)\n",
        "  output_function.append(line)\n",
        "\n",
        "for i, output in enumerate(output_function):\n",
        "  print(\"#\", i, \"\\tПример: \", output)    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Примеры из обучающей выборки\n",
            "# 0 \tПример:  A red stop sign next to the side of a road .                \n",
            "# 1 \tПример:  A person riding on a bike with a helmet and gloves on .              \n",
            "# 2 \tПример:  An elephant holding a small piece of paper in its trunk .                \n",
            "# 3 \tПример:  A train with engine is standing on the railway station .                  \n",
            "# 4 \tПример:  A person on a snow board in the air at night .                \n",
            "# 5 \tПример:  A woman on the sidewalk with her back to us .                  \n",
            "# 6 \tПример:  A gray cat is sitting on the hood of a car .                \n",
            "# 7 \tПример:  An individual holding a remote control , aiming it at the television and pushing a button .      \n",
            "# 8 \tПример:  A man holding up a white neck tie with a bucket of paint on it .        \n",
            "# 9 \tПример:  Two people play tennis on a tennis court in a resort complex .              \n",
            "# 10 \tПример:  A lighthouse shines brightly in the background of this picture .                  \n",
            "# 11 \tПример:  A young woman takes pictures of a large black jet .                  \n",
            "# 12 \tПример:  A man and dog on top of a surfboard in the water .              \n",
            "# 13 \tПример:  A man stands by a bicycle on a dirty street .                  \n",
            "# 14 \tПример:  Two fire engines and two small fire trucks parked in a parking lot .            \n",
            "# 15 \tПример:  A man is riding a bicycle while other men are waiting .                \n",
            "# 16 \tПример:  A plate with an apple , grapes and a knife next to a glass with a spoon in it .\n",
            "# 17 \tПример:  A man rests his head on another man ' s shoulder for a photo .          \n",
            "# 18 \tПример:  A personal pizza with a baseball field in the background .                  \n",
            "# 19 \tПример:  A group of people are standing next to an airplane .                  \n",
            "# 20 \tПример:  A white polar bear stands with a carrot in it ' s mouth .            \n",
            "# 21 \tПример:  A statue of a silver bear is sitting on a green bench .              \n",
            "# 22 \tПример:  A herd of elephants wading through a large body of water .                \n",
            "# 23 \tПример:  A deer like animal standing on a sidewalk next to a fire hydrant .            \n",
            "# 24 \tПример:  A girl being viewed through a wine glass at a table .                \n",
            "# 25 \tПример:  A couple of birds by some plants in the water .                  \n",
            "# 26 \tПример:  A couple motorcycles parked on the side of the road .                  \n",
            "# 27 \tПример:  A book with a train on the cover near a keyboard .                \n",
            "# 28 \tПример:  A black cat that is sitting on top of a television .                \n",
            "# 29 \tПример:  A man sitting on a seat in the back of a van .              \n",
            "# 30 \tПример:  A skateboarder rode down the skate ramp , he has on a red hat .          \n",
            "# 31 \tПример:  A home is furnished with a chair , table , and bed .              \n",
            "# 32 \tПример:  A person petting the face of a brown and white horse .                \n",
            "# 33 \tПример:  A small white and black bird walking across a dirty covered ground .              \n",
            "# 34 \tПример:  A group of young men kicking a ball around a field .                \n",
            "# 35 \tПример:  A lady standing in front of an oven cooking pizza .                  \n",
            "# 36 \tПример:  Three elephants stand next to each other in their enclosure .                  \n",
            "# 37 \tПример:  An open pink suitcase in front of a pink wall .                  \n",
            "# 38 \tПример:  A kitchen that has an in - wall refrigerator and microwave , along with a dishwasher and wood cabinets .\n",
            "# 39 \tПример:  Two horses are pulling a red wagon on the street .                  \n",
            "# 40 \tПример:  A tiger striped cat about to step onto a computer keyboard .                \n",
            "# 41 \tПример:  Two people are watching a woman playing a game in an office .              \n",
            "# 42 \tПример:  A variety of food on display outside on a city sidewalk .                \n",
            "# 43 \tПример:  A beautiful woman standing on the side of a ski slope holding ski poles .          \n",
            "# 44 \tПример:  A black cat is on a yellow checkered bed under a desk .              \n",
            "# 45 \tПример:  A group of people sitting and standing around a bench .                  \n",
            "# 46 \tПример:  A bus pulled over near a sidewalk with people on it .                \n",
            "# 47 \tПример:  A cat sits on a chair near a laptop while another looks out a window .        \n",
            "# 48 \tПример:  A cinnamon apple dessert with vanilla ice cream in a dish .                \n",
            "# 49 \tПример:  A woman in a kitchen standing in front of a pizza .                \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FtfMO3AXK-yk"
      },
      "source": [
        "Оценка качества примеров из обучающей выборки на основе BLEU  (для сравнения с генератором)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FNMHGxTTIQMZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "796e5540-ed56-4139-bb9d-c140ecb0a5a6"
      },
      "source": [
        "%%time\n",
        "# оценка качества на основе примеров из обучающей выборки (для сравнения с генератором)\n",
        "print(\"Оценка примеров из обучающей выборки на основе BLEU\")\n",
        "BLEU(data_file_test.tolist(), data_file_train[:500].tolist(), print_iteration=100)\n",
        "\n",
        "'''\n",
        "BLEU примеров из обучающей выборки\n",
        "--- --- ---\n",
        "Start BLEU\n",
        "2 100 0.5365504958995001\n",
        "2 200 0.5426700180034696\n",
        "2 300 0.5425210147596119\n",
        "2 400 0.5438925313146432\n",
        "2 500 0.5499117864293879\n",
        "--- --- ---\n",
        "2 -gram BLEU score :  0.5499117864293879\n",
        "3 100 0.4252853298296578\n",
        "3 200 0.4294441261529973\n",
        "3 300 0.42938411299670276\n",
        "3 400 0.432946142036555\n",
        "3 500 0.436991427933691\n",
        "--- --- ---\n",
        "3 -gram BLEU score :  0.436991427933691\n",
        "4 100 0.3118228221158724\n",
        "4 200 0.31347352868277367\n",
        "4 300 0.3133847969805193\n",
        "4 400 0.3148005592801212\n",
        "4 500 0.3173224414085976\n",
        "--- --- ---\n",
        "4 -gram BLEU score :  0.3173224414085976\n",
        "5 100 0.20748007111715946\n",
        "5 200 0.21057918753505803\n",
        "5 300 0.20884027925072032\n",
        "5 400 0.20986772415037908\n",
        "5 500 0.21083373415979106\n",
        "--- --- ---\n",
        "5 -gram BLEU score :  0.21083373415979106\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Оценка примеров из обучающей выборки на основе BLEU\n",
            "--- --- ---\n",
            "Start BLEU\n",
            "2 100 0.5421079509296283\n",
            "2 200 0.5499670537764236\n",
            "2 300 0.5487035461267846\n",
            "2 400 0.5475417748156669\n",
            "2 500 0.5499117864293877\n",
            "--- --- ---\n",
            "2 -gram BLEU score :  0.5499117864293877 \n",
            "\n",
            "3 100 0.4209555782881417\n",
            "3 200 0.4339168124014302\n",
            "3 300 0.4329917541110669\n",
            "3 400 0.4342559012400833\n",
            "3 500 0.43699142793369145\n",
            "--- --- ---\n",
            "3 -gram BLEU score :  0.43699142793369145 \n",
            "\n",
            "4 100 0.29846429405080027\n",
            "4 200 0.31175877359006376\n",
            "4 300 0.3122735814016834\n",
            "4 400 0.31386833801542907\n",
            "4 500 0.3173224414085974\n",
            "--- --- ---\n",
            "4 -gram BLEU score :  0.3173224414085974 \n",
            "\n",
            "5 100 0.19259023471054995\n",
            "5 200 0.20160570942355704\n",
            "5 300 0.20423897927921025\n",
            "5 400 0.2063109642063208\n",
            "5 500 0.210833734159791\n",
            "--- --- ---\n",
            "5 -gram BLEU score :  0.210833734159791 \n",
            "\n",
            "CPU times: user 7min 36s, sys: 127 ms, total: 7min 36s\n",
            "Wall time: 7min 36s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wQ2SVFc57G_h"
      },
      "source": [
        "Создание нейронных сетей генератора и дискриминатора"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LziOsVRduVtC"
      },
      "source": [
        "# объявление нейронных сетей генератора и дискриминатора, подготовка выборок данных для использования pytorch\n",
        "gen = Generator(GEN_EMBEDDING_DIM, GEN_HIDDEN_DIM, VOCAB_SIZE, MAX_SEQ_LEN, gpu=CUDA)\n",
        "dis = Discriminator(DIS_EMBEDDING_DIM, DIS_HIDDEN_DIM, VOCAB_SIZE, MAX_SEQ_LEN, gpu=CUDA)\n",
        "\n",
        "if CUDA:\n",
        "  gen = gen.cuda()\n",
        "  dis = dis.cuda()\n",
        "  data_file_tensor_train = torch.tensor(data_file_train).cuda()\n",
        "  data_file_tensor_test = torch.tensor(data_file_test).cuda()\n",
        "else:\n",
        "  data_file_tensor_train = torch.tensor(data_file_train)\n",
        "  data_file_tensor_test = torch.tensor(data_file_test)\n",
        "\n",
        "gen_optimizer = optim.Adam(gen.parameters(), lr=0.001) #, lr=0.001\n",
        "dis_optimizer = optim.Adagrad(dis.parameters())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PjtGu-Dh7Xn0"
      },
      "source": [
        "Обучение генератора на основе MLE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2w7pqxEA3jhx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92a26377-8d3d-4f76-e9c3-ee1f6d48bf80"
      },
      "source": [
        "%%time\n",
        "test_mle(gen, data_file_tensor_train, data_file_tensor_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "average_train_NLL = 8.5058 average_test_NLL = 8.5068\n",
            "CPU times: user 1.55 s, sys: 46 ms, total: 1.6 s\n",
            "Wall time: 1.6 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R_ZzVettuZHH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42293ecc-e940-45d4-8068-a66423bac6fd"
      },
      "source": [
        "%%time\n",
        "# обучение генератора на основе MLE / предобучение генератора\n",
        "print('Запуск обучения генератора на основе MLE...')\n",
        "gen_optimizer = optim.Adam(gen.parameters())#, lr=0.0002\n",
        "train_generator_MLE(gen, gen_optimizer, data_file_tensor_train, data_file_tensor_test, MLE_TRAIN_EPOCHS) # MLE_TRAIN_EPOCHS\n",
        "\n",
        "test_mle(gen, data_file_tensor_train, data_file_tensor_test)\n",
        "# сохранение результата обучения\n",
        "save_models(data_file_tensor_train, gen, dis, gen_optimizer, dis_optimizer,\n",
        "            FILE_PATHS['saved_models'] + r'/' + r'seqgan_mle.pytorch')\n",
        "# epoch 1 : .......... average_train_NLL = 1.8447 average_test_NLL = 1.9937"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Запуск обучения генератора на основе MLE...\n",
            "epoch 1 : .......... average_train_NLL = 3.6984 average_test_NLL = 3.0179\n",
            "epoch 2 : .......... average_train_NLL = 2.6903 average_test_NLL = 2.6763\n",
            "epoch 3 : .......... average_train_NLL = 2.4632 average_test_NLL = 2.5240\n",
            "epoch 4 : .......... average_train_NLL = 2.3351 average_test_NLL = 2.4251\n",
            "epoch 5 : .......... average_train_NLL = 2.2443 average_test_NLL = 2.3538\n",
            "epoch 6 : .......... average_train_NLL = 2.1714 average_test_NLL = 2.2993\n",
            "epoch 7 : .......... average_train_NLL = 2.1094 average_test_NLL = 2.2562\n",
            "epoch 8 : .......... average_train_NLL = 2.0575 average_test_NLL = 2.2122\n",
            "epoch 9 : .......... average_train_NLL = 2.0134 average_test_NLL = 2.1799\n",
            "epoch 10 : .......... average_train_NLL = 1.9758 average_test_NLL = 2.1526\n",
            "epoch 11 : .......... average_train_NLL = 1.9435 average_test_NLL = 2.1228\n",
            "epoch 12 : .......... average_train_NLL = 1.9156 average_test_NLL = 2.0973\n",
            "epoch 13 : .......... average_train_NLL = 1.8894 average_test_NLL = 2.0686\n",
            "epoch 14 : .......... average_train_NLL = 1.8665 average_test_NLL = 2.0546\n",
            "epoch 15 : .......... average_train_NLL = 1.8448 average_test_NLL = 2.0391\n",
            "epoch 16 : .......... average_train_NLL = 1.8251 average_test_NLL = 2.0315\n",
            "epoch 17 : .......... average_train_NLL = 1.8071 average_test_NLL = 2.0209\n",
            "epoch 18 : .......... average_train_NLL = 1.7904 average_test_NLL = 2.0167\n",
            "epoch 19 : .......... average_train_NLL = 1.7749 average_test_NLL = 2.0074\n",
            "epoch 20 : .......... average_train_NLL = 1.7604 average_test_NLL = 1.9977\n",
            "average_train_NLL = 1.8360 average_test_NLL = 1.9977\n",
            "CPU times: user 1min 19s, sys: 6.59 s, total: 1min 26s\n",
            "Wall time: 1min 28s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9vE1qrmlgJNa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61c13a49-5aec-4cd5-9c09-bc799aaaa721"
      },
      "source": [
        "%%time\n",
        "test_mle(gen, data_file_tensor_train, data_file_tensor_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "average_train_NLL = 1.8360 average_test_NLL = 1.9977\n",
            "CPU times: user 1.55 s, sys: 37 ms, total: 1.58 s\n",
            "Wall time: 1.59 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O2AFMeIuIg6R"
      },
      "source": [
        "Генерация примеров текстов на основе MLE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eGaETrFgIfzL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "989df8c8-5443-4c94-992d-d83287cc9f8b"
      },
      "source": [
        "# примеры сгенерированных текстов\n",
        "print(\"Примеры генерируемых текстов на основе MLE\")\n",
        "degree = 1\n",
        "print(\"Degree:\", degree)\n",
        "samples = gen.sample(50, degree=degree).cpu().detach().numpy()\n",
        "\n",
        "output_function = []\n",
        "for i, samp in enumerate(samples):\n",
        "  line = [word[x] for x in samp]\n",
        "  line = ' '.join(line)\n",
        "  output_function.append(line)\n",
        "  bleu = BLEU(data_file_test.tolist(), [samp], flag_print=False)\n",
        "  print(\"#\", i, \"\\tПример: \", line, ' '*(100-len(line)), '\\tОценка: ', bleu)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Примеры генерируемых текстов на основе MLE\n",
            "Degree: 1\n",
            "# 0 \tПример:  A group of people are parasailing on a laptop in a wooden pool .                                      \tОценка:  [0.5548826333938605, 0.49288159365841444, 0.38126332702591925, 0.26555594605914223]\n",
            "# 1 \tПример:  A pizza sitting on top of a blue plate with food on it while others look at the table .               \tОценка:  [0.9733285267845752, 0.8334502759861924, 0.6423770871903809, 0.4630352305296693]\n",
            "# 2 \tПример:  A display of red butter set stands in front of a bed .                                                \tОценка:  [0.533113989983183, 0.42898873304984025, 0.3435599238920265, 0.2806622489471059]\n",
            "# 3 \tПример:  A couple of people sitting on top of a Wii controller .                                               \tОценка:  [0.4812265031857878, 0.44823751677106155, 0.40342371407615724, 0.3191472754928875]\n",
            "# 4 \tПример:  A Nintendo Wii on the teams just hit the front window .                                               \tОценка:  [0.3077935056255462, 0.17394640854894952, 0.0745932224853342, 0.04542924288455331]\n",
            "# 5 \tПример:  A lot of people are getting ready to play the video game .                                            \tОценка:  [0.5548826333938605, 0.4681952501639962, 0.41682189465797687, 0.3275988897735649]\n",
            "# 6 \tПример:  A polka dot computer mouse and an office sheets with a room of coffee towing it .                     \tОценка:  [0.5231483637805969, 0.11498973660786516, 0.05468674556294572, 0.03543901697517779]\n",
            "# 7 \tПример:  A large group of people in a kite skating passengers .                                                \tОценка:  [0.4588314677411235, 0.3881515247704053, 0.3424946089789314, 0.24372439184104333]\n",
            "# 8 \tПример:  The bowl of pickles on the counter outdoors on the table .                                            \tОценка:  [0.4701623459816272, 0.3327475090445512, 0.21576146358278564, 0.10625640225460382]\n",
            "# 9 \tПример:  Small utility person riding a wave but with taxis and fans near the mountain .                        \tОценка:  [0.4701623459816272, 0.2906817235909849, 0.10963546543618267, 0.06182111806058444]\n",
            "# 10 \tПример:  A two zebra standing and TV side by side of other a wire .                                            \tОценка:  [0.5758289219624358, 0.3327475090445512, 0.12133158735615288, 0.06704325740058405]\n",
            "# 11 \tПример:  Two umbrellas playing a video game with a teddy bear .                                                \tОценка:  [0.41675437673324534, 0.268229131353767, 0.1835554260049945, 0.09336622186146905]\n",
            "# 12 \tПример:  A person holding a soccer top near a crowd of people watching .                                       \tОценка:  [0.5848976518656018, 0.5104992364672556, 0.44476089284108944, 0.374198057862978]\n",
            "# 13 \tПример:  A snowboarder performing a serve in the frisbee while some friends take waves .                       \tОценка:  [0.17013926184468015, 0.054380791933026716, 0.03118687901642477, 0.022612758047214694]\n",
            "# 14 \tПример:  A four pillow cross a crowded street with a plastic wedge .                                           \tОценка:  [0.45014617508912413, 0.32323518297936166, 0.11872077943222034, 0.0658866452025356]\n",
            "# 15 \tПример:  A semi - vendor sits next to two kids in a mirror .                                                   \tОценка:  [0.5026246899500345, 0.3829055908234224, 0.2397212592215149, 0.11559558408112314]\n",
            "# 16 \tПример:  Two people sit and watching TV and playing video games .                                              \tОценка:  [0.3627381250550058, 0.19407576238520263, 0.08097785064266204, 0.048514214015354815]\n",
            "# 17 \tПример:  There is a man moving toward the ocean slightly up .                                                  \tОценка:  [0.41675437673324534, 0.268229131353767, 0.1835554260049945, 0.09336622186146905]\n",
            "# 18 \tПример:  Happy people standing around a video game playing a game .                                            \tОценка:  [0.40717253552297766, 0.3023211754492263, 0.200788666417121, 0.10031534236369895]\n",
            "# 19 \tПример:  A girl with a clock and four kite in the air .                                                        \tОценка:  [0.5619514869490163, 0.4721631957086834, 0.36917916399395617, 0.1632923161254164]\n",
            "# 20 \tПример:  Several varieties of people sharing a kite in a match .                                               \tОценка:  [0.3441236008058426, 0.2360815978543417, 0.16679551613797314, 0.08648155715006021]\n",
            "# 21 \tПример:  A building that has a couch markings in the water .                                                   \tОценка:  [0.4588314677411235, 0.3881515247704053, 0.3187271473320672, 0.2300971545350741]\n",
            "# 22 \tПример:  A man standing near the ocean while several a woman .                                                 \tОценка:  [0.45014617508912413, 0.38323768603830394, 0.2852636439147137, 0.21055867735724068]\n",
            "# 23 \tПример:  A motorcycle frame with two people flying in the sky .                                                \tОценка:  [0.4812265031857878, 0.37195938466682343, 0.2789439259471503, 0.2068185698600316]\n",
            "# 24 \tПример:  The front reflection in the dark room with it ' s lights turned like other .                          \tОценка:  [0.6488856845230502, 0.5196828406118894, 0.3584668928097086, 0.15949065609065943]\n",
            "# 25 \tПример:  A man is swinging racket the tennis ball .                                                            \tОценка:  [0.27144835701531844, 0.20154745029948426, 0.08330493905143331, 0.049626380861717174]\n",
            "# 26 \tПример:  A farmers area features a pizza on a couch and a notebook .                                           \tОценка:  [0.533113989983183, 0.36182311050064736, 0.12919925124488807, 0.07049916949671992]\n",
            "# 27 \tПример:  A person on a backpack in front of a very tasty looking passenger Here .                              \tОценка:  [0.5758289219624358, 0.4192355909453147, 0.3051327880362441, 0.14020616334521654]\n",
            "# 28 \tПример:  A full rifle holding a law with a green bike .                                                        \tОценка:  [0.3441236008058426, 0.1873780883921577, 0.07887272990342094, 0.047502613204364615]\n",
            "# 29 \tПример:  A group of people standing on top of sandy beach holding trees .                                      \tОценка:  [0.5548826333938605, 0.4681952501639962, 0.41682189465797687, 0.37631230578174896]\n",
            "# 30 \tПример:  Man lying on a bed looking off into a toilet and .                                                    \tОценка:  [0.5026246899500345, 0.41247254393856775, 0.14253911354181859, 0.0762646438227276]\n",
            "# 31 \tПример:  a boy wearing a helmet jumping a oven next to a white wall .                                          \tОценка:  [0.6649099662043687, 0.5560541333192193, 0.4173552570984386, 0.1801277872949914]\n",
            "# 32 \tПример:  Two men are on mobile couch in a living room with two couches and coffee table .                      \tОценка:  [0.7914011558455574, 0.6245103377171076, 0.4892800310863599, 0.3242067081134428]\n",
            "# 33 \tПример:  A very long large sandwich and two chairs sitting on a television paper .                             \tОценка:  [0.5758289219624358, 0.4192355909453147, 0.1442883869585112, 0.0770124794896937]\n",
            "# 34 \tПример:  Two surfers , one sandwich and followed fashioned on a table .                                        \tОценка:  [0.39735970711951313, 0.2598414203059447, 0.17923344640485428, 0.09160332714436914]\n",
            "# 35 \tПример:  Two hot dogs are in the bathroom looking into a pie .                                                 \tОценка:  [0.435285750066007, 0.31608160102348876, 0.2076047003130265, 0.10303048615651293]\n",
            "# 36 \tПример:  The man is cutting a kite fly the floor airplane .                                                    \tОценка:  [0.45014617508912413, 0.2823719413662334, 0.10727633416507679, 0.06075459680224768]\n",
            "# 37 \tПример:  A surfboard tries to easel from the ceiling has the tube .                                            \tОценка:  [0.22941573387056174, 0.14299624434994673, 0.06439931429457921, 0.040390664483064546]\n",
            "# 38 \tПример:  Two people standing on a beach holding a kite kite .                                                  \tОценка:  [0.4812265031857878, 0.40068110080455893, 0.2480201200336197, 0.11878607549052882]\n",
            "# 39 \tПример:  A sink directing contains the sink and three pieces of it .                                           \tОценка:  [0.45014617508912413, 0.2823719413662334, 0.10727633416507679, 0.06075459680224768]\n",
            "# 40 \tПример:  A bunch of people are watching displayed in a blue room .                                             \tОценка:  [0.533113989983183, 0.4558685532582043, 0.2732231510487644, 0.12834826432879642]\n",
            "# 41 \tПример:  A black and white     next to a painting .                                                            \tОценка:  [0.37696851746252596, 0.28717919311756684, 0.19319794288373765, 0.09726979526300615]\n",
            "# 42 \tПример:  A group of people sitting together on a serving , one couch .                                         \tОценка:  [0.5548826333938605, 0.44058859895528674, 0.35050403701715416, 0.24827353220010312]\n",
            "# 43 \tПример:  Group of people standing in a living room playing with their wedding cooking on video game side adds .    \tОценка:  [0.7416198487095663, 0.568085640286245, 0.4818819170776301, 0.32027903183364226]\n",
            "# 44 \tПример:  A person surfing on the beach getting to his waves on the ground .                                    \tОценка:  [0.5231483637805969, 0.3572998474390311, 0.22759483012793272, 0.11089345578518284]\n",
            "# 45 \tПример:  A man in white shirt on area holding a remote .                                                       \tОценка:  [0.45014617508912413, 0.32323518297936166, 0.11872077943222034, 0.0658866452025356]\n",
            "# 46 \tПример:  A blue and white slope flying over the ocean .                                                        \tОценка:  [0.42919753763947605, 0.3446412921261351, 0.22152015777624515, 0.10851920540253215]\n",
            "# 47 \tПример:  A large crowd near several young men play a video game .                                              \tОценка:  [0.39735970711951313, 0.20623627196928382, 0.08475426399505566, 0.05031590041818311]\n",
            "# 48 \tПример:  A sandwich is sitting in the cardboard box with strawberries .                                        \tОценка:  [0.3402785236893603, 0.2343197292238376, 0.16586105071157164, 0.08609373184361885]\n",
            "# 49 \tПример:  A picture of a building with a small bed .                                                            \tОценка:  [0.4588314677411235, 0.41247254393856775, 0.3584668928097086, 0.290362979195798]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8lZnWDHB7xsN"
      },
      "source": [
        "Оценка качества генерации текста после обучения с помощью MLE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4R2_zZKV7yPv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25bc49ca-10d7-4bbf-96e3-8a414d03c440"
      },
      "source": [
        "%%time\n",
        "print(\"Оценка качества генерации текста на основе BLEU, после обучения с помощью MLE\")\n",
        "# проверка качества обучения\n",
        "BLEU(data_file_test.tolist(), gen.sample(500, degree=degree).cpu().detach().numpy().tolist(), print_iteration=100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Оценка качества генерации текста на основе BLEU, после обучения с помощью MLE\n",
            "--- --- ---\n",
            "Start BLEU\n",
            "2 100 0.5080927823539096\n",
            "2 200 0.5239255352114979\n",
            "2 300 0.5196645922747047\n",
            "2 400 0.5169048486561942\n",
            "2 500 0.5124157647560529\n",
            "--- --- ---\n",
            "2 -gram BLEU score :  0.5124157647560529 \n",
            "\n",
            "3 100 0.3589668039910406\n",
            "3 200 0.37453352059029915\n",
            "3 300 0.37245833636267023\n",
            "3 400 0.37305866724577763\n",
            "3 500 0.3688106393597105\n",
            "--- --- ---\n",
            "3 -gram BLEU score :  0.3688106393597105 \n",
            "\n",
            "4 100 0.22814810872756944\n",
            "4 200 0.24001213438964086\n",
            "4 300 0.24151700368284398\n",
            "4 400 0.24360669484432723\n",
            "4 500 0.24210380591293543\n",
            "--- --- ---\n",
            "4 -gram BLEU score :  0.24210380591293543 \n",
            "\n",
            "5 100 0.1405140568859867\n",
            "5 200 0.1460657475667092\n",
            "5 300 0.14816910962004398\n",
            "5 400 0.15072367072668805\n",
            "5 500 0.14866956817307805\n",
            "--- --- ---\n",
            "5 -gram BLEU score :  0.14866956817307805 \n",
            "\n",
            "CPU times: user 7min 32s, sys: 109 ms, total: 7min 32s\n",
            "Wall time: 7min 32s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ILoM7VA7nKpO"
      },
      "source": [
        "Оценка с возведением в степень"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ncMN88-nGy6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b672bf86-1867-4b91-d483-f9db64f01a91"
      },
      "source": [
        "# примеры сгенерированных текстов\n",
        "print(\"Примеры генерируемых текстов на основе MLE\")\n",
        "degree = 1.5\n",
        "print(\"Degree:\", degree)\n",
        "samples = gen.sample(50, degree=degree).cpu().detach().numpy()\n",
        "\n",
        "output_function = []\n",
        "for i, samp in enumerate(samples):\n",
        "  line = [word[x] for x in samp]\n",
        "  line = ' '.join(line)\n",
        "  output_function.append(line)\n",
        "  bleu = BLEU(data_file_test.tolist(), [samp], flag_print=False)\n",
        "  print(\"#\", i, \"\\tПример: \", line, ' '*(100-len(line)), '\\tОценка: ', bleu)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Примеры генерируемых текстов на основе MLE\n",
            "Degree: 1.5\n",
            "# 0 \tПример:  A man in black shirt playing a video game in a kitchen .                                              \tОценка:  [0.5848976518656018, 0.42362581168373686, 0.30752616970214336, 0.1410852677518539]\n",
            "# 1 \tПример:  A bunch of people who are sitting in a field .                                                        \tОценка:  [0.5380275868489703, 0.5250407733778476, 0.4754122362294423, 0.39469037777958105]\n",
            "# 2 \tПример:  A young person flying a kite over a green field .                                                     \tОценка:  [0.45014617508912413, 0.32323518297936166, 0.2111187176080899, 0.10442329545559932]\n",
            "# 3 \tПример:  A woman in a living room playing a video game .                                                       \tОценка:  [0.4812265031857878, 0.37195938466682343, 0.2789439259471503, 0.1304936956280769]\n",
            "# 4 \tПример:  A large group of people gathered around a table with a remote controllers .                           \tОценка:  [0.6134458325505882, 0.5935080929093216, 0.5211893901353604, 0.449970927139221]\n",
            "# 5 \tПример:  A woman in a red jacket is riding a wave .                                                            \tОценка:  [0.5104177855340404, 0.44283653888216973, 0.3179273238456, 0.14488995814892022]\n",
            "# 6 \tПример:  A man and a woman are playing a game of video game .                                                  \tОценка:  [0.533113989983183, 0.3982378626139663, 0.32491891521065375, 0.2684120433772583]\n",
            "# 7 \tПример:  A woman in a red dress holding a Wii controller .                                                     \tОценка:  [0.3627381250550058, 0.2799056849071412, 0.18951629567590741, 0.0957840620111102]\n",
            "# 8 \tПример:  A man in a wetsuit is holding a bat sitting near a tennis ball .                                      \tОценка:  [0.6882472016116853, 0.5948883492590029, 0.3967088290836577, 0.17296311430012043]\n",
            "# 9 \tПример:  A group of people standing around a large cake with a knife .                                         \tОценка:  [0.6407232755171874, 0.5671781536927951, 0.48130446616982553, 0.3985989659640793]\n",
            "# 10 \tПример:  A man on a tennis court with a racket in the hand .                                                   \tОценка:  [0.5026246899500345, 0.30391236883880285, 0.20158074753947833, 0.10063180083636622]\n",
            "# 11 \tПример:  A small child is holding a video game remote in the background .                                      \tОценка:  [0.5548826333938605, 0.44058859895528674, 0.31671615012203974, 0.14444821224686133]\n",
            "# 12 \tПример:  A man standing next to a child , holding a kite .                                                     \tОценка:  [0.5619514869490163, 0.49705875547910827, 0.412295470431275, 0.3521819593208653]\n",
            "# 13 \tПример:  A man with a kite flying flying the kite on the ground .                                              \tОценка:  [0.533113989983183, 0.3982378626139663, 0.293597382795084, 0.13594954153429603]\n",
            "# 14 \tПример:  Two boys playing a video game while holding a Wii game controller .                                   \tОценка:  [0.380442955126341, 0.20034055040227947, 0.08293052535578581, 0.049447864072160404]\n",
            "# 15 \tПример:  A person holding a Wii controller in a large kitchen .                                                \tОценка:  [0.42919753763947605, 0.3446412921261351, 0.22152015777624515, 0.10851920540253215]\n",
            "# 16 \tПример:  A young man swinging a bat in a baseball game .                                                       \tОценка:  [0.39735970711951313, 0.2598414203059447, 0.10079037376973914, 0.05779779204056156]\n",
            "# 17 \tПример:  A man with a surfboard standing on the beach next to the ocean .                                      \tОценка:  [0.6920602346769048, 0.6639509405734763, 0.6274084880643078, 0.5660392742258654]\n",
            "# 18 \tПример:  A group of people standing on top of a beach .                                                        \tОценка:  [0.5380275868489703, 0.5250407733778476, 0.4940911248125205, 0.45083294673070695]\n",
            "# 19 \tПример:  A woman holding white remotes and a remote controller in a bathroom .                                 \tОценка:  [0.5231483637805969, 0.4236258116837369, 0.2585976536992378, 0.1228218593141609]\n",
            "# 20 \tПример:  A group of people flying kites fly in the sky .                                                       \tОценка:  [0.5380275868489703, 0.5048265531987134, 0.46161745771674506, 0.3855014663175419]\n",
            "# 21 \tПример:  A man is surfing on a hill holding a kite .                                                           \tОценка:  [0.4812265031857878, 0.37195938466682343, 0.13190443867346036, 0.07167761258360167]\n",
            "# 22 \tПример:  A man with a backpack is taking a picture of himself .                                                \tОценка:  [0.5893796917545019, 0.5579390770002352, 0.5171331332905545, 0.46757566031593883]\n",
            "# 23 \tПример:  Two people on a beach next to the ocean .                                                             \tОценка:  [0.4866642633922876, 0.4721631957086835, 0.4390304885323691, 0.3922687815593154]\n",
            "# 24 \tПример:  A room with a cat and a keyboard on the table .                                                       \tОценка:  [0.5893796917545019, 0.5131038694945721, 0.3550579456592081, 0.1582761188516619]\n",
            "# 25 \tПример:  A picture of a living room with a fireplace in the background .                                       \tОценка:  [0.5619514869490163, 0.5196828406118894, 0.47176896213068414, 0.4155004455267955]\n",
            "# 26 \tПример:  A group of people playing a video game on a video game console .                                      \tОценка:  [0.4701623459816272, 0.2906817235909849, 0.19496249079519765, 0.0979798691645551]\n",
            "# 27 \tПример:  A couple of people sitting on a beach behind a kite .                                                 \tОценка:  [0.5619514869490163, 0.49705875547910827, 0.435949382480739, 0.3395712052221365]\n",
            "# 28 \tПример:  A man and woman in a field while standing on the slope .                                              \tОценка:  [0.6134458325505882, 0.5509641073413446, 0.37453098197433415, 0.16518332463083782]\n",
            "# 29 \tПример:  A lady is standing in a kitchen next to a sink .                                                      \tОценка:  [0.5893796917545019, 0.5579390770002352, 0.5171331332905545, 0.4471671515841253]\n",
            "# 30 \tПример:  A baseball player swings a bat at a baseball field .                                                  \tОценка:  [0.32444284226152503, 0.1801639783124087, 0.07658412276041004, 0.046396689848933415]\n",
            "# 31 \tПример:  A man holding a tennis racket in a baseball game .                                                    \tОценка:  [0.42919753763947605, 0.3131273945313386, 0.2061477352156375, 0.10245162655617687]\n",
            "# 32 \tПример:  A dog sitting in a bed in a room with a computer .                                                    \tОценка:  [0.6407232755171874, 0.6306964608093198, 0.5454951299940093, 0.46668162765347004]\n",
            "# 33 \tПример:  A man in a living room with a remote control .                                                        \tОценка:  [0.5380275868489703, 0.5250407733778476, 0.4542291944311804, 0.3509150848958905]\n",
            "# 34 \tПример:  Two young women standing next to each other playing a video game .                                    \tОценка:  [0.5548826333938605, 0.4090062242255915, 0.3314862519307121, 0.27274350642227413]\n",
            "# 35 \tПример:  A boy flying a kite in a grassy field in front of trees .                                             \tОценка:  [0.6649099662043687, 0.6262547890626772, 0.5830738459889044, 0.5146937012650945]\n",
            "# 36 \tПример:  A woman in a living room with another - remote .                                                      \tОценка:  [0.45014617508912413, 0.38323768603830394, 0.31569611706824424, 0.22834494177465156]\n",
            "# 37 \tПример:  A young boy sitting in front of a TV in a room .                                                      \tОценка:  [0.6407232755171874, 0.5898890511424149, 0.5391877679155437, 0.5014161044490777]\n",
            "# 38 \tПример:  A woman in a bedroom and looking at a laptop .                                                        \tОценка:  [0.5104177855340404, 0.46618580376022084, 0.2778478578918629, 0.13008332996565256]\n",
            "# 39 \tПример:  A woman and a little girl are playing a game .                                                        \tОценка:  [0.4812265031857878, 0.37195938466682343, 0.2345629473857563, 0.1136013602356153]\n",
            "# 40 \tПример:  A man that is standing in a living room with a kite .                                                 \tОценка:  [0.6407232755171874, 0.6109741448719966, 0.572370695651743, 0.5259544888154983]\n",
            "# 41 \tПример:  A man is playing a game on the Wii motorcycle .                                                       \tОценка:  [0.4588314677411235, 0.28599248869989347, 0.10830630507021792, 0.061220799289344076]\n",
            "# 42 \tПример:  A young man is swinging a bat at a ball in the air .                                                  \tОценка:  [0.5848976518656018, 0.45633707214217845, 0.32516933459899267, 0.1475243362492685]\n",
            "# 43 \tПример:  A woman is flying a kite in the sky .                                                                 \tОценка:  [0.4866642633922876, 0.42898873304984025, 0.3435599238920265, 0.24433067891686003]\n",
            "# 44 \tПример:  A young boy is playing a video game in the living room .                                              \tОценка:  [0.5848976518656018, 0.45633707214217845, 0.3598590234416894, 0.2535606877812186]\n",
            "# 45 \tПример:  A man is standing in front of a computer desk with a laptop .                                         \tОценка:  [0.6920602346769048, 0.6834900197659399, 0.6412059299276004, 0.5759758543496769]\n",
            "# 46 \tПример:  A baby laying in front of a window looking at a window .                                              \tОценка:  [0.5619514869490163, 0.4721631957086834, 0.3335910322759463, 0.2386423391385826]\n",
            "# 47 \tПример:  A boy is standing in the living room with a kite .                                                    \tОценка:  [0.5893796917545019, 0.5579390770002352, 0.4496171332314307, 0.19118344596905382]\n",
            "# 48 \tПример:  A woman uses a brown leather couch next to a wall .                                                   \tОценка:  [0.5026246899500345, 0.3829055908234224, 0.28507822708363717, 0.21044918240598418]\n",
            "# 49 \tПример:  A boy is brushing his teeth with his feet up .                                                        \tОценка:  [0.4812265031857878, 0.37195938466682343, 0.2345629473857563, 0.1136013602356153]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XOr1E34CnJ_v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e2c0c72-582a-4571-dfbb-ea601da637f0"
      },
      "source": [
        "%%time\n",
        "print(\"Оценка качества генерации текста на основе BLEU, после обучения с помощью MLE\")\n",
        "# проверка качества обучения\n",
        "BLEU(data_file_test.tolist(), gen.sample(500, degree=degree).cpu().detach().numpy().tolist(), print_iteration=100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Оценка качества генерации текста на основе BLEU, после обучения с помощью MLE\n",
            "--- --- ---\n",
            "Start BLEU\n",
            "2 100 0.5554020966946029\n",
            "2 200 0.5569857332677769\n",
            "2 300 0.5527045340006904\n",
            "2 400 0.5512694131771387\n",
            "2 500 0.5489960772783707\n",
            "--- --- ---\n",
            "2 -gram BLEU score :  0.5489960772783707 \n",
            "\n",
            "3 100 0.48279639356814313\n",
            "3 200 0.48251694389347527\n",
            "3 300 0.47611531119061073\n",
            "3 400 0.47339326248041397\n",
            "3 500 0.4702095930578137\n",
            "--- --- ---\n",
            "3 -gram BLEU score :  0.4702095930578137 \n",
            "\n",
            "4 100 0.3777182340111975\n",
            "4 200 0.3805518656873029\n",
            "4 300 0.3722858666357529\n",
            "4 400 0.36914010674892966\n",
            "4 500 0.36686741332932404\n",
            "--- --- ---\n",
            "4 -gram BLEU score :  0.36686741332932404 \n",
            "\n",
            "5 100 0.25688064362212837\n",
            "5 200 0.26431840820576935\n",
            "5 300 0.256649993492535\n",
            "5 400 0.2554217947897245\n",
            "5 500 0.25457816646887266\n",
            "--- --- ---\n",
            "5 -gram BLEU score :  0.25457816646887266 \n",
            "\n",
            "CPU times: user 7min 36s, sys: 117 ms, total: 7min 36s\n",
            "Wall time: 7min 36s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vdrWQfpV7bie"
      },
      "source": [
        "Предварительное обучение дискриминатора"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FVypqCS4ucWp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3cc811d8-7241-4e91-c6f4-590c16f2abc6"
      },
      "source": [
        "%%time\n",
        "# предобучение дискриминатора\n",
        "print('Запуск обучения дискриминатора...')\n",
        "# dis_optimizer = optim.Adagrad(dis.parameters()) # , lr=0.0001\n",
        "# dis_optimizer = optim.Adam(gen.parameters(), lr=0.001, weight_decay=1e-5)#0.001\n",
        "# dis_optimizer = optim.Adadelta(gen.parameters())\n",
        "# dis_optimizer = optim.Adagrad(dis.parameters())#, lr=0.0001)#, weight_decay=1e-5)\n",
        "#, weight_decay=1e-5) # регуляризация\n",
        "train_discriminator(dis, dis_optimizer, data_file_tensor_train, gen, DIS_TRAIN_ITERATIONS, DIS_TRAIN_EPOCHS)#25, 1 | (15, 3), (25, 1)\n",
        "\n",
        "# сохранение результата обучения\n",
        "save_models(data_file_tensor_train, gen, dis, gen_optimizer, dis_optimizer,\n",
        "            FILE_PATHS['saved_models'] + r'/' + r'seqgan_pretraining_dis.pytorch')\n",
        "\n",
        "# ДО ОБУЧЕНИЯ: val_acc = 0.5230\n",
        "# d-step 50 epoch 1 : .......... average_loss = 0.2859, train_acc = 0.9136, val_acc = 0.5240"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Запуск обучения дискриминатора...\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5000\n",
            "d-step 1 epoch 1 : .......... average_loss = 0.3886, train_acc = 0.8716, val_acc = 0.5000\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5000\n",
            "d-step 2 epoch 1 : .......... average_loss = 0.3226, train_acc = 0.8887, val_acc = 0.5000\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5000\n",
            "d-step 3 epoch 1 : .......... average_loss = 0.3019, train_acc = 0.8909, val_acc = 0.5000\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5000\n",
            "d-step 4 epoch 1 : .......... average_loss = 0.2958, train_acc = 0.8903, val_acc = 0.5000\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5000\n",
            "d-step 5 epoch 1 : .......... average_loss = 0.2889, train_acc = 0.8902, val_acc = 0.5000\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5000\n",
            "d-step 6 epoch 1 : .......... average_loss = 0.2957, train_acc = 0.8880, val_acc = 0.5000\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5000\n",
            "d-step 7 epoch 1 : .......... average_loss = 0.2897, train_acc = 0.8888, val_acc = 0.5000\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5000\n",
            "d-step 8 epoch 1 : .......... average_loss = 0.2869, train_acc = 0.8885, val_acc = 0.5140\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5120\n",
            "d-step 9 epoch 1 : .......... average_loss = 0.2814, train_acc = 0.8915, val_acc = 0.5010\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5020\n",
            "d-step 10 epoch 1 : .......... average_loss = 0.2788, train_acc = 0.8902, val_acc = 0.5040\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5060\n",
            "d-step 11 epoch 1 : .......... average_loss = 0.2805, train_acc = 0.8909, val_acc = 0.5240\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5110\n",
            "d-step 12 epoch 1 : .......... average_loss = 0.2866, train_acc = 0.8871, val_acc = 0.5140\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5100\n",
            "d-step 13 epoch 1 : .......... average_loss = 0.2746, train_acc = 0.8924, val_acc = 0.5520\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5550\n",
            "d-step 14 epoch 1 : .......... average_loss = 0.2785, train_acc = 0.8930, val_acc = 0.5130\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5100\n",
            "d-step 15 epoch 1 : .......... average_loss = 0.2781, train_acc = 0.8924, val_acc = 0.5490\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5610\n",
            "d-step 16 epoch 1 : .......... average_loss = 0.2730, train_acc = 0.8941, val_acc = 0.5540\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5520\n",
            "d-step 17 epoch 1 : .......... average_loss = 0.2688, train_acc = 0.8968, val_acc = 0.5760\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5700\n",
            "d-step 18 epoch 1 : .......... average_loss = 0.2648, train_acc = 0.9003, val_acc = 0.5390\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5460\n",
            "d-step 19 epoch 1 : .......... average_loss = 0.2638, train_acc = 0.8980, val_acc = 0.6030\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5990\n",
            "d-step 20 epoch 1 : .......... average_loss = 0.2609, train_acc = 0.9005, val_acc = 0.6060\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5970\n",
            "d-step 21 epoch 1 : .......... average_loss = 0.2712, train_acc = 0.8961, val_acc = 0.5760\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5820\n",
            "d-step 22 epoch 1 : .......... average_loss = 0.2604, train_acc = 0.9023, val_acc = 0.5760\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5780\n",
            "d-step 23 epoch 1 : .......... average_loss = 0.2585, train_acc = 0.9029, val_acc = 0.6140\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.6100\n",
            "d-step 24 epoch 1 : .......... average_loss = 0.2502, train_acc = 0.9051, val_acc = 0.5950\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5990\n",
            "d-step 25 epoch 1 : .......... average_loss = 0.2436, train_acc = 0.9090, val_acc = 0.6040\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.6100\n",
            "d-step 26 epoch 1 : .......... average_loss = 0.2475, train_acc = 0.9062, val_acc = 0.6200\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.6190\n",
            "d-step 27 epoch 1 : .......... average_loss = 0.2508, train_acc = 0.9059, val_acc = 0.5900\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.5880\n",
            "d-step 28 epoch 1 : .......... average_loss = 0.2526, train_acc = 0.9054, val_acc = 0.6660\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.6680\n",
            "d-step 29 epoch 1 : .......... average_loss = 0.2442, train_acc = 0.9081, val_acc = 0.6400\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.6430\n",
            "d-step 30 epoch 1 : .......... average_loss = 0.2460, train_acc = 0.9092, val_acc = 0.6030\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.6040\n",
            "d-step 31 epoch 1 : .......... average_loss = 0.2396, train_acc = 0.9110, val_acc = 0.6220\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.6240\n",
            "d-step 32 epoch 1 : .......... average_loss = 0.2500, train_acc = 0.9057, val_acc = 0.6670\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.6690\n",
            "d-step 33 epoch 1 : .......... average_loss = 0.2386, train_acc = 0.9121, val_acc = 0.6240\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.6220\n",
            "d-step 34 epoch 1 : .......... average_loss = 0.2427, train_acc = 0.9103, val_acc = 0.6360\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.6270\n",
            "d-step 35 epoch 1 : .......... average_loss = 0.2473, train_acc = 0.9093, val_acc = 0.6500\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.6570\n",
            "d-step 36 epoch 1 : .......... average_loss = 0.2390, train_acc = 0.9137, val_acc = 0.6360\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.6350\n",
            "d-step 37 epoch 1 : .......... average_loss = 0.2386, train_acc = 0.9123, val_acc = 0.6400\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.6360\n",
            "d-step 38 epoch 1 : .......... average_loss = 0.2345, train_acc = 0.9130, val_acc = 0.6150\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.6190\n",
            "d-step 39 epoch 1 : .......... average_loss = 0.2345, train_acc = 0.9140, val_acc = 0.6450\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.6460\n",
            "d-step 40 epoch 1 : .......... average_loss = 0.2313, train_acc = 0.9136, val_acc = 0.6780\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.6810\n",
            "d-step 41 epoch 1 : .......... average_loss = 0.2310, train_acc = 0.9155, val_acc = 0.6430\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.6420\n",
            "d-step 42 epoch 1 : .......... average_loss = 0.2306, train_acc = 0.9143, val_acc = 0.6340\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.6280\n",
            "d-step 43 epoch 1 : .......... average_loss = 0.2302, train_acc = 0.9167, val_acc = 0.6530\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.6520\n",
            "d-step 44 epoch 1 : .......... average_loss = 0.2292, train_acc = 0.9169, val_acc = 0.6350\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.6380\n",
            "d-step 45 epoch 1 : .......... average_loss = 0.2318, train_acc = 0.9157, val_acc = 0.6390\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.6390\n",
            "d-step 46 epoch 1 : .......... average_loss = 0.2283, train_acc = 0.9160, val_acc = 0.6490\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.6480\n",
            "d-step 47 epoch 1 : .......... average_loss = 0.2280, train_acc = 0.9173, val_acc = 0.6460\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.6440\n",
            "d-step 48 epoch 1 : .......... average_loss = 0.2275, train_acc = 0.9169, val_acc = 0.6840\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.6860\n",
            "d-step 49 epoch 1 : .......... average_loss = 0.2246, train_acc = 0.9192, val_acc = 0.6520\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.6460\n",
            "d-step 50 epoch 1 : .......... average_loss = 0.2317, train_acc = 0.9164, val_acc = 0.6660\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.6700\n",
            "d-step 51 epoch 1 : .......... average_loss = 0.2235, train_acc = 0.9193, val_acc = 0.6600\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.6560\n",
            "d-step 52 epoch 1 : .......... average_loss = 0.2235, train_acc = 0.9185, val_acc = 0.6800\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.6800\n",
            "d-step 53 epoch 1 : .......... average_loss = 0.2305, train_acc = 0.9153, val_acc = 0.6530\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.6440\n",
            "d-step 54 epoch 1 : .......... average_loss = 0.2227, train_acc = 0.9203, val_acc = 0.6570\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.6550\n",
            "d-step 55 epoch 1 : .......... average_loss = 0.2228, train_acc = 0.9201, val_acc = 0.6700\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.6650\n",
            "d-step 56 epoch 1 : .......... average_loss = 0.2151, train_acc = 0.9221, val_acc = 0.6870\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.6870\n",
            "d-step 57 epoch 1 : .......... average_loss = 0.2221, train_acc = 0.9205, val_acc = 0.6780\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.6750\n",
            "d-step 58 epoch 1 : .......... average_loss = 0.2264, train_acc = 0.9182, val_acc = 0.6750\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.6760\n",
            "d-step 59 epoch 1 : .......... average_loss = 0.2224, train_acc = 0.9208, val_acc = 0.7010\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7010\n",
            "d-step 60 epoch 1 : .......... average_loss = 0.2154, train_acc = 0.9250, val_acc = 0.6280\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.6310\n",
            "d-step 61 epoch 1 : .......... average_loss = 0.2180, train_acc = 0.9223, val_acc = 0.6590\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.6570\n",
            "d-step 62 epoch 1 : .......... average_loss = 0.2177, train_acc = 0.9206, val_acc = 0.6810\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.6820\n",
            "d-step 63 epoch 1 : .......... average_loss = 0.2140, train_acc = 0.9240, val_acc = 0.7020\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7000\n",
            "d-step 64 epoch 1 : .......... average_loss = 0.2219, train_acc = 0.9221, val_acc = 0.6990\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.6950\n",
            "d-step 65 epoch 1 : .......... average_loss = 0.2125, train_acc = 0.9260, val_acc = 0.6780\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.6810\n",
            "d-step 66 epoch 1 : .......... average_loss = 0.2141, train_acc = 0.9260, val_acc = 0.6730\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.6800\n",
            "d-step 67 epoch 1 : .......... average_loss = 0.2119, train_acc = 0.9251, val_acc = 0.6820\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.6800\n",
            "d-step 68 epoch 1 : .......... average_loss = 0.2086, train_acc = 0.9266, val_acc = 0.6820\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.6830\n",
            "d-step 69 epoch 1 : .......... average_loss = 0.2059, train_acc = 0.9291, val_acc = 0.6910\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.6920\n",
            "d-step 70 epoch 1 : .......... average_loss = 0.2060, train_acc = 0.9283, val_acc = 0.6940\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7020\n",
            "d-step 71 epoch 1 : .......... average_loss = 0.2118, train_acc = 0.9258, val_acc = 0.7140\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7060\n",
            "d-step 72 epoch 1 : .......... average_loss = 0.2104, train_acc = 0.9275, val_acc = 0.7140\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7130\n",
            "d-step 73 epoch 1 : .......... average_loss = 0.2061, train_acc = 0.9270, val_acc = 0.6930\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.6890\n",
            "d-step 74 epoch 1 : .......... average_loss = 0.2079, train_acc = 0.9265, val_acc = 0.7070\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7080\n",
            "d-step 75 epoch 1 : .......... average_loss = 0.2019, train_acc = 0.9283, val_acc = 0.7130\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7140\n",
            "d-step 76 epoch 1 : .......... average_loss = 0.2067, train_acc = 0.9283, val_acc = 0.7160\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7180\n",
            "d-step 77 epoch 1 : .......... average_loss = 0.2078, train_acc = 0.9268, val_acc = 0.6930\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.6940\n",
            "d-step 78 epoch 1 : .......... average_loss = 0.2099, train_acc = 0.9276, val_acc = 0.7090\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7100\n",
            "d-step 79 epoch 1 : .......... average_loss = 0.1980, train_acc = 0.9327, val_acc = 0.6970\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.6980\n",
            "d-step 80 epoch 1 : .......... average_loss = 0.2024, train_acc = 0.9302, val_acc = 0.6990\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.6930\n",
            "d-step 81 epoch 1 : .......... average_loss = 0.2055, train_acc = 0.9290, val_acc = 0.7120\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7170\n",
            "d-step 82 epoch 1 : .......... average_loss = 0.1996, train_acc = 0.9327, val_acc = 0.7050\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7090\n",
            "d-step 83 epoch 1 : .......... average_loss = 0.2032, train_acc = 0.9305, val_acc = 0.7210\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7240\n",
            "d-step 84 epoch 1 : .......... average_loss = 0.2104, train_acc = 0.9275, val_acc = 0.7170\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7010\n",
            "d-step 85 epoch 1 : .......... average_loss = 0.2000, train_acc = 0.9317, val_acc = 0.7240\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7240\n",
            "d-step 86 epoch 1 : .......... average_loss = 0.1935, train_acc = 0.9346, val_acc = 0.6930\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.6930\n",
            "d-step 87 epoch 1 : .......... average_loss = 0.1970, train_acc = 0.9346, val_acc = 0.7080\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7130\n",
            "d-step 88 epoch 1 : .......... average_loss = 0.2065, train_acc = 0.9297, val_acc = 0.7100\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7050\n",
            "d-step 89 epoch 1 : .......... average_loss = 0.1970, train_acc = 0.9337, val_acc = 0.7180\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7160\n",
            "d-step 90 epoch 1 : .......... average_loss = 0.1929, train_acc = 0.9359, val_acc = 0.7150\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7150\n",
            "d-step 91 epoch 1 : .......... average_loss = 0.2008, train_acc = 0.9321, val_acc = 0.7090\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7060\n",
            "d-step 92 epoch 1 : .......... average_loss = 0.1990, train_acc = 0.9342, val_acc = 0.7150\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7150\n",
            "d-step 93 epoch 1 : .......... average_loss = 0.1993, train_acc = 0.9324, val_acc = 0.7320\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7260\n",
            "d-step 94 epoch 1 : .......... average_loss = 0.1940, train_acc = 0.9335, val_acc = 0.7560\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7430\n",
            "d-step 95 epoch 1 : .......... average_loss = 0.1891, train_acc = 0.9367, val_acc = 0.7300\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7350\n",
            "d-step 96 epoch 1 : .......... average_loss = 0.1904, train_acc = 0.9361, val_acc = 0.7120\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7110\n",
            "d-step 97 epoch 1 : .......... average_loss = 0.1919, train_acc = 0.9357, val_acc = 0.7500\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7510\n",
            "d-step 98 epoch 1 : .......... average_loss = 0.1962, train_acc = 0.9347, val_acc = 0.7200\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7200\n",
            "d-step 99 epoch 1 : .......... average_loss = 0.1998, train_acc = 0.9322, val_acc = 0.7170\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7160\n",
            "d-step 100 epoch 1 : .......... average_loss = 0.1887, train_acc = 0.9365, val_acc = 0.7100\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7110\n",
            "d-step 101 epoch 1 : .......... average_loss = 0.1823, train_acc = 0.9400, val_acc = 0.7600\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7560\n",
            "d-step 102 epoch 1 : .......... average_loss = 0.1841, train_acc = 0.9381, val_acc = 0.7320\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7440\n",
            "d-step 103 epoch 1 : .......... average_loss = 0.1827, train_acc = 0.9381, val_acc = 0.7590\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7590\n",
            "d-step 104 epoch 1 : .......... average_loss = 0.1909, train_acc = 0.9376, val_acc = 0.7470\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7380\n",
            "d-step 105 epoch 1 : .......... average_loss = 0.1826, train_acc = 0.9407, val_acc = 0.7410\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7440\n",
            "d-step 106 epoch 1 : .......... average_loss = 0.1854, train_acc = 0.9394, val_acc = 0.7480\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7420\n",
            "d-step 107 epoch 1 : .......... average_loss = 0.1866, train_acc = 0.9374, val_acc = 0.7440\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7440\n",
            "d-step 108 epoch 1 : .......... average_loss = 0.1869, train_acc = 0.9383, val_acc = 0.7300\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7240\n",
            "d-step 109 epoch 1 : .......... average_loss = 0.1836, train_acc = 0.9395, val_acc = 0.7110\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7180\n",
            "d-step 110 epoch 1 : .......... average_loss = 0.1825, train_acc = 0.9424, val_acc = 0.7400\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7460\n",
            "d-step 111 epoch 1 : .......... average_loss = 0.1856, train_acc = 0.9385, val_acc = 0.7220\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7220\n",
            "d-step 112 epoch 1 : .......... average_loss = 0.1922, train_acc = 0.9358, val_acc = 0.7430\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7400\n",
            "d-step 113 epoch 1 : .......... average_loss = 0.1837, train_acc = 0.9401, val_acc = 0.7150\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7120\n",
            "d-step 114 epoch 1 : .......... average_loss = 0.1765, train_acc = 0.9428, val_acc = 0.7530\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7590\n",
            "d-step 115 epoch 1 : .......... average_loss = 0.1828, train_acc = 0.9398, val_acc = 0.7530\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7540\n",
            "d-step 116 epoch 1 : .......... average_loss = 0.1813, train_acc = 0.9414, val_acc = 0.7320\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7370\n",
            "d-step 117 epoch 1 : .......... average_loss = 0.1810, train_acc = 0.9407, val_acc = 0.7450\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7370\n",
            "d-step 118 epoch 1 : .......... average_loss = 0.1848, train_acc = 0.9390, val_acc = 0.7490\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7450\n",
            "d-step 119 epoch 1 : .......... average_loss = 0.1793, train_acc = 0.9429, val_acc = 0.7600\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7500\n",
            "d-step 120 epoch 1 : .......... average_loss = 0.1767, train_acc = 0.9441, val_acc = 0.7640\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7620\n",
            "d-step 121 epoch 1 : .......... average_loss = 0.1756, train_acc = 0.9437, val_acc = 0.7720\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7660\n",
            "d-step 122 epoch 1 : .......... average_loss = 0.1759, train_acc = 0.9423, val_acc = 0.7620\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7550\n",
            "d-step 123 epoch 1 : .......... average_loss = 0.1794, train_acc = 0.9427, val_acc = 0.7550\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7590\n",
            "d-step 124 epoch 1 : .......... average_loss = 0.1830, train_acc = 0.9404, val_acc = 0.7560\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7570\n",
            "d-step 125 epoch 1 : .......... average_loss = 0.1738, train_acc = 0.9452, val_acc = 0.7550\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7500\n",
            "d-step 126 epoch 1 : .......... average_loss = 0.1760, train_acc = 0.9425, val_acc = 0.7350\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7390\n",
            "d-step 127 epoch 1 : .......... average_loss = 0.1778, train_acc = 0.9423, val_acc = 0.7740\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7750\n",
            "d-step 128 epoch 1 : .......... average_loss = 0.1793, train_acc = 0.9416, val_acc = 0.7650\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7610\n",
            "d-step 129 epoch 1 : .......... average_loss = 0.1732, train_acc = 0.9440, val_acc = 0.7580\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7460\n",
            "d-step 130 epoch 1 : .......... average_loss = 0.1733, train_acc = 0.9449, val_acc = 0.7490\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7520\n",
            "d-step 131 epoch 1 : .......... average_loss = 0.1732, train_acc = 0.9447, val_acc = 0.7650\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7660\n",
            "d-step 132 epoch 1 : .......... average_loss = 0.1724, train_acc = 0.9453, val_acc = 0.7750\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7760\n",
            "d-step 133 epoch 1 : .......... average_loss = 0.1674, train_acc = 0.9484, val_acc = 0.7840\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7780\n",
            "d-step 134 epoch 1 : .......... average_loss = 0.1700, train_acc = 0.9449, val_acc = 0.7710\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7620\n",
            "d-step 135 epoch 1 : .......... average_loss = 0.1668, train_acc = 0.9478, val_acc = 0.7730\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7650\n",
            "d-step 136 epoch 1 : .......... average_loss = 0.1674, train_acc = 0.9476, val_acc = 0.7570\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7590\n",
            "d-step 137 epoch 1 : .......... average_loss = 0.1709, train_acc = 0.9474, val_acc = 0.7750\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7740\n",
            "d-step 138 epoch 1 : .......... average_loss = 0.1719, train_acc = 0.9454, val_acc = 0.7750\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7710\n",
            "d-step 139 epoch 1 : .......... average_loss = 0.1634, train_acc = 0.9477, val_acc = 0.7740\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7690\n",
            "d-step 140 epoch 1 : .......... average_loss = 0.1687, train_acc = 0.9465, val_acc = 0.7610\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7610\n",
            "d-step 141 epoch 1 : .......... average_loss = 0.1680, train_acc = 0.9464, val_acc = 0.7900\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7810\n",
            "d-step 142 epoch 1 : .......... average_loss = 0.1656, train_acc = 0.9466, val_acc = 0.7530\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7580\n",
            "d-step 143 epoch 1 : .......... average_loss = 0.1675, train_acc = 0.9473, val_acc = 0.7530\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7520\n",
            "d-step 144 epoch 1 : .......... average_loss = 0.1609, train_acc = 0.9481, val_acc = 0.7840\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7840\n",
            "d-step 145 epoch 1 : .......... average_loss = 0.1714, train_acc = 0.9460, val_acc = 0.7760\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7760\n",
            "d-step 146 epoch 1 : .......... average_loss = 0.1682, train_acc = 0.9482, val_acc = 0.7640\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7620\n",
            "d-step 147 epoch 1 : .......... average_loss = 0.1686, train_acc = 0.9478, val_acc = 0.7520\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7550\n",
            "d-step 148 epoch 1 : .......... average_loss = 0.1646, train_acc = 0.9478, val_acc = 0.7780\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7750\n",
            "d-step 149 epoch 1 : .......... average_loss = 0.1673, train_acc = 0.9474, val_acc = 0.7720\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7730\n",
            "d-step 150 epoch 1 : .......... average_loss = 0.1649, train_acc = 0.9490, val_acc = 0.7770\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7780\n",
            "d-step 151 epoch 1 : .......... average_loss = 0.1586, train_acc = 0.9515, val_acc = 0.7790\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7740\n",
            "d-step 152 epoch 1 : .......... average_loss = 0.1603, train_acc = 0.9503, val_acc = 0.7940\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7920\n",
            "d-step 153 epoch 1 : .......... average_loss = 0.1642, train_acc = 0.9488, val_acc = 0.7920\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7890\n",
            "d-step 154 epoch 1 : .......... average_loss = 0.1557, train_acc = 0.9513, val_acc = 0.7890\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7850\n",
            "d-step 155 epoch 1 : .......... average_loss = 0.1597, train_acc = 0.9506, val_acc = 0.7790\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7770\n",
            "d-step 156 epoch 1 : .......... average_loss = 0.1602, train_acc = 0.9508, val_acc = 0.7420\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7450\n",
            "d-step 157 epoch 1 : .......... average_loss = 0.1654, train_acc = 0.9490, val_acc = 0.7870\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7900\n",
            "d-step 158 epoch 1 : .......... average_loss = 0.1635, train_acc = 0.9483, val_acc = 0.7790\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7820\n",
            "d-step 159 epoch 1 : .......... average_loss = 0.1623, train_acc = 0.9513, val_acc = 0.7830\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7890\n",
            "d-step 160 epoch 1 : .......... average_loss = 0.1599, train_acc = 0.9514, val_acc = 0.7860\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7830\n",
            "d-step 161 epoch 1 : .......... average_loss = 0.1675, train_acc = 0.9475, val_acc = 0.8070\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.8070\n",
            "d-step 162 epoch 1 : .......... average_loss = 0.1581, train_acc = 0.9520, val_acc = 0.8050\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7980\n",
            "d-step 163 epoch 1 : .......... average_loss = 0.1641, train_acc = 0.9503, val_acc = 0.7980\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.8070\n",
            "d-step 164 epoch 1 : .......... average_loss = 0.1592, train_acc = 0.9518, val_acc = 0.7910\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7890\n",
            "d-step 165 epoch 1 : .......... average_loss = 0.1634, train_acc = 0.9499, val_acc = 0.7800\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7780\n",
            "d-step 166 epoch 1 : .......... average_loss = 0.1562, train_acc = 0.9516, val_acc = 0.7920\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7860\n",
            "d-step 167 epoch 1 : .......... average_loss = 0.1618, train_acc = 0.9502, val_acc = 0.7970\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7980\n",
            "d-step 168 epoch 1 : .......... average_loss = 0.1609, train_acc = 0.9508, val_acc = 0.7890\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7930\n",
            "d-step 169 epoch 1 : .......... average_loss = 0.1562, train_acc = 0.9529, val_acc = 0.7870\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7850\n",
            "d-step 170 epoch 1 : .......... average_loss = 0.1589, train_acc = 0.9510, val_acc = 0.8070\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.8010\n",
            "d-step 171 epoch 1 : .......... average_loss = 0.1545, train_acc = 0.9531, val_acc = 0.7990\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.8010\n",
            "d-step 172 epoch 1 : .......... average_loss = 0.1524, train_acc = 0.9542, val_acc = 0.7890\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7920\n",
            "d-step 173 epoch 1 : .......... average_loss = 0.1493, train_acc = 0.9552, val_acc = 0.7830\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7910\n",
            "d-step 174 epoch 1 : .......... average_loss = 0.1591, train_acc = 0.9516, val_acc = 0.7820\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7890\n",
            "d-step 175 epoch 1 : .......... average_loss = 0.1535, train_acc = 0.9529, val_acc = 0.8240\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.8100\n",
            "d-step 176 epoch 1 : .......... average_loss = 0.1494, train_acc = 0.9536, val_acc = 0.8030\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.8010\n",
            "d-step 177 epoch 1 : .......... average_loss = 0.1582, train_acc = 0.9528, val_acc = 0.7860\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7830\n",
            "d-step 178 epoch 1 : .......... average_loss = 0.1522, train_acc = 0.9536, val_acc = 0.7900\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.8000\n",
            "d-step 179 epoch 1 : .......... average_loss = 0.1599, train_acc = 0.9515, val_acc = 0.8060\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.8060\n",
            "d-step 180 epoch 1 : .......... average_loss = 0.1489, train_acc = 0.9563, val_acc = 0.8080\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.8100\n",
            "d-step 181 epoch 1 : .......... average_loss = 0.1563, train_acc = 0.9523, val_acc = 0.8050\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.8060\n",
            "d-step 182 epoch 1 : .......... average_loss = 0.1559, train_acc = 0.9532, val_acc = 0.8260\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.8180\n",
            "d-step 183 epoch 1 : .......... average_loss = 0.1527, train_acc = 0.9535, val_acc = 0.8000\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.8050\n",
            "d-step 184 epoch 1 : .......... average_loss = 0.1525, train_acc = 0.9529, val_acc = 0.8010\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7970\n",
            "d-step 185 epoch 1 : .......... average_loss = 0.1455, train_acc = 0.9565, val_acc = 0.8050\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.8020\n",
            "d-step 186 epoch 1 : .......... average_loss = 0.1487, train_acc = 0.9555, val_acc = 0.7920\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7920\n",
            "d-step 187 epoch 1 : .......... average_loss = 0.1511, train_acc = 0.9551, val_acc = 0.8020\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.8090\n",
            "d-step 188 epoch 1 : .......... average_loss = 0.1531, train_acc = 0.9543, val_acc = 0.8020\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.8050\n",
            "d-step 189 epoch 1 : .......... average_loss = 0.1478, train_acc = 0.9566, val_acc = 0.7980\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7920\n",
            "d-step 190 epoch 1 : .......... average_loss = 0.1512, train_acc = 0.9544, val_acc = 0.8120\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.8110\n",
            "d-step 191 epoch 1 : .......... average_loss = 0.1510, train_acc = 0.9554, val_acc = 0.8010\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7980\n",
            "d-step 192 epoch 1 : .......... average_loss = 0.1502, train_acc = 0.9550, val_acc = 0.7790\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7850\n",
            "d-step 193 epoch 1 : .......... average_loss = 0.1532, train_acc = 0.9556, val_acc = 0.8180\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.8120\n",
            "d-step 194 epoch 1 : .......... average_loss = 0.1506, train_acc = 0.9557, val_acc = 0.7900\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7890\n",
            "d-step 195 epoch 1 : .......... average_loss = 0.1495, train_acc = 0.9536, val_acc = 0.7970\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7910\n",
            "d-step 196 epoch 1 : .......... average_loss = 0.1456, train_acc = 0.9564, val_acc = 0.8040\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.8070\n",
            "d-step 197 epoch 1 : .......... average_loss = 0.1500, train_acc = 0.9545, val_acc = 0.7980\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7990\n",
            "d-step 198 epoch 1 : .......... average_loss = 0.1436, train_acc = 0.9578, val_acc = 0.8190\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.8190\n",
            "d-step 199 epoch 1 : .......... average_loss = 0.1457, train_acc = 0.9568, val_acc = 0.8230\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.8120\n",
            "d-step 200 epoch 1 : .......... average_loss = 0.1484, train_acc = 0.9555, val_acc = 0.8110\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.8100\n",
            "d-step 201 epoch 1 : .......... average_loss = 0.1421, train_acc = 0.9585, val_acc = 0.8130\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.8120\n",
            "d-step 202 epoch 1 : .......... average_loss = 0.1482, train_acc = 0.9564, val_acc = 0.7980\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.7940\n",
            "d-step 203 epoch 1 : .......... average_loss = 0.1450, train_acc = 0.9568, val_acc = 0.8130\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.8130\n",
            "d-step 204 epoch 1 : .......... average_loss = 0.1417, train_acc = 0.9581, val_acc = 0.8130\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.8170\n",
            "d-step 205 epoch 1 : .......... average_loss = 0.1454, train_acc = 0.9575, val_acc = 0.8230\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.8220\n",
            "d-step 206 epoch 1 : .......... average_loss = 0.1423, train_acc = 0.9573, val_acc = 0.8280\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.8230\n",
            "d-step 207 epoch 1 : .......... average_loss = 0.1424, train_acc = 0.9577, val_acc = 0.8100\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.8050\n",
            "d-step 208 epoch 1 : .......... average_loss = 0.1460, train_acc = 0.9579, val_acc = 0.8200\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.8150\n",
            "d-step 209 epoch 1 : .......... average_loss = 0.1507, train_acc = 0.9555, val_acc = 0.8180\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.8200\n",
            "d-step 210 epoch 1 : .......... average_loss = 0.1458, train_acc = 0.9577, val_acc = 0.8290\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.8250\n",
            "d-step 211 epoch 1 : .......... average_loss = 0.1491, train_acc = 0.9563, val_acc = 0.8210\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.8160\n",
            "d-step 212 epoch 1 : .......... average_loss = 0.1423, train_acc = 0.9583, val_acc = 0.8070\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.8040\n",
            "d-step 213 epoch 1 : .......... average_loss = 0.1427, train_acc = 0.9575, val_acc = 0.8060\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.8180\n",
            "d-step 214 epoch 1 : .......... average_loss = 0.1441, train_acc = 0.9578, val_acc = 0.8270\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.8290\n",
            "d-step 215 epoch 1 : .......... average_loss = 0.1459, train_acc = 0.9567, val_acc = 0.8100\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.8130\n",
            "d-step 216 epoch 1 : .......... average_loss = 0.1435, train_acc = 0.9575, val_acc = 0.8190\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.8200\n",
            "d-step 217 epoch 1 : .......... average_loss = 0.1466, train_acc = 0.9565, val_acc = 0.8140\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.8190\n",
            "d-step 218 epoch 1 : .......... average_loss = 0.1417, train_acc = 0.9589, val_acc = 0.8040\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.8140\n",
            "d-step 219 epoch 1 : .......... average_loss = 0.1386, train_acc = 0.9597, val_acc = 0.8290\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.8170\n",
            "d-step 220 epoch 1 : .......... average_loss = 0.1461, train_acc = 0.9574, val_acc = 0.8020\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.8050\n",
            "d-step 221 epoch 1 : .......... average_loss = 0.1411, train_acc = 0.9591, val_acc = 0.8370\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.8330\n",
            "d-step 222 epoch 1 : .......... average_loss = 0.1450, train_acc = 0.9573, val_acc = 0.8220\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.8260\n",
            "d-step 223 epoch 1 : .......... average_loss = 0.1412, train_acc = 0.9598, val_acc = 0.8130\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.8150\n",
            "d-step 224 epoch 1 : .......... average_loss = 0.1356, train_acc = 0.9615, val_acc = 0.8250\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.8240\n",
            "d-step 225 epoch 1 : .......... average_loss = 0.1449, train_acc = 0.9574, val_acc = 0.8260\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.8330\n",
            "d-step 226 epoch 1 : .......... average_loss = 0.1376, train_acc = 0.9594, val_acc = 0.8270\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.8210\n",
            "d-step 227 epoch 1 : .......... average_loss = 0.1374, train_acc = 0.9599, val_acc = 0.8250\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.8330\n",
            "d-step 228 epoch 1 : .......... average_loss = 0.1385, train_acc = 0.9593, val_acc = 0.8280\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.8250\n",
            "d-step 229 epoch 1 : .......... average_loss = 0.1332, train_acc = 0.9625, val_acc = 0.8330\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.8190\n",
            "d-step 230 epoch 1 : .......... average_loss = 0.1405, train_acc = 0.9605, val_acc = 0.8220\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.8210\n",
            "d-step 231 epoch 1 : .......... average_loss = 0.1405, train_acc = 0.9596, val_acc = 0.8250\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.8220\n",
            "d-step 232 epoch 1 : .......... average_loss = 0.1361, train_acc = 0.9609, val_acc = 0.8250\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.8290\n",
            "d-step 233 epoch 1 : .......... average_loss = 0.1357, train_acc = 0.9605, val_acc = 0.8430\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.8310\n",
            "d-step 234 epoch 1 : .......... average_loss = 0.1362, train_acc = 0.9617, val_acc = 0.8270\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.8250\n",
            "d-step 235 epoch 1 : .......... average_loss = 0.1360, train_acc = 0.9609, val_acc = 0.8330\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.8360\n",
            "d-step 236 epoch 1 : .......... average_loss = 0.1410, train_acc = 0.9588, val_acc = 0.8280\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.8340\n",
            "d-step 237 epoch 1 : .......... average_loss = 0.1366, train_acc = 0.9606, val_acc = 0.8290\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.8390\n",
            "d-step 238 epoch 1 : .......... average_loss = 0.1351, train_acc = 0.9611, val_acc = 0.8420\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.8370\n",
            "d-step 239 epoch 1 : .......... average_loss = 0.1358, train_acc = 0.9610, val_acc = 0.8270\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.8200\n",
            "d-step 240 epoch 1 : .......... average_loss = 0.1375, train_acc = 0.9615, val_acc = 0.8250\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.8260\n",
            "d-step 241 epoch 1 : .......... average_loss = 0.1387, train_acc = 0.9603, val_acc = 0.8270\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.8170\n",
            "d-step 242 epoch 1 : .......... average_loss = 0.1332, train_acc = 0.9617, val_acc = 0.8280\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.8310\n",
            "d-step 243 epoch 1 : .......... average_loss = 0.1328, train_acc = 0.9624, val_acc = 0.8410\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.8340\n",
            "d-step 244 epoch 1 : .......... average_loss = 0.1385, train_acc = 0.9614, val_acc = 0.8150\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.8130\n",
            "d-step 245 epoch 1 : .......... average_loss = 0.1314, train_acc = 0.9634, val_acc = 0.8320\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.8280\n",
            "d-step 246 epoch 1 : .......... average_loss = 0.1324, train_acc = 0.9621, val_acc = 0.8280\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.8310\n",
            "d-step 247 epoch 1 : .......... average_loss = 0.1384, train_acc = 0.9601, val_acc = 0.8240\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.8300\n",
            "d-step 248 epoch 1 : .......... average_loss = 0.1295, train_acc = 0.9633, val_acc = 0.8440\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.8380\n",
            "d-step 249 epoch 1 : .......... average_loss = 0.1409, train_acc = 0.9594, val_acc = 0.8320\n",
            "ДО ОБУЧЕНИЯ: val_acc = 0.8280\n",
            "d-step 250 epoch 1 : .......... average_loss = 0.1350, train_acc = 0.9608, val_acc = 0.8310\n",
            "CPU times: user 6min 2s, sys: 1min 45s, total: 7min 47s\n",
            "Wall time: 7min 51s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j8Znhasa7gr5"
      },
      "source": [
        "Состязательное обучение. Обучение генератора на основе обучения с подкреплением"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oELznd8Bs6-q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ede421f-67ff-4aee-c406-9f4457de20d2"
      },
      "source": [
        "test_mle(gen, data_file_tensor_train, data_file_tensor_test)\n",
        "# average_train_NLL = 1.7516 average_test_NLL = 1.9832"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "average_train_NLL = 1.8360 average_test_NLL = 1.9977\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V9gy5KOOuibf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 595
        },
        "outputId": "b3f78b92-569f-4560-be6d-871fa89a29a5"
      },
      "source": [
        "%%time\n",
        "# gen_optimizer = optim.Adagrad(gen.parameters(), lr=0.0005)#Adam #, lr=0.0005\n",
        "# dis_optimizer = optim.Adagrad(dis.parameters())\n",
        "# gen_optimizer = optim.Adam(gen.parameters(), lr=0.0001)#Adam #, lr=0.0005\n",
        "# dis_optimizer = optim.Adagrad(dis.parameters(), lr=0.001)#, lr=0.002\n",
        "\n",
        "# состязательное обучение генератора\n",
        "print('\\nStarting Adversarial Training...')\n",
        "\n",
        "for epoch in range(ADV_TRAIN_EPOCHS):# ADV_TRAIN_EPOCHS\n",
        "    print('\\n--------\\nEPOCH %d\\n--------' % (epoch+1))\n",
        "    # обучение генератора\n",
        "    print('\\nAdversarial Training Generator : ', end='')\n",
        "    train_generator_PG(gen, gen_optimizer, dis, 1)#\n",
        "\n",
        "    # тестирование nll\n",
        "    print('\\nTesting Generator : ', end='')\n",
        "    test_mle(gen, data_file_tensor_train, data_file_tensor_test)\n",
        "\n",
        "    # обучение дискриминатора\n",
        "    print('\\nAdversarial Training Discriminator : ')\n",
        "    train_discriminator(dis, dis_optimizer, data_file_tensor_train, gen, 5, 1)#3, 1\n",
        "\n",
        "# сохранение результата обучения\n",
        "save_models(data_file_tensor_train, gen, dis, gen_optimizer, dis_optimizer,\n",
        "            FILE_PATHS['saved_models'] + r'/' + r'seqgan_adversarial_training.pytorch')\n",
        "# epoch 3 : .......... average_train_NLL = 1.8005 average_test_NLL = 1.9824\n",
        "# average_train_NLL = 1.7340 average_test_NLL = 2.0599"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Starting Adversarial Training...\n",
            "\n",
            "--------\n",
            "EPOCH 1\n",
            "--------\n",
            "\n",
            "Adversarial Training Generator : "
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-106-d4924a2daaa4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"# gen_optimizer = optim.Adagrad(gen.parameters(), lr=0.0005)#Adam #, lr=0.0005\\n# dis_optimizer = optim.Adagrad(dis.parameters())\\n# gen_optimizer = optim.Adam(gen.parameters(), lr=0.0001)#Adam #, lr=0.0005\\n# dis_optimizer = optim.Adagrad(dis.parameters(), lr=0.001)#, lr=0.002\\n\\n# состязательное обучение генератора\\nprint('\\\\nStarting Adversarial Training...')\\n\\nfor epoch in range(ADV_TRAIN_EPOCHS):# ADV_TRAIN_EPOCHS\\n    print('\\\\n--------\\\\nEPOCH %d\\\\n--------' % (epoch+1))\\n    # обучение генератора\\n    print('\\\\nAdversarial Training Generator : ', end='')\\n    train_generator_PG(gen, gen_optimizer, dis, 1)#\\n\\n    # тестирование nll\\n    print('\\\\nTesting Generator : ', end='')\\n    test_mle(gen, data_file_tensor_train, data_file_tensor_test)\\n\\n    # обучение дискриминатора\\n    print('\\\\nAdversarial Training Discriminator : ')\\n    train_discriminator(dis, dis_optimizer, data_file_tensor_train, gen, 5, 1)#3, 1\\n\\n# сохранение результата обучения\\nsave_models(data_file_tensor_train, gen, dis, gen_optimizer, dis_optimizer,\\n            FILE_PATHS['saved_models'] + r'/' + r'seqgan_adversarial_training.pytorch')\\n# epoch 3 : .......... average_train_NLL = 1.8005 average_test_NLL = 1.9824\\n# average_train_NLL = 1.7340 average_test_NLL = 2.0599\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2115\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2116\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2117\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2118\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<decorator-gen-60>\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1191\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m             \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1193\u001b[0;31m             \u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1194\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1195\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m<ipython-input-74-4d91a0b59fe3>\u001b[0m in \u001b[0;36mtrain_generator_PG\u001b[0;34m(gen, gen_opt, dis, num_batches)\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0mpg_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatchPGLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrewards\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0mpg_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m         \u001b[0mgen_opt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    117\u001b[0m                    \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m                    \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'weight_decay'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m                    \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'eps'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m                    )\n\u001b[1;32m    121\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/optim/functional.py\u001b[0m in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0;31m# Decay the first and second moment running average coefficient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m         \u001b[0mexp_avg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m         \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mamsgrad\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vs3-xXxc3rQ6"
      },
      "source": [
        "Тестирование генератора на обучающей выборке после состязательного обучения."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CWz3XBxE3nOp"
      },
      "source": [
        "%%time\n",
        "test_mle(gen, data_file_tensor_train, data_file_tensor_test)\n",
        "# average_train_NLL = 1.5186 average_test_NLL = 2.0730\n",
        "# average_train_NLL = 1.4459 average_test_NLL = 1.9926"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vF9S-MHOJm7d"
      },
      "source": [
        "Генерация примеров текстов на основе SeqGAN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cLUxNkP7LhHU"
      },
      "source": [
        "# примеры сгенерированных текстов\n",
        "print(\"Примеры генерируемых текстов на основе SeqGAN\")\n",
        "degree = 1\n",
        "print(\"Degree:\", degree)\n",
        "samples = gen.sample(50, degree=degree).cpu().detach().numpy()\n",
        "\n",
        "output_function = []\n",
        "for i, samp in enumerate(samples):\n",
        "  line = [word[x] for x in samp]\n",
        "  line = ' '.join(line)\n",
        "  output_function.append(line)\n",
        "  bleu = BLEU(data_file_test.tolist(), [samp], flag_print=False)\n",
        "  print(\"#\", i, \"\\tПример: \", line, ' '*(100-len(line)), '\\tОценка: ', bleu)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J7ZUtKiv7n88"
      },
      "source": [
        "Оценка качества генерации на основе SeqGAN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tets0DMEuDkC"
      },
      "source": [
        "%%time\n",
        "print(\"Оценка качества генерации текстов на основе BLEU, после обучения с помощью SeqGAN\")\n",
        "degree = 1\n",
        "print(\"Degree:\", degree)\n",
        "# проверка качества обучения\n",
        "BLEU(data_file_test.tolist(), gen.sample(500, degree=degree).cpu().detach().numpy().tolist(), print_iteration=100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a5RkMEMws99n"
      },
      "source": [
        "Оценка с возведением в степень"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2tZle_Ydnb85"
      },
      "source": [
        "# примеры сгенерированных текстов\n",
        "print(\"Примеры генерируемых текстов на основе SeqGAN с возведением в степень\")\n",
        "degree = 1.5\n",
        "print(\"Degree:\", degree)\n",
        "samples = gen.sample(50, degree=degree).cpu().detach().numpy()\n",
        "\n",
        "output_function = []\n",
        "for i, samp in enumerate(samples):\n",
        "  line = [word[x] for x in samp]\n",
        "  line = ' '.join(line)\n",
        "  output_function.append(line)\n",
        "  bleu = BLEU(data_file_test.tolist(), [samp], flag_print=False)\n",
        "  print(\"#\", i, \"\\tПример: \", line, ' '*(100-len(line)), '\\tОценка: ', bleu)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ATYRFjknb85"
      },
      "source": [
        "%%time\n",
        "print(\"Оценка качества генерации текстов на основе BLEU, после обучения с помощью SeqGAN\")\n",
        "# проверка качества обучения\n",
        "BLEU(data_file_test.tolist(), gen.sample(500, degree=degree).cpu().detach().numpy().tolist(), print_iteration=100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VhrWW-2bKH9E"
      },
      "source": [
        "Загрузка сохраненной модели"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mHsreqY23P-T"
      },
      "source": [
        "# загрузка моделей\n",
        "[data_file_tensor_train, gen, dis, gen_optimizer, dis_optimizer,\n",
        "VOCAB_SIZE, MAX_SEQ_LEN, GEN_EMBEDDING_DIM, GEN_HIDDEN_DIM, DIS_EMBEDDING_DIM,\n",
        " DIS_HIDDEN_DIM] = load_models(FILE_PATHS['saved_models'] + r'/' + r'seqgan_adversarial_training.pytorch')#[seqgan_mle, seqgan_pretraining_dis, seqgan_adversarial_training]\n",
        "\n",
        "if(CUDA):\n",
        "  gen = gen.cuda()\n",
        "  dis = dis.cuda()\n",
        "  data_file_tensor_train = torch.tensor(data_file_tensor_train).cuda()\n",
        "  data_file_tensor_test = torch.tensor(data_file_test).cuda()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OxiSFluHn55b"
      },
      "source": [
        "Оценка разнообразия текста"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WWqjB09kjCHN"
      },
      "source": [
        "degree = 1.5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KhYDh_ByyqIS"
      },
      "source": [
        "# плагиат из обучающей выборки\n",
        "samples = gen.sample(1500, degree=degree).cpu().detach().numpy().tolist()\n",
        "# samples = data_file_test.tolist()[:500]\n",
        "train_samples = data_file_train.tolist()\n",
        "n = 0\n",
        "for i in range(len(samples)):\n",
        "  if samples[i] in train_samples:\n",
        "    n += 1\n",
        "  if i%(len(samples)//10) == 0:\n",
        "    print(i/len(samples)*100, \"%\")\n",
        "print(\"Совпало сгенерированных примеров с обучающей выборкой: \", n, \"из\", len(samples))\n",
        "print(\"Плагиат: \", n/len(samples)*100, \"%\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gOzmSGPN7Jc6"
      },
      "source": [
        "# оригинальность примеров\n",
        "N_samples = 1500\n",
        "samples_1 = gen.sample(N_samples, degree=degree).cpu().detach().numpy().tolist()\n",
        "samples_2 = gen.sample(N_samples, degree=degree).cpu().detach().numpy().tolist()\n",
        "\n",
        "n = 0\n",
        "for i in range(len(samples_1)):\n",
        "  if samples_1[i] in samples_2:\n",
        "    n += 1\n",
        "  if i%(len(samples_1)//10) == 0:\n",
        "    print(i/len(samples_1)*100, \"%\")\n",
        "\n",
        "print(\"Оригинальность генерируемых примеров\")\n",
        "print(\"Совпало примеров из выборки 1 с примерами из выборки 2: \", n, \"из\", len(samples_1))\n",
        "print(\"Плагиат: \", n/len(samples_1)*100, \"%\")\n",
        "print(\"Оригинальность: \", (1-n/len(samples_1))*100, \"%\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AY0ev9FO94ll"
      },
      "source": [
        "# оригинальность примеров подход 2\n",
        "N_samples = 1500\n",
        "samples = gen.sample(N_samples, degree=degree).cpu().detach().numpy().tolist()\n",
        "\n",
        "i = 0\n",
        "n = 0\n",
        "while len(samples)>0:\n",
        "  if samples[0] not in samples[1:]:\n",
        "    n += 1\n",
        "  if i%(N_samples//10) == 0:\n",
        "    print(i/N_samples*100, \"%\")\n",
        "  del(samples[0])\n",
        "  i += 1\n",
        "\n",
        "print(\"Оригинальность генерируемых примеров\")\n",
        "print(\"Сгенерировано оригинальных примеров: \", n, \"из\", N_samples)\n",
        "print(\"Оригинальность: \", n/N_samples*100, \"%\")\n",
        "print(\"Плагиат: \", (1-n/N_samples)*100, \"%\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}